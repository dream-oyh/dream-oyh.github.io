<!doctype html>
<html lang="zh-CN" data-theme="light">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <meta name="generator" content="VuePress 2.0.0-rc.8" />
    <meta name="theme" content="VuePress Theme Hope 2.0.0-rc.31" />
    <style>
      html {
        background: var(--bg-color, #fff);
      }

      html[data-theme="dark"] {
        background: var(--bg-color, #1d1e1f);
      }

      body {
        background: var(--bg-color);
      }
    </style>
    <script>
      const userMode = localStorage.getItem("vuepress-theme-hope-scheme");
      const systemDarkMode =
        window.matchMedia &&
        window.matchMedia("(prefers-color-scheme: dark)").matches;

      if (userMode === "dark" || (userMode !== "light" && systemDarkMode)) {
        document.documentElement.setAttribute("data-theme", "dark");
      }
    </script>
    <meta property="og:url" content="https://dream-oyh.github.io/code/python/pytorch/1pytorch.html"><meta property="og:site_name" content="Dream_oyh 的 blog"><meta property="og:title" content="Pytorch 的配置与基本操作"><meta property="og:description" content="Pytorch 的配置与基本操作 官网 《动手学深度学习-Pytorch 版》学习文档 《动手学深度学习》原书文档 Miniconda 配置 Pytorch 由于 poetry 配置 pytorch 很麻烦，所以我把 pytorch 配置在了 linux 环境下，并且采取 miniconda 作为包管理器。 到官网的 Get started 文档 选择..."><meta property="og:type" content="article"><meta property="og:locale" content="zh-CN"><meta property="og:updated_time" content="2024-02-19T14:31:50.000Z"><meta property="article:author" content="OYH"><meta property="article:published_time" content="2024-02-16T00:00:00.000Z"><meta property="article:modified_time" content="2024-02-19T14:31:50.000Z"><script type="application/ld+json">{"@context":"https://schema.org","@type":"Article","headline":"Pytorch 的配置与基本操作","image":[""],"datePublished":"2024-02-16T00:00:00.000Z","dateModified":"2024-02-19T14:31:50.000Z","author":[{"@type":"Person","name":"OYH","email":"19859860010@163.com"}]}</script><link rel="stylesheet" href="/mask.css"><link rel="stylesheet" href="/highlight.css"><script async src="https://www.googletagmanager.com/gtag/js?id=G-NQR8MZSFKD"></script><script><!-- Google tag (gtag.js) -->
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
    gtag('config', 'G-xxxxxxxx');</script><link rel="icon" href="/web_logo.jpg"><title>Pytorch 的配置与基本操作 | Dream_oyh 的 blog</title><meta name="description" content="Pytorch 的配置与基本操作 官网 《动手学深度学习-Pytorch 版》学习文档 《动手学深度学习》原书文档 Miniconda 配置 Pytorch 由于 poetry 配置 pytorch 很麻烦，所以我把 pytorch 配置在了 linux 环境下，并且采取 miniconda 作为包管理器。 到官网的 Get started 文档 选择...">
    <link rel="preload" href="/assets/style-Bs8rmnSy.css" as="style"><link rel="stylesheet" href="/assets/style-Bs8rmnSy.css">
    <link rel="modulepreload" href="/assets/app-x5j0Ecu0.js"><link rel="modulepreload" href="/assets/1pytorch.html-0S0_9O9U.js"><link rel="modulepreload" href="/assets/plugin-vue_export-helper-DlAUqK2U.js">
    <link rel="prefetch" href="/assets/index.html-DneO2PlE.js" as="script"><link rel="prefetch" href="/assets/intro.html-Bxpj9BOV.js" as="script"><link rel="prefetch" href="/assets/CPC.html-BWK14AHV.js" as="script"><link rel="prefetch" href="/assets/CSU.html-CZ9c8ubr.js" as="script"><link rel="prefetch" href="/assets/article.html-OdJa6Q8O.js" as="script"><link rel="prefetch" href="/assets/baoyan.html-DVYhbFxm.js" as="script"><link rel="prefetch" href="/assets/diary.html-COW-88PG.js" as="script"><link rel="prefetch" href="/assets/external.html-aRvSZbct.js" as="script"><link rel="prefetch" href="/assets/film_recommend.html-Dy7Jhjy5.js" as="script"><link rel="prefetch" href="/assets/hamlet.html-DkVgBXXP.js" as="script"><link rel="prefetch" href="/assets/index.html-DYXNnolA.js" as="script"><link rel="prefetch" href="/assets/read.html-DALikefc.js" as="script"><link rel="prefetch" href="/assets/software.html-DG4mKZuk.js" as="script"><link rel="prefetch" href="/assets/weakness.html-vFtBBs5g.js" as="script"><link rel="prefetch" href="/assets/web.html-C4ELBHWW.js" as="script"><link rel="prefetch" href="/assets/index.html-CFKoDJmN.js" as="script"><link rel="prefetch" href="/assets/log.html-BgODauGT.js" as="script"><link rel="prefetch" href="/assets/schedule.html-reRvYe9K.js" as="script"><link rel="prefetch" href="/assets/spots.html-B4UUbfyn.js" as="script"><link rel="prefetch" href="/assets/vuepress.html-htRWHPr8.js" as="script"><link rel="prefetch" href="/assets/Linux.html-B_fCmY90.js" as="script"><link rel="prefetch" href="/assets/cpp.html-B5nM0_0a.js" as="script"><link rel="prefetch" href="/assets/git.html-QlqnveG4.js" as="script"><link rel="prefetch" href="/assets/github.html-9Q178OU5.js" as="script"><link rel="prefetch" href="/assets/html.html-BgIY_1AT.js" as="script"><link rel="prefetch" href="/assets/index.html-5Pcq0wNv.js" as="script"><link rel="prefetch" href="/assets/latex.html-D6GDCPAZ.js" as="script"><link rel="prefetch" href="/assets/markdown.html-n0Q_C2rC.js" as="script"><link rel="prefetch" href="/assets/python.html-_QM-400G.js" as="script"><link rel="prefetch" href="/assets/shell.html-CVKVTOhy.js" as="script"><link rel="prefetch" href="/assets/vim.html-Cy15cg3a.js" as="script"><link rel="prefetch" href="/assets/vscode.html-D2AETIa7.js" as="script"><link rel="prefetch" href="/assets/index.html-CTq46yw8.js" as="script"><link rel="prefetch" href="/assets/index.html-DY4EFyLn.js" as="script"><link rel="prefetch" href="/assets/LocalAugment.html-C6Nil8uD.js" as="script"><link rel="prefetch" href="/assets/Seaborn.html-T3QHGNeY.js" as="script"><link rel="prefetch" href="/assets/pandas.html-D7kxPZsh.js" as="script"><link rel="prefetch" href="/assets/web_crawler.html-DBFlrk4z.js" as="script"><link rel="prefetch" href="/assets/websocket.html-CaKvGvKN.js" as="script"><link rel="prefetch" href="/assets/pdf2docx.html-XtN-rueb.js" as="script"><link rel="prefetch" href="/assets/regex.html-D15bNYO-.js" as="script"><link rel="prefetch" href="/assets/10.22.html-DfiWxFdZ.js" as="script"><link rel="prefetch" href="/assets/10.23.html-BCq1VCmy.js" as="script"><link rel="prefetch" href="/assets/10.24.html-BhHoLaSw.js" as="script"><link rel="prefetch" href="/assets/10.25.html-CGZ21VDO.js" as="script"><link rel="prefetch" href="/assets/10.26.html-BxvpX6pY.js" as="script"><link rel="prefetch" href="/assets/10.27.html-5MpEIX4F.js" as="script"><link rel="prefetch" href="/assets/10.28.html-C2Xp_iwS.js" as="script"><link rel="prefetch" href="/assets/10.29.html-CPaC31oy.js" as="script"><link rel="prefetch" href="/assets/10.30.html-DpWGBUuy.js" as="script"><link rel="prefetch" href="/assets/10.31.html-BMHfleFu.js" as="script"><link rel="prefetch" href="/assets/11.1.html-v9niSAxG.js" as="script"><link rel="prefetch" href="/assets/11.2.html-CyIpUa2v.js" as="script"><link rel="prefetch" href="/assets/1.html-CNgHek8i.js" as="script"><link rel="prefetch" href="/assets/2.html-CBtPvP3X.js" as="script"><link rel="prefetch" href="/assets/3.html-CpZhGAoO.js" as="script"><link rel="prefetch" href="/assets/4.html-CyUZhkJg.js" as="script"><link rel="prefetch" href="/assets/5.html-CRrbBN_8.js" as="script"><link rel="prefetch" href="/assets/6.html-VwAPeYZt.js" as="script"><link rel="prefetch" href="/assets/7.html-C0a_EfJb.js" as="script"><link rel="prefetch" href="/assets/8.html-BAgkQyC9.js" as="script"><link rel="prefetch" href="/assets/9.html-mEnC_1z2.js" as="script"><link rel="prefetch" href="/assets/1.html-DMOuN1Yx.js" as="script"><link rel="prefetch" href="/assets/2.html-DBp-zygm.js" as="script"><link rel="prefetch" href="/assets/3.html-BpDTopIj.js" as="script"><link rel="prefetch" href="/assets/4.html-CrEDCxlT.js" as="script"><link rel="prefetch" href="/assets/5.html-DkzjCSxV.js" as="script"><link rel="prefetch" href="/assets/6.html-CDYmLYaV.js" as="script"><link rel="prefetch" href="/assets/7.html-BTqYn7o8.js" as="script"><link rel="prefetch" href="/assets/8.html-CN61COJs.js" as="script"><link rel="prefetch" href="/assets/9.html-3QeYFniD.js" as="script"><link rel="prefetch" href="/assets/2.1linear_regression.html-DsOhFrdg.js" as="script"><link rel="prefetch" href="/assets/2.2FashionMNIST.html-DNOyoCzz.js" as="script"><link rel="prefetch" href="/assets/2.3softmax.html-ClrNmXWG.js" as="script"><link rel="prefetch" href="/assets/2.4MLP.html-qzaq-Vby.js" as="script"><link rel="prefetch" href="/assets/3.1Deeplearning_basic.html-w2yIEMPk.js" as="script"><link rel="prefetch" href="/assets/4.1convolutional_nn_basic.html-CUfjFtVi.js" as="script"><link rel="prefetch" href="/assets/4.2LeNet.html-fXn9DQWa.js" as="script"><link rel="prefetch" href="/assets/4.3AlexNet.html-DWFnIsDx.js" as="script"><link rel="prefetch" href="/assets/4.4VGG.html-Be0yyA1U.js" as="script"><link rel="prefetch" href="/assets/4.5NiN.html-D_HpNIYZ.js" as="script"><link rel="prefetch" href="/assets/4.6GoogleNet.html-BJ-oKBYI.js" as="script"><link rel="prefetch" href="/assets/img.html-Bj_c6aVL.js" as="script"><link rel="prefetch" href="/assets/404.html-BVCvE5MN.js" as="script"><link rel="prefetch" href="/assets/index.html-BCORYUdE.js" as="script"><link rel="prefetch" href="/assets/index.html-BR3Hyzcr.js" as="script"><link rel="prefetch" href="/assets/index.html-DcP802na.js" as="script"><link rel="prefetch" href="/assets/index.html-DqGU_KRR.js" as="script"><link rel="prefetch" href="/assets/index.html-idPZbO8N.js" as="script"><link rel="prefetch" href="/assets/index.html-ByjLwyUm.js" as="script"><link rel="prefetch" href="/assets/index.html-BCMR2EU5.js" as="script"><link rel="prefetch" href="/assets/index.html-FEPdtKi2.js" as="script"><link rel="prefetch" href="/assets/index.html-Cetjctbq.js" as="script"><link rel="prefetch" href="/assets/index.html-DzwtT5eF.js" as="script"><link rel="prefetch" href="/assets/index.html-ByNUzw_L.js" as="script"><link rel="prefetch" href="/assets/index.html-BN02Jm8f.js" as="script"><link rel="prefetch" href="/assets/index.html-Cetg516M.js" as="script"><link rel="prefetch" href="/assets/index.html-CdfvDStA.js" as="script"><link rel="prefetch" href="/assets/index.html-BXcqGsPW.js" as="script"><link rel="prefetch" href="/assets/index.html-Czk9dgrQ.js" as="script"><link rel="prefetch" href="/assets/index.html-B-SiZ6nS.js" as="script"><link rel="prefetch" href="/assets/index.html-DvrUYjHK.js" as="script"><link rel="prefetch" href="/assets/index.html-BFcB_Mfq.js" as="script"><link rel="prefetch" href="/assets/index.html-DOoYuRQb.js" as="script"><link rel="prefetch" href="/assets/index.html-Bs4_DLEk.js" as="script"><link rel="prefetch" href="/assets/index.html-CFdbJBgI.js" as="script"><link rel="prefetch" href="/assets/index.html-D2fUwTjV.js" as="script"><link rel="prefetch" href="/assets/index.html-BvAv5zT7.js" as="script"><link rel="prefetch" href="/assets/index.html-BraNc0XR.js" as="script"><link rel="prefetch" href="/assets/index.html-Bv5yoihv.js" as="script"><link rel="prefetch" href="/assets/index.html-DrLmux3w.js" as="script"><link rel="prefetch" href="/assets/index.html-hFdystIw.js" as="script"><link rel="prefetch" href="/assets/index.html-PKooicVp.js" as="script"><link rel="prefetch" href="/assets/index.html-DYXNnolA.js" as="script"><link rel="prefetch" href="/assets/giscus-7BMGhbDA.js" as="script"><link rel="prefetch" href="/assets/mermaid.core-B8N2Us4j.js" as="script"><link rel="prefetch" href="/assets/photoswipe.esm-SzV8tJDW.js" as="script"><link rel="prefetch" href="/assets/SearchResult-BXZT_uf7.js" as="script">
  </head>
  <body>
    <div id="app"><!--[--><!--[--><!--[--><span tabindex="-1"></span><a href="#main-content" class="vp-skip-link sr-only">跳至主要內容</a><!--]--><div class="theme-container has-toc"><!--[--><header id="navbar" class="vp-navbar"><div class="vp-navbar-start"><button type="button" class="vp-toggle-sidebar-button" title="Toggle Sidebar"><span class="icon"></span></button><!--[--><!----><!--]--><!--[--><a class="route-link vp-brand" href="/"><img class="vp-nav-logo" src="/web_logo.jpg" alt><!----><span class="vp-site-name hide-in-pad">Dream_oyh 的 blog</span></a><!--]--><!--[--><!----><!--]--></div><div class="vp-navbar-center"><!--[--><!----><!--]--><!--[--><nav class="vp-nav-links"><div class="nav-item hide-in-mobile"><a class="route-link nav-link active" href="/code/" aria-label="编程"><span class="font-icon icon iconfont icon-code" style=""></span>编程<!----></a></div><div class="nav-item hide-in-mobile"><a class="route-link nav-link" href="/english/" aria-label="English"><span class="font-icon icon iconfont icon-language" style=""></span>English<!----></a></div><div class="nav-item hide-in-mobile"><a class="route-link nav-link" href="/article/" aria-label="文章"><span class="font-icon icon iconfont icon-Article" style=""></span>文章<!----></a></div><div class="nav-item hide-in-mobile"><a class="route-link nav-link" href="/credit/" aria-label="资料站"><span class="font-icon icon iconfont icon-folder" style=""></span>资料站<!----></a></div><div class="nav-item hide-in-mobile"><a class="route-link nav-link" href="/blog/" aria-label="Blog"><span class="font-icon icon iconfont icon-vue" style=""></span>Blog<!----></a></div></nav><!--]--><!--[--><!----><!--]--></div><div class="vp-navbar-end"><!--[--><!----><!--]--><!--[--><div class="nav-item vp-repo"><a class="vp-repo-link" href="https://github.com/dream-oyh/dream-oyh.github.io" target="_blank" rel="noopener noreferrer" aria-label="GitHub"><svg xmlns="http://www.w3.org/2000/svg" class="icon github-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="github icon" style="width:1.25rem;height:1.25rem;vertical-align:middle;"><path d="M511.957 21.333C241.024 21.333 21.333 240.981 21.333 512c0 216.832 140.544 400.725 335.574 465.664 24.49 4.395 32.256-10.07 32.256-23.083 0-11.69.256-44.245 0-85.205-136.448 29.61-164.736-64.64-164.736-64.64-22.315-56.704-54.4-71.765-54.4-71.765-44.587-30.464 3.285-29.824 3.285-29.824 49.195 3.413 75.179 50.517 75.179 50.517 43.776 75.008 114.816 53.333 142.762 40.79 4.523-31.66 17.152-53.377 31.19-65.537-108.971-12.458-223.488-54.485-223.488-242.602 0-53.547 19.114-97.323 50.517-131.67-5.035-12.33-21.93-62.293 4.779-129.834 0 0 41.258-13.184 134.912 50.346a469.803 469.803 0 0 1 122.88-16.554c41.642.213 83.626 5.632 122.88 16.554 93.653-63.488 134.784-50.346 134.784-50.346 26.752 67.541 9.898 117.504 4.864 129.834 31.402 34.347 50.474 78.123 50.474 131.67 0 188.586-114.73 230.016-224.042 242.09 17.578 15.232 33.578 44.672 33.578 90.454v135.85c0 13.142 7.936 27.606 32.854 22.87C862.25 912.597 1002.667 728.747 1002.667 512c0-271.019-219.648-490.667-490.71-490.667z"></path></svg></a></div><div class="nav-item hide-in-mobile"><button type="button" id="appearance-switch"><svg xmlns="http://www.w3.org/2000/svg" class="icon auto-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="auto icon" style="display:none;"><path d="M512 992C246.92 992 32 777.08 32 512S246.92 32 512 32s480 214.92 480 480-214.92 480-480 480zm0-840c-198.78 0-360 161.22-360 360 0 198.84 161.22 360 360 360s360-161.16 360-360c0-198.78-161.22-360-360-360zm0 660V212c165.72 0 300 134.34 300 300 0 165.72-134.28 300-300 300z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon dark-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="dark icon" style="display:none;"><path d="M524.8 938.667h-4.267a439.893 439.893 0 0 1-313.173-134.4 446.293 446.293 0 0 1-11.093-597.334A432.213 432.213 0 0 1 366.933 90.027a42.667 42.667 0 0 1 45.227 9.386 42.667 42.667 0 0 1 10.24 42.667 358.4 358.4 0 0 0 82.773 375.893 361.387 361.387 0 0 0 376.747 82.774 42.667 42.667 0 0 1 54.187 55.04 433.493 433.493 0 0 1-99.84 154.88 438.613 438.613 0 0 1-311.467 128z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon light-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="light icon" style="display:block;"><path d="M952 552h-80a40 40 0 0 1 0-80h80a40 40 0 0 1 0 80zM801.88 280.08a41 41 0 0 1-57.96-57.96l57.96-58a41.04 41.04 0 0 1 58 58l-58 57.96zM512 752a240 240 0 1 1 0-480 240 240 0 0 1 0 480zm0-560a40 40 0 0 1-40-40V72a40 40 0 0 1 80 0v80a40 40 0 0 1-40 40zm-289.88 88.08-58-57.96a41.04 41.04 0 0 1 58-58l57.96 58a41 41 0 0 1-57.96 57.96zM192 512a40 40 0 0 1-40 40H72a40 40 0 0 1 0-80h80a40 40 0 0 1 40 40zm30.12 231.92a41 41 0 0 1 57.96 57.96l-57.96 58a41.04 41.04 0 0 1-58-58l58-57.96zM512 832a40 40 0 0 1 40 40v80a40 40 0 0 1-80 0v-80a40 40 0 0 1 40-40zm289.88-88.08 58 57.96a41.04 41.04 0 0 1-58 58l-57.96-58a41 41 0 0 1 57.96-57.96z"></path></svg></button></div><!--[--><button type="button" class="search-pro-button" aria-label="搜索"><svg xmlns="http://www.w3.org/2000/svg" class="icon search-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="search icon"><path d="M192 480a256 256 0 1 1 512 0 256 256 0 0 1-512 0m631.776 362.496-143.2-143.168A318.464 318.464 0 0 0 768 480c0-176.736-143.264-320-320-320S128 303.264 128 480s143.264 320 320 320a318.016 318.016 0 0 0 184.16-58.592l146.336 146.368c12.512 12.48 32.768 12.48 45.28 0 12.48-12.512 12.48-32.768 0-45.28"></path></svg><div class="search-pro-placeholder">搜索</div><div class="search-pro-key-hints"><kbd class="search-pro-key">Ctrl</kbd><kbd class="search-pro-key">K</kbd></div></button><!--]--><!--]--><!--[--><!----><!--]--><button type="button" class="vp-toggle-navbar-button" aria-label="Toggle Navbar" aria-expanded="false" aria-controls="nav-screen"><span><span class="vp-top"></span><span class="vp-middle"></span><span class="vp-bottom"></span></span></button></div></header><!----><!--]--><!----><div class="toggle-sidebar-wrapper"><span class="arrow start"></span></div><aside id="sidebar" class="vp-sidebar"><!--[--><!----><!--]--><ul class="vp-sidebar-links"><li><section class="vp-sidebar-group"><p class="vp-sidebar-header active"><span class="font-icon icon iconfont icon-pytorch" style=""></span><span class="vp-sidebar-title">Pytorch 学习笔记</span><!----></p><ul class="vp-sidebar-links"><li><a class="route-link nav-link active vp-sidebar-link vp-sidebar-page active" href="/code/python/pytorch/1pytorch.html" aria-label="Pytorch 基础"><!---->Pytorch 基础<!----></a></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">常见的模型源码实现</span><span class="vp-arrow end"></span></button><!----></section></li><li><a class="route-link nav-link vp-sidebar-link vp-sidebar-page" href="/code/python/pytorch/3.1Deeplearning_basic.html" aria-label="走进深度学习"><!---->走进深度学习<!----></a></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">卷积神经网络</span><span class="vp-arrow end"></span></button><!----></section></li><li><a class="route-link nav-link vp-sidebar-link vp-sidebar-page" href="/code/python/pytorch/img.html" aria-label="神经网络可视化工具"><!---->神经网络可视化工具<!----></a></li></ul></section></li></ul><!--[--><!----><!--]--></aside><!--[--><main id="main-content" class="vp-page"><!--[--><!--[--><!----><!--]--><!----><nav class="vp-breadcrumb disable"></nav><div class="vp-page-title"><h1><!---->Pytorch 的配置与基本操作</h1><div class="page-info"><span class="page-author-info" aria-label="作者🖊" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon author-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="author icon"><path d="M649.6 633.6c86.4-48 147.2-144 147.2-249.6 0-160-128-288-288-288s-288 128-288 288c0 108.8 57.6 201.6 147.2 249.6-121.6 48-214.4 153.6-240 288-3.2 9.6 0 19.2 6.4 25.6 3.2 9.6 12.8 12.8 22.4 12.8h704c9.6 0 19.2-3.2 25.6-12.8 6.4-6.4 9.6-16 6.4-25.6-25.6-134.4-121.6-240-243.2-288z"></path></svg><span><span class="page-author-item">OYH</span></span><span property="author" content="OYH"></span></span><!----><span class="page-date-info" aria-label="写作日期📅" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon calendar-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="calendar icon"><path d="M716.4 110.137c0-18.753-14.72-33.473-33.472-33.473-18.753 0-33.473 14.72-33.473 33.473v33.473h66.993v-33.473zm-334.87 0c0-18.753-14.72-33.473-33.473-33.473s-33.52 14.72-33.52 33.473v33.473h66.993v-33.473zm468.81 33.52H716.4v100.465c0 18.753-14.72 33.473-33.472 33.473a33.145 33.145 0 01-33.473-33.473V143.657H381.53v100.465c0 18.753-14.72 33.473-33.473 33.473a33.145 33.145 0 01-33.473-33.473V143.657H180.6A134.314 134.314 0 0046.66 277.595v535.756A134.314 134.314 0 00180.6 947.289h669.74a134.36 134.36 0 00133.94-133.938V277.595a134.314 134.314 0 00-133.94-133.938zm33.473 267.877H147.126a33.145 33.145 0 01-33.473-33.473c0-18.752 14.72-33.473 33.473-33.473h736.687c18.752 0 33.472 14.72 33.472 33.473a33.145 33.145 0 01-33.472 33.473z"></path></svg><span><!----></span><meta property="datePublished" content="2024-02-16T00:00:00.000Z"></span><!----><span class="page-reading-time-info" aria-label="阅读时间⌛" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon timer-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="timer icon"><path d="M799.387 122.15c4.402-2.978 7.38-7.897 7.38-13.463v-1.165c0-8.933-7.38-16.312-16.312-16.312H256.33c-8.933 0-16.311 7.38-16.311 16.312v1.165c0 5.825 2.977 10.874 7.637 13.592 4.143 194.44 97.22 354.963 220.201 392.763-122.204 37.542-214.893 196.511-220.2 389.397-4.661 5.049-7.638 11.651-7.638 19.03v5.825h566.49v-5.825c0-7.379-2.849-13.981-7.509-18.9-5.049-193.016-97.867-351.985-220.2-389.527 123.24-37.67 216.446-198.453 220.588-392.892zM531.16 450.445v352.632c117.674 1.553 211.787 40.778 211.787 88.676H304.097c0-48.286 95.149-87.382 213.728-88.676V450.445c-93.077-3.107-167.901-81.297-167.901-177.093 0-8.803 6.99-15.793 15.793-15.793 8.803 0 15.794 6.99 15.794 15.793 0 80.261 63.69 145.635 142.01 145.635s142.011-65.374 142.011-145.635c0-8.803 6.99-15.793 15.794-15.793s15.793 6.99 15.793 15.793c0 95.019-73.789 172.82-165.96 177.093z"></path></svg><span>大约 5 分钟</span><meta property="timeRequired" content="PT5M"></span><!----><!----></div><hr></div><div class="vp-toc-placeholder"><aside id="toc"><!--[--><!----><!--]--><div class="vp-toc-header">此页内容<button type="button" class="print-button" title="打印"><svg xmlns="http://www.w3.org/2000/svg" class="icon print-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="print icon"><path d="M819.2 364.8h-44.8V128c0-17.067-14.933-32-32-32H281.6c-17.067 0-32 14.933-32 32v236.8h-44.8C145.067 364.8 96 413.867 96 473.6v192c0 59.733 49.067 108.8 108.8 108.8h44.8V896c0 17.067 14.933 32 32 32h460.8c17.067 0 32-14.933 32-32V774.4h44.8c59.733 0 108.8-49.067 108.8-108.8v-192c0-59.733-49.067-108.8-108.8-108.8zM313.6 160h396.8v204.8H313.6V160zm396.8 704H313.6V620.8h396.8V864zM864 665.6c0 25.6-19.2 44.8-44.8 44.8h-44.8V588.8c0-17.067-14.933-32-32-32H281.6c-17.067 0-32 14.933-32 32v121.6h-44.8c-25.6 0-44.8-19.2-44.8-44.8v-192c0-25.6 19.2-44.8 44.8-44.8h614.4c25.6 0 44.8 19.2 44.8 44.8v192z"></path></svg></button><div class="arrow end"></div></div><div class="vp-toc-wrapper"><ul class="vp-toc-list"><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="/#miniconda-配置-pytorch">Miniconda 配置 Pytorch</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="/#tensor-创建及基本操作">Tensor 创建及基本操作</a></li><li><ul class="vp-toc-list"><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="/#torch-中的乘法">Torch 中的乘法</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="/#索引">索引</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="/#改变形状">改变形状</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="/#线性代数">线性代数</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="/#tensor-转-numpy">Tensor 转 numpy</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="/#numpy-转-tensor">numpy 转 Tensor</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="/#tensor的存储和读取">Tensor的存储和读取</a></li><!----><!--]--></ul></li><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="/#自动求梯度">自动求梯度</a></li><li><ul class="vp-toc-list"><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="/#function对象">Function对象</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="/#梯度">梯度</a></li><!----><!--]--></ul></li><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="/#学习资料">学习资料</a></li><!----><!--]--></ul><div class="vp-toc-marker" style="top:-1.7rem;"></div></div><!--[--><!----><!--]--></aside></div><!--[--><!----><!--]--><div class="theme-hope-content"><h1 id="pytorch-的配置与基本操作" tabindex="-1"><a class="header-anchor" href="#pytorch-的配置与基本操作"><span>Pytorch 的配置与基本操作</span></a></h1><p><a href="https://pytorch.org/" target="_blank" rel="noopener noreferrer">官网<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></p><p><a href="https://tangshusen.me/Dive-into-DL-PyTorch/" target="_blank" rel="noopener noreferrer">《动手学深度学习-Pytorch 版》学习文档<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></p><p><a href="https://zh.d2l.ai/index.html" target="_blank" rel="noopener noreferrer">《动手学深度学习》原书文档<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></p><h2 id="miniconda-配置-pytorch" tabindex="-1"><a class="header-anchor" href="#miniconda-配置-pytorch"><span>Miniconda 配置 Pytorch</span></a></h2><p>由于 poetry 配置 pytorch 很麻烦，所以我把 pytorch 配置在了 linux 环境下，并且采取 miniconda 作为包管理器。</p><p>到<a href="https://pytorch.org/get-started/locally/" target="_blank" rel="noopener noreferrer">官网的 Get started 文档<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a> 选择你的 PC 端配置，可以在终端用<code>nvidia-smi</code>命令查看 PC 的 <code>CUDA</code> 版本。我的配置是：</p><ul><li><code>Pytorch Build</code> Stable(2.2.0)</li><li><code>Your OS</code> linux</li><li><code>Package</code> conda</li><li><code>Lanuage</code> python</li><li><code>Compute Platform</code> CUDA 11.8 运行以下代码来配置环境：</li></ul><div class="language-bash line-numbers-mode" data-ext="sh" data-title="sh"><pre class="language-bash"><code>conda <span class="token function">install</span> pytorch torchvision torchaudio pytorch-cuda<span class="token operator">=</span><span class="token number">11.8</span> <span class="token parameter variable">-c</span> pytorch <span class="token parameter variable">-c</span> nvidia
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><blockquote><p><strong>踩坑：</strong></p><p>如果决定采用<code>conda</code>做包管理器，就老老实实用<code>conda</code>创建虚拟环境，并且在虚拟环境中安装<code>pytorch</code>，GPU 加速版会大概占用 7 ～ 8 GB 空间，请注意磁盘空间的规划。不要像我一样没搞清楚，用了<code>conda</code>管理环境，又反用<code>pip</code>作包管理，最后这个环境整了一天才整出来</p></blockquote><ul><li>安装脚本</li></ul><div class="language-bash line-numbers-mode" data-ext="sh" data-title="sh"><pre class="language-bash"><code>conda create <span class="token parameter variable">-n</span> torch <span class="token assign-left variable">python</span><span class="token operator">=</span><span class="token number">3.9</span>
conda activate torch
conda <span class="token function">install</span> pytorch torchvision torchaudio pytorch-cuda<span class="token operator">=</span><span class="token number">11.8</span> <span class="token parameter variable">-c</span> pytorch <span class="token parameter variable">-c</span> nvidia
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>使用：</p><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="language-python"><code><span class="token keyword">import</span> torch
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><h2 id="tensor-创建及基本操作" tabindex="-1"><a class="header-anchor" href="#tensor-创建及基本操作"><span>Tensor 创建及基本操作</span></a></h2><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="language-python"><code>x <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span>  <span class="token comment"># 指定数据创建 tensor</span>
y <span class="token operator">=</span> torch<span class="token punctuation">.</span>empty<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>  <span class="token comment"># 创建 2x3 空 tensor</span>
x1 <span class="token operator">=</span> torch<span class="token punctuation">.</span>random<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>  <span class="token comment"># 创建 2x3 随机 tensor</span>
x2 <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span><span class="token builtin">long</span><span class="token punctuation">)</span>  <span class="token comment"># 创建 long 型的 0 tensor</span>
x3 <span class="token operator">=</span> torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>  <span class="token comment"># 创建 2x3 全 1 tensor</span>
<span class="token builtin">tuple</span> <span class="token operator">=</span> x1<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># 返回一个 tuple，任何对于 tuple 的操作都可以适用</span>

<span class="token comment"># 加法</span>
x <span class="token operator">+</span> y
torch<span class="token punctuation">.</span>add<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">,</span> out<span class="token operator">=</span>result<span class="token punctuation">)</span> <span class="token comment"># 通过 out 参数指定输出</span>
y<span class="token punctuation">.</span>add_<span class="token punctuation">(</span>x<span class="token punctuation">)</span>  <span class="token comment"># pytorch 的 inplace 操作都有在最后加上下划线</span>

</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="torch-中的乘法" tabindex="-1"><a class="header-anchor" href="#torch-中的乘法"><span>Torch 中的乘法</span></a></h3><p><code>Torch</code>包中包括多种乘法方式，具体的细则可以看<a href="https://www.cnblogs.com/HOMEofLowell/p/15962140.html" target="_blank" rel="noopener noreferrer">这篇博客<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></p><div class="hint-container tip"><p class="hint-container-title">总结</p><ul><li><code>torch.mul()</code> 有广播机制，各个元素相乘</li><li><code>torch.multiply()</code> 与<code>torch.mul()</code>相同</li><li><code>torch.dot()</code>计算两向量的点积</li><li><code>torch.mv()</code> 计算矩阵和向量的乘积（二者一定有一个维度尺寸相同）</li><li><code>torch.mm()</code> 线代中严格的矩阵乘法</li><li><code>torch.bmm()</code> 批量矩阵相乘，比如<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">[</mo><mi>b</mi><mo>×</mo><mi>m</mi><mo>×</mo><mi>n</mi><mo stretchy="false">]</mo><mo>∗</mo><mo stretchy="false">[</mo><mi>b</mi><mo>×</mo><mi>n</mi><mo>×</mo><mi>p</mi><mo stretchy="false">]</mo><mo>=</mo><mo stretchy="false">[</mo><mi>b</mi><mo>×</mo><mi>m</mi><mo>×</mo><mi>p</mi><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">[b\times m\times n] * [b\times n \times p] = [b\times m \times p]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">[</span><span class="mord mathnormal">b</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal">m</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">n</span><span class="mclose">]</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">[</span><span class="mord mathnormal">b</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal">n</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">p</span><span class="mclose">]</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">[</span><span class="mord mathnormal">b</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal">m</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">p</span><span class="mclose">]</span></span></span></span></li><li><code>torch.matmul()</code> 混合型矩阵乘法，会根据输入维度自动匹配，易出错，不建议使用。</li></ul></div><p>的那是该博文中没有明确写<code>torch.matmul()</code>的用法，具体可以查<a href="https://pytorch.org/docs/stable/generated/torch.matmul.html" target="_blank" rel="noopener noreferrer">官方文档<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></p><h3 id="索引" tabindex="-1"><a class="header-anchor" href="#索引"><span>索引</span></a></h3><p>可以采用类似 numpy 的索引，<code>y=x[0,:]</code>，但是索引出的数据与原数据共享内存，修改一个另一个也会改变。</p><h3 id="改变形状" tabindex="-1"><a class="header-anchor" href="#改变形状"><span>改变形状</span></a></h3><p><code>view(*size)</code>可以改变<code>tensor</code>的形状，同理，与原数据共享内存，可以理解为：view 仅仅是改变了对这个张量的观察角度，内部数据并未改变。</p><p>如果需要返回一个新的独立副本，应该先<code>clone</code>再<code>view</code>，即：<code>x.clone().view(3,5)</code>\</p><h3 id="线性代数" tabindex="-1"><a class="header-anchor" href="#线性代数"><span>线性代数</span></a></h3><p>与 MATLAB 语法类似：</p><table><thead><tr><th style="text-align:center;">语法</th><th style="text-align:left;">功能</th></tr></thead><tbody><tr><td style="text-align:center;"><code>trace</code></td><td style="text-align:left;">矩阵的迹</td></tr><tr><td style="text-align:center;"><code>diag</code></td><td style="text-align:left;">对角线元素</td></tr><tr><td style="text-align:center;"><code>triu/tril</code></td><td style="text-align:left;">上三角或下三角矩阵</td></tr><tr><td style="text-align:center;"><code>mm</code></td><td style="text-align:left;">矩阵乘法</td></tr><tr><td style="text-align:center;"><code>t</code></td><td style="text-align:left;">矩阵转置</td></tr><tr><td style="text-align:center;"><code>dot</code></td><td style="text-align:left;">矩阵内积</td></tr><tr><td style="text-align:center;"><code>inverse</code></td><td style="text-align:left;">求逆矩阵</td></tr><tr><td style="text-align:center;"><code>svd</code></td><td style="text-align:left;">奇异值分解</td></tr></tbody></table><h3 id="tensor-转-numpy" tabindex="-1"><a class="header-anchor" href="#tensor-转-numpy"><span>Tensor 转 numpy</span></a></h3><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="language-python"><code>a <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>
b <span class="token operator">=</span> a<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="numpy-转-tensor" tabindex="-1"><a class="header-anchor" href="#numpy-转-tensor"><span>numpy 转 Tensor</span></a></h3><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="language-python"><code>a <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>
b <span class="token operator">=</span> a<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div><div class="hint-container important"><p class="hint-container-title">注意</p><p>以上两种方法得到的 Tensor/numpy 共享内存，改变一个另一个也会改变。</p></div><h3 id="tensor的存储和读取" tabindex="-1"><a class="header-anchor" href="#tensor的存储和读取"><span><code>Tensor</code>的存储和读取</span></a></h3><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="language-python"><code>torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token string">&#39;tensor.pt&#39;</span><span class="token punctuation">)</span>  <span class="token comment"># 保存</span>
x <span class="token operator">=</span> torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">&#39;tensor.pt&#39;</span><span class="token punctuation">)</span>  <span class="token comment"># 读取</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div><blockquote><p><code>Tensor</code>的保存支持多种数据类型，可以是<code>Tensor</code>，也可以是<code>list</code>和<code>dictionary</code>，保存的 <code>Tensor</code> 和读取的 <code>Tensor</code> 具有相同的类型。<code>Tensor</code>会被保存到以<code>.pt</code>为后缀名的文件中。</p></blockquote><h2 id="自动求梯度" tabindex="-1"><a class="header-anchor" href="#自动求梯度"><span>自动求梯度</span></a></h2><h3 id="function对象" tabindex="-1"><a class="header-anchor" href="#function对象"><span><code>Function</code>对象</span></a></h3><p>如果将其属性<code>.requires_grad</code>设置为<code>True</code>，它将开始追踪 (track) 在其上的所有操作（这样就可以利用链式法则进行梯度传播了）。完成计算后，可以调用<code>.backward()</code>来完成所有梯度计算。此<code>Tensor</code>的梯度将累积到<code>.grad</code>属性中。</p><p>如果不想要被继续追踪，可以调用<code>.detach()</code>将其从追踪记录中分离出来，这样就可以防止将来的计算被追踪，这样梯度就传不过去了。此外，还可以用<code>with torch.no_grad()</code>将不想被追踪的操作代码块包裹起来，这种方法在评估模型的时候很常用，因为在评估模型时，我们并不需要计算可训练参数<code>（requires_grad=True）</code>的梯度。</p><p><code>Function</code>是另外一个很重要的类。<code>Tensor</code>和<code>Function</code>互相结合就可以构建一个记录有整个计算过程的有向无环图（DAG）。每个<code>Tensor</code>都有一个<code>.grad_fn</code>属性，该属性即创建该<code>Tensor</code>的<code>Function</code>, 就是说该<code>Tensor</code>是不是通过某些运算得到的，若是，则<code>grad_fn</code>返回一个与这些运算相关的对象，否则是<code>None</code>。</p><div class="hint-container tip"><p class="hint-container-title">提示</p><p>这个 Function 能够反映该<code>Tensor</code>是如何被创建的，<code>print(x.grad_fn)</code>后可以显示其对象名称，包括但不限于：<code>&lt;AddBackward&gt;</code> , <code>&lt;MeanBackward1&gt;</code>, <code>&lt;SumBackward0&gt;</code></p></div><p>所以，梯度链一定是从一个 <code>Tensor(requires_grad=True)</code> 被创建开始的，这个 <code>Tensor</code>被称作叶子节点，Pytorch 提供了 <code>is_leaf()</code> 函数来角读取其是否为叶子节点。</p><h3 id="梯度" tabindex="-1"><a class="header-anchor" href="#梯度"><span>梯度</span></a></h3><p>首先我们得明白在计算流中反向传播的概念，推荐参考<a href="http://colah.github.io/posts/2015-08-Backprop/" target="_blank" rel="noopener noreferrer">colah&#39;s blog 有关反向传播的理解<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></p><div class="hint-container important"><p class="hint-container-title">前向传播与反向传播区别</p><p><strong>前向传播</strong>：只能获得一个输出量对指定自变量的梯度</p><p><strong>反向传播</strong>：遍历一次就可以获得输出量对于计算流图中任意节点的梯度</p></div><p><strong>反向传播</strong>的过程是累加的（这一部分还并没有找到相关原理的文章做支撑，暂且先记住），所以在反向传播之前需要将梯度清零。</p><h4 id="举例说明" tabindex="-1"><a class="header-anchor" href="#举例说明"><span>举例说明</span></a></h4><p>现有如下 python 程序：</p><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="language-python"><code><span class="token keyword">import</span> torch
x <span class="token operator">=</span> torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
y <span class="token operator">=</span> x <span class="token operator">+</span> <span class="token number">2</span>
z <span class="token operator">=</span> y <span class="token operator">*</span> y <span class="token operator">*</span> <span class="token number">3</span>
out <span class="token operator">=</span> z<span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>o</mi><mi>u</mi><mi>t</mi><mo>=</mo><mfrac><mn>1</mn><mn>4</mn></mfrac><msubsup><mi mathvariant="normal">Σ</mi><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mn>4</mn></msubsup><mn>3</mn><mo stretchy="false">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo>+</mo><mn>2</mn><msup><mo stretchy="false">)</mo><mn>2</mn></msup></mrow><annotation encoding="application/x-tex"> out=\frac{1}{4}\Sigma_{i=1}^{4}3(x_i+2)^2 </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6151em;"></span><span class="mord mathnormal">o</span><span class="mord mathnormal">u</span><span class="mord mathnormal">t</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.0074em;vertical-align:-0.686em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3214em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">4</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mord"><span class="mord">Σ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8641em;"><span style="top:-2.453em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">4</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span><span class="mord">3</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.1141em;vertical-align:-0.25em;"></span><span class="mord">2</span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span></span></p><p>现在对<code>out</code>反向传播，并求<code>out</code>对<code>x</code>的梯度（在反向传播之前需要将 x 的梯度清零）。</p><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="language-python"><code>x<span class="token punctuation">.</span>grad<span class="token punctuation">.</span>data<span class="token punctuation">.</span>zero_<span class="token punctuation">(</span><span class="token punctuation">)</span>
out<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>x<span class="token punctuation">.</span>grad<span class="token punctuation">)</span>
<span class="token comment"># 输出</span>
tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">4.5000</span><span class="token punctuation">,</span> <span class="token number">4.5000</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
        <span class="token punctuation">[</span><span class="token number">4.5000</span><span class="token punctuation">,</span> <span class="token number">4.5000</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><blockquote><p>现在看不懂可以不用纠结，因为我也不会（</p></blockquote><h2 id="学习资料" tabindex="-1"><a class="header-anchor" href="#学习资料"><span>学习资料</span></a></h2><ul><li><a href="https://speech.ee.ntu.edu.tw/~tlkagk/courses_ML20.html" target="_blank" rel="noopener noreferrer">台大李宏毅深度学习作业安排<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></li></ul></div><!--[--><!----><!--]--><footer class="page-meta"><div class="meta-item edit-link"><a href="https://github.com/dream-oyh/dream-oyh.github.io/edit/main/src/code/python/pytorch/1pytorch.md" rel="noopener noreferrer" target="_blank" aria-label="编辑此页" class="nav-link label"><!--[--><svg xmlns="http://www.w3.org/2000/svg" class="icon edit-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="edit icon"><path d="M430.818 653.65a60.46 60.46 0 0 1-50.96-93.281l71.69-114.012 7.773-10.365L816.038 80.138A60.46 60.46 0 0 1 859.225 62a60.46 60.46 0 0 1 43.186 18.138l43.186 43.186a60.46 60.46 0 0 1 0 86.373L588.879 565.55l-8.637 8.637-117.466 68.234a60.46 60.46 0 0 1-31.958 11.229z"></path><path d="M728.802 962H252.891A190.883 190.883 0 0 1 62.008 771.98V296.934a190.883 190.883 0 0 1 190.883-192.61h267.754a60.46 60.46 0 0 1 0 120.92H252.891a69.962 69.962 0 0 0-69.098 69.099V771.98a69.962 69.962 0 0 0 69.098 69.098h475.911A69.962 69.962 0 0 0 797.9 771.98V503.363a60.46 60.46 0 1 1 120.922 0V771.98A190.883 190.883 0 0 1 728.802 962z"></path></svg><!--]-->编辑此页<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span><!----></a></div><div class="meta-item git-info"><div class="update-time"><span class="label">上次编辑于: </span><!----></div><div class="contributors"><span class="label">贡献者: </span><!--[--><!--[--><span class="contributor" title="email: 1399541701@qq.com">dream_linux</span>,<!--]--><!--[--><span class="contributor" title="email: 1399541701@qq.com">dream同学0</span><!--]--><!--]--></div></div></footer><!----><div id="vp-comment" class="giscus-wrapper input-top" style="display:block;"><svg xmlns="http://www.w3.org/2000/svg" width="32" height="32" preserveAspectRatio="xMidYMid" viewBox="0 0 100 100"><circle cx="28" cy="75" r="11" fill="currentColor"><animate attributeName="fill-opacity" begin="0s" dur="1s" keyTimes="0;0.2;1" repeatCount="indefinite" values="0;1;1"></animate></circle><path fill="none" stroke="#88baf0" stroke-width="10" d="M28 47a28 28 0 0 1 28 28"><animate attributeName="stroke-opacity" begin="0.1s" dur="1s" keyTimes="0;0.2;1" repeatCount="indefinite" values="0;1;1"></animate></path><path fill="none" stroke="#88baf0" stroke-width="10" d="M28 25a50 50 0 0 1 50 50"><animate attributeName="stroke-opacity" begin="0.2s" dur="1s" keyTimes="0;0.2;1" repeatCount="indefinite" values="0;1;1"></animate></path></svg></div><!--[--><!----><!--]--><!--]--></main><!--]--><footer class="vp-footer-wrapper"><div class="vp-footer">希望你能在此有所收获</div><div class="vp-copyright">Copyright © 2024 OYH </div></footer></div><!--]--><!--[--><!----><!----><!--]--><!--]--></div>
    <script type="module" src="/assets/app-x5j0Ecu0.js" defer></script>
  </body>
</html>
