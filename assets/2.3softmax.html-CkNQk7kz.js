import{_ as a}from"./plugin-vue_export-helper-DlAUqK2U.js";import{r as t,o as p,c as e,d as n,b as o,a as c,e as i}from"./app-ByFM7qA5.js";const l={},u=n("h1",{id:"softmax-回归实现",tabindex:"-1"},[n("a",{class:"header-anchor",href:"#softmax-回归实现"},[n("span",null,"softmax 回归实现")])],-1),r={href:"https://tangshusen.me/Dive-into-DL-PyTorch/#/chapter03_DL-basics/3.4_softmax-regression",target:"_blank",rel:"noopener noreferrer"},k=i(`<h2 id="导入所需的包和库" tabindex="-1"><a class="header-anchor" href="#导入所需的包和库"><span>导入所需的包和库</span></a></h2><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="language-python"><code><span class="token keyword">import</span> torch
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn
<span class="token keyword">import</span> d2lzh_pytorch <span class="token keyword">as</span> d2l
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="获取和读取数据" tabindex="-1"><a class="header-anchor" href="#获取和读取数据"><span>获取和读取数据</span></a></h2><p>设置<code>batch_size</code>大小为<code>256</code>，利用<code>Data.DataLoader</code>读取 fashion_mnist 数据集数据。</p><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="language-python"><code><span class="token comment"># 本函数已封装在 d2lzh 包中</span>
<span class="token keyword">def</span> <span class="token function">load_data_fashion_mnist</span><span class="token punctuation">(</span>batch_size<span class="token punctuation">,</span> root<span class="token operator">=</span><span class="token string">&#39;./Datasets/&#39;</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">&quot;&quot;&quot;Download the fashion mnist dataset and then load into memory.&quot;&quot;&quot;</span>
    transform <span class="token operator">=</span> transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span>
    mnist_train <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>FashionMNIST<span class="token punctuation">(</span>root<span class="token operator">=</span>root<span class="token punctuation">,</span> train<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> transform<span class="token operator">=</span>transform<span class="token punctuation">)</span>
    mnist_test <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>FashionMNIST<span class="token punctuation">(</span>root<span class="token operator">=</span>root<span class="token punctuation">,</span> train<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> transform<span class="token operator">=</span>transform<span class="token punctuation">)</span>
    train_iter <span class="token operator">=</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>mnist_train<span class="token punctuation">,</span> batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> num_workers<span class="token operator">=</span>num_workers<span class="token punctuation">)</span>
    test_iter <span class="token operator">=</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>mnist_test<span class="token punctuation">,</span> batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> num_workers<span class="token operator">=</span>num_workers<span class="token punctuation">)</span>

    <span class="token keyword">return</span> train_iter<span class="token punctuation">,</span> test_iter

batch_size <span class="token operator">=</span> <span class="token number">256</span>
train_iter<span class="token punctuation">,</span> test_iter <span class="token operator">=</span> d2l<span class="token punctuation">.</span>load_data_fashion_mnist<span class="token punctuation">(</span>batch_size<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="定义和初始化模型" tabindex="-1"><a class="header-anchor" href="#定义和初始化模型"><span>定义和初始化模型</span></a></h2><p>由于从<code>DataLoader</code>读出的数据尺寸为<code>[batch_size x channels x height x width]</code>，是一个四维张量，故我们需要把<code>features</code>的尺寸 reshape 到<code>[batch_size x 28*28]</code>，然后才能输入到全连接层中。但是相较于传统的<code>reshape</code>或者<code>view()</code>函数，更聪明的方法是，定义一个<code>nn.Module</code>的继承类作为压平<code>features</code>尺寸的特殊层，该层的前馈函数就是改变 x 的尺寸。</p><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="language-python"><code><span class="token keyword">class</span> <span class="token class-name">FlattenLayer</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>FlattenLayer<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> x<span class="token punctuation">.</span>view<span class="token punctuation">(</span>x<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>


net <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>FlattenLayer<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>num_inputs<span class="token punctuation">,</span> num_outputs<span class="token punctuation">)</span><span class="token punctuation">)</span>
init<span class="token punctuation">.</span>normal_<span class="token punctuation">(</span>net<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>weight<span class="token punctuation">,</span> mean<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> std<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">)</span>
init<span class="token punctuation">.</span>constant_<span class="token punctuation">(</span>net<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>bias<span class="token punctuation">,</span> val<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="定义交叉熵函数" tabindex="-1"><a class="header-anchor" href="#定义交叉熵函数"><span>定义交叉熵函数</span></a></h2><p>softmax 回归中我们定义交叉熵函数作为损失函数。</p><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="language-python"><code>loss <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><h2 id="定义优化算法" tabindex="-1"><a class="header-anchor" href="#定义优化算法"><span>定义优化算法</span></a></h2><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="language-python"><code>optim <span class="token operator">=</span> optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>net<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><h2 id="训练模型" tabindex="-1"><a class="header-anchor" href="#训练模型"><span>训练模型</span></a></h2><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="language-python"><code>num_epochs <span class="token operator">=</span> <span class="token number">5</span>
<span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>num_epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">for</span> X<span class="token punctuation">,</span> y <span class="token keyword">in</span> train_iter<span class="token punctuation">:</span>
        output <span class="token operator">=</span> net<span class="token punctuation">(</span>X<span class="token punctuation">)</span>
        l <span class="token operator">=</span> loss<span class="token punctuation">(</span>output<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
        optim<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
        l<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
        optim<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&quot;epoch:</span><span class="token interpolation"><span class="token punctuation">{</span>epoch<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">}</span></span><span class="token string">,loss:</span><span class="token interpolation"><span class="token punctuation">{</span>l<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span></span><span class="token string">&quot;</span></span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>在 softmax 回归中，我们需要计算训练准确度，因此，对训练模型算法稍作调整：</p><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="language-python"><code><span class="token keyword">def</span> <span class="token function">evaluate_accuracy</span><span class="token punctuation">(</span>data_iter<span class="token punctuation">,</span> net<span class="token punctuation">)</span><span class="token punctuation">:</span>
    acc_sum<span class="token punctuation">,</span> n <span class="token operator">=</span> <span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">0</span>
    <span class="token keyword">for</span> X<span class="token punctuation">,</span> y <span class="token keyword">in</span> data_iter<span class="token punctuation">:</span>
        acc_sum <span class="token operator">+=</span> <span class="token punctuation">(</span>net<span class="token punctuation">(</span>X<span class="token punctuation">)</span><span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">==</span> y<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>
        n <span class="token operator">+=</span> y<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
    <span class="token keyword">return</span> acc_sum <span class="token operator">/</span> n


num_epochs <span class="token operator">=</span> <span class="token number">5</span>
<span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>num_epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>
    train_loss_sum <span class="token operator">=</span> <span class="token number">0</span>
    train_acc_sum <span class="token operator">=</span> <span class="token number">0</span>
    n <span class="token operator">=</span> <span class="token number">0</span>
    <span class="token keyword">for</span> X<span class="token punctuation">,</span> y <span class="token keyword">in</span> train_iter<span class="token punctuation">:</span>
        output <span class="token operator">=</span> net<span class="token punctuation">(</span>X<span class="token punctuation">)</span>
        l <span class="token operator">=</span> loss<span class="token punctuation">(</span>output<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
        optim<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
        l<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
        optim<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
        train_loss_sum <span class="token operator">+=</span> l<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>
        train_acc_sum <span class="token operator">+=</span> <span class="token punctuation">(</span>output<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">==</span> y<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>
        n <span class="token operator">+=</span> y<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
    test_acc <span class="token operator">=</span> evaluate_accuracy<span class="token punctuation">(</span>test_iter<span class="token punctuation">,</span> net<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>
        <span class="token string-interpolation"><span class="token string">f&quot;epoch:</span><span class="token interpolation"><span class="token punctuation">{</span>epoch<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">}</span></span><span class="token string">,loss:</span><span class="token interpolation"><span class="token punctuation">{</span>train_loss_sum<span class="token operator">/</span>n<span class="token punctuation">}</span></span><span class="token string">,train acc:</span><span class="token interpolation"><span class="token punctuation">{</span>train_acc_sum<span class="token operator">/</span>n<span class="token punctuation">}</span></span><span class="token string">,test acc:</span><span class="token interpolation"><span class="token punctuation">{</span>test_acc<span class="token punctuation">}</span></span><span class="token string">&quot;</span></span>
    <span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="测试模型" tabindex="-1"><a class="header-anchor" href="#测试模型"><span>测试模型</span></a></h2><p>现在通过训练，我们就得到了一个模型网络，直接将待测试数据输入网络，即可得到预测结果。</p><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="language-python"><code>X<span class="token punctuation">,</span>y <span class="token operator">=</span> <span class="token builtin">next</span><span class="token punctuation">(</span><span class="token builtin">iter</span><span class="token punctuation">(</span>test_iter<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># 通过构建迭代器获得下一批测试数据</span>

true_label <span class="token operator">=</span> d2l<span class="token punctuation">.</span>get_fashion_mnist_labels<span class="token punctuation">(</span>y<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
pred_label <span class="token operator">=</span> d2l<span class="token punctuation">.</span>get_fashion_mnist_labels<span class="token punctuation">(</span>net<span class="token punctuation">(</span>X<span class="token punctuation">)</span><span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
titles <span class="token operator">=</span> <span class="token punctuation">[</span>true<span class="token operator">+</span><span class="token string">&#39;\\n&#39;</span><span class="token operator">+</span>pred <span class="token keyword">for</span> true<span class="token punctuation">,</span>pred <span class="token keyword">in</span> <span class="token builtin">zip</span><span class="token punctuation">(</span>true_label<span class="token punctuation">,</span>pred_label<span class="token punctuation">)</span><span class="token punctuation">]</span>
d2l<span class="token punctuation">.</span>show_fashion_mnist<span class="token punctuation">(</span>X<span class="token punctuation">[</span><span class="token number">10</span><span class="token punctuation">:</span><span class="token number">20</span><span class="token punctuation">]</span><span class="token punctuation">,</span>titles<span class="token punctuation">[</span><span class="token number">10</span><span class="token punctuation">:</span><span class="token number">20</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token comment"># 显示前十个数据;</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div>`,20);function d(m,v){const s=t("ExternalLinkIcon");return p(),e("div",null,[u,n("p",null,[n("a",r,[o("softmax 原理介绍"),c(s)])]),k])}const _=a(l,[["render",d],["__file","2.3softmax.html.vue"]]),y=JSON.parse('{"path":"/code/python/pytorch/2.3softmax.html","title":"softmax 回归实现","lang":"zh-CN","frontmatter":{"date":"2024-02-17T00:00:00.000Z","description":"softmax 回归实现 softmax 原理介绍 导入所需的包和库 获取和读取数据 设置batch_size大小为256，利用Data.DataLoader读取 fashion_mnist 数据集数据。 定义和初始化模型 由于从DataLoader读出的数据尺寸为[batch_size x channels x height x width]，是一个...","head":[["meta",{"property":"og:url","content":"https://dream-oyh.github.io/code/python/pytorch/2.3softmax.html"}],["meta",{"property":"og:site_name","content":"Dream_oyh 的 blog"}],["meta",{"property":"og:title","content":"softmax 回归实现"}],["meta",{"property":"og:description","content":"softmax 回归实现 softmax 原理介绍 导入所需的包和库 获取和读取数据 设置batch_size大小为256，利用Data.DataLoader读取 fashion_mnist 数据集数据。 定义和初始化模型 由于从DataLoader读出的数据尺寸为[batch_size x channels x height x width]，是一个..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2024-02-18T13:18:03.000Z"}],["meta",{"property":"article:author","content":"OYH"}],["meta",{"property":"article:published_time","content":"2024-02-17T00:00:00.000Z"}],["meta",{"property":"article:modified_time","content":"2024-02-18T13:18:03.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"softmax 回归实现\\",\\"image\\":[\\"\\"],\\"datePublished\\":\\"2024-02-17T00:00:00.000Z\\",\\"dateModified\\":\\"2024-02-18T13:18:03.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"OYH\\",\\"email\\":\\"19859860010@163.com\\"}]}"]]},"headers":[{"level":2,"title":"导入所需的包和库","slug":"导入所需的包和库","link":"#导入所需的包和库","children":[]},{"level":2,"title":"获取和读取数据","slug":"获取和读取数据","link":"#获取和读取数据","children":[]},{"level":2,"title":"定义和初始化模型","slug":"定义和初始化模型","link":"#定义和初始化模型","children":[]},{"level":2,"title":"定义交叉熵函数","slug":"定义交叉熵函数","link":"#定义交叉熵函数","children":[]},{"level":2,"title":"定义优化算法","slug":"定义优化算法","link":"#定义优化算法","children":[]},{"level":2,"title":"训练模型","slug":"训练模型","link":"#训练模型","children":[]},{"level":2,"title":"测试模型","slug":"测试模型","link":"#测试模型","children":[]}],"git":{"createdTime":1708138728000,"updatedTime":1708262283000,"contributors":[{"name":"dream_linux","email":"1399541701@qq.com","commits":2}]},"readingTime":{"minutes":1.98,"words":593},"filePathRelative":"code/python/pytorch/2.3softmax.md","localizedDate":"2024年2月17日","excerpt":"\\n<p><a href=\\"https://tangshusen.me/Dive-into-DL-PyTorch/#/chapter03_DL-basics/3.4_softmax-regression\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">softmax 原理介绍</a></p>\\n<h2>导入所需的包和库</h2>\\n<div class=\\"language-python\\" data-ext=\\"py\\" data-title=\\"py\\"><pre class=\\"language-python\\"><code><span class=\\"token keyword\\">import</span> torch\\n<span class=\\"token keyword\\">import</span> torch<span class=\\"token punctuation\\">.</span>nn <span class=\\"token keyword\\">as</span> nn\\n<span class=\\"token keyword\\">import</span> d2lzh_pytorch <span class=\\"token keyword\\">as</span> d2l\\n</code></pre></div>","autoDesc":true}');export{_ as comp,y as data};
