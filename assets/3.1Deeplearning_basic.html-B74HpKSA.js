import{_ as c}from"./plugin-vue_export-helper-DlAUqK2U.js";import{r as o,o as i,c as u,d as n,b as s,a,w as p,e as l}from"./app-HzmxQN1V.js";const r={},m=l(`<h1 id="深度学习基础" tabindex="-1"><a class="header-anchor" href="#深度学习基础"><span>深度学习基础</span></a></h1><h2 id="模型构建" tabindex="-1"><a class="header-anchor" href="#模型构建"><span>模型构建</span></a></h2><p>根据之前章节，我们已经能够发现，利用<code>nn.Module</code>和<code>nn.Sequential</code>可以很方便地构建模型，并且<code>nn.Sequential</code>本身也是<code>nn.Module</code>的一个继承类。所以，通过<code>nn.Module</code>来构建继承类也是非常通用的模型构建方式，一般来说，在继承类中我们会重载<code>nn.Module</code>的<code>forward()</code>函数，比如说我们可以通过继承类很容易地构建一个多层感知机模型：</p><blockquote><p>forward() 函数的目的在于，定义模型的前向计算，如何根据输入的数据 <code>x</code>计算出所需要的模型输出 <code>y</code>。</p></blockquote><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="language-python"><code><span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn
<span class="token keyword">class</span> <span class="token class-name">MLP</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
  <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span><span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token builtin">super</span><span class="token punctuation">(</span>MLP<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token operator">**</span>kwargs<span class="token punctuation">)</span>
    self<span class="token punctuation">.</span>hidden <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">784</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">)</span>  <span class="token comment"># 隐藏层</span>
    self<span class="token punctuation">.</span>act <span class="token operator">=</span> nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span>
    self<span class="token punctuation">.</span>output <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span>  <span class="token comment"># 输出层</span>
  <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
    a <span class="token operator">=</span> self<span class="token punctuation">.</span>act<span class="token punctuation">(</span>self<span class="token punctuation">.</span>hidden<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>
    renturn self<span class="token punctuation">.</span>output<span class="token punctuation">(</span>a<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>而<code>pytorch</code>库会自动生成<code>backward</code>反向传播函数</p><h3 id="nn-module的子类" tabindex="-1"><a class="header-anchor" href="#nn-module的子类"><span><code>nn.Module</code>的子类</span></a></h3><p><code>Pytorch</code>提供了丰富的<code>nn.Module</code>子类，我们可以直接使用这些子类来构建模型，比如<code>nn.Sequential</code>，<code>nn.Moudlelist</code>，<code>nn.ModuleDict</code>等，这些子类都继承自<code>nn.Module</code>。</p><h4 id="nn-sequential类" tabindex="-1"><a class="header-anchor" href="#nn-sequential类"><span><code>nn.Sequential</code>类</span></a></h4>`,9),d=n("code",null,"nn.Sequential",-1),h=n("code",null,"OrderedDict",-1),k=n("code",null,"add_module()",-1),g=l(`<h4 id="nn-modulelist类" tabindex="-1"><a class="header-anchor" href="#nn-modulelist类"><span><code>nn.ModuleList</code>类</span></a></h4><p>该类接受一个模块列表作为输入，如：</p><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="language-python"><code>net <span class="token operator">=</span> nn<span class="token punctuation">.</span>Modulelist<span class="token punctuation">(</span><span class="token punctuation">[</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
net<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">[</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div><p>该类的索引和列表类似，并且支持类似列表的<code>.append()</code>和<code>.extend()</code>操作。</p><div class="hint-container tip"><p class="hint-container-title">注意</p><p>不同于<code>nn.Sequential</code>，<code>nn.ModuleList</code>类并不支持<code>forward()</code>函数，而是需要自己定义。但是区分于传统<code>列表</code>，<code>nn.ModuleList</code>又能够生成参数，可以通过<code>nn.MoudleList.parameters()</code>来访问参数，所以该类只能认为是一个模块的容器，而并不是一个新的网络。</p></div><h4 id="nn-moduledict类" tabindex="-1"><a class="header-anchor" href="#nn-moduledict类"><span><code>nn.ModuleDict</code>类</span></a></h4><p>该类接受一个模块字典作为输入，也可以像字典一样操作。</p><p>和<code>nn.ModuleList</code>与<code>list</code>的关系一样，<code>nn.ModuleDict</code>没有定义<code>forward()</code>函数，需要自己定义，并且他较传统字典，他包括了模型所需要的权重参数。</p><ul><li>由于三者均为<code>nn..Module</code>的子类，所以可以互相嵌套调用。</li></ul>`,9),v={class:"hint-container important"},b=n("p",{class:"hint-container-title"},"不要局限了 Module 的用法",-1),y=n("code",null,"FlattenLayer",-1),_=n("code",null,"reshape",-1),f=n("code",null,"Module",-1),w=n("code",null,"Module",-1),x=n("code",null,"forward",-1),M=n("code",null,"Action",-1),L={href:"https://tangshusen.me/Dive-into-DL-PyTorch/#/chapter03_DL-basics/3.13_dropout?id=_3131-%E6%96%B9%E6%B3%95",target:"_blank",rel:"noopener noreferrer"},D=n("code",null,"nn.Module",-1),U=n("code",null,"nn.Dropout(drop_prob)",-1),I=n("code",null,"Dropout",-1),z=l(`<h2 id="访问模型参数" tabindex="-1"><a class="header-anchor" href="#访问模型参数"><span>访问模型参数</span></a></h2><p>对于用<code>Sequential</code>类构建的网络，我们可以简单地用<code>net[i]</code>调用指定层（i 的索引从 0 开始），用<code>parameters()</code>和<code>name_parameters()</code>调用参数，并且返回一个参数迭代器。</p><p>如：</p><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="language-python"><code>net <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">for</span> params <span class="token keyword">in</span> net<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span>：
    <span class="token keyword">print</span><span class="token punctuation">(</span>params<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment"># 输出结果为：</span>
torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">10</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

<span class="token keyword">for</span> name<span class="token punctuation">,</span>params <span class="token keyword">in</span> net<span class="token punctuation">.</span>named_parameters<span class="token punctuation">(</span><span class="token punctuation">)</span>：
    <span class="token keyword">print</span><span class="token punctuation">(</span>name<span class="token punctuation">,</span>params<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment"># name_parameters() 输出带有名字的参数列表，输出结果为：</span>
<span class="token number">0</span><span class="token punctuation">.</span>weight torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token number">0</span><span class="token punctuation">.</span>bias torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">10</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token number">2</span><span class="token punctuation">.</span>weight torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token number">2</span><span class="token punctuation">.</span>bias torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><div class="hint-container tip"><p class="hint-container-title">params 的对象类型</p><p><code>params</code>本质上也是一个<code>Tesnor</code>张量，其类型为<code>torch.nn.parameter.Parameter</code>，可以与<code>Tensor</code>有同样的操作，如<code>.data</code>读取数据，<code>.grad</code>求取梯度。</p></div><h2 id="初始化模型参数" tabindex="-1"><a class="header-anchor" href="#初始化模型参数"><span>初始化模型参数</span></a></h2><p>一般来说，我们需要对权重赋予正态分布的初始化，对偏差清零，赋予常数的初始化，我们可以通过参数的名字对参数进行区分：</p><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="language-python"><code><span class="token keyword">for</span> name<span class="token punctuation">,</span> param <span class="token keyword">in</span> net<span class="token punctuation">.</span>named_parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
  <span class="token keyword">if</span> <span class="token string">&quot;weight&quot;</span> <span class="token keyword">in</span> name<span class="token punctuation">:</span>
    init<span class="token punctuation">.</span>normal_<span class="token punctuation">(</span>param<span class="token punctuation">,</span>mean<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span>std<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">)</span>
  <span class="token keyword">if</span> <span class="token string">&quot;bias&quot;</span> <span class="token keyword">in</span> name<span class="token punctuation">:</span>
    init<span class="token punctuation">.</span>constant_<span class="token punctuation">(</span>param<span class="token punctuation">,</span>val <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="自定义初始化方法" tabindex="-1"><a class="header-anchor" href="#自定义初始化方法"><span>自定义初始化方法</span></a></h3><p><code>pytorch</code>中对一个张量初始化是不记录梯度的，所以我们需要在<code>with tensor.no_grad()</code>环境里配置，比如说初始化使得整体分布于（0,0.01）的标准正态分布，但是权重有一半的概率初始化为 0，另一半参数大于 0。可以这么定义初始化函数：</p><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="language-python"><code><span class="token keyword">def</span> <span class="token function">init_weight_</span><span class="token punctuation">(</span>tensor<span class="token punctuation">,</span> mean<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> std<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
  <span class="token keyword">with</span> tensor<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    tensor<span class="token punctuation">.</span>normal_<span class="token punctuation">(</span>mean<span class="token punctuation">,</span>std<span class="token punctuation">)</span>
    tensor <span class="token operator">*=</span> <span class="token punctuation">(</span>tensor<span class="token operator">&gt;</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token keyword">for</span> name<span class="token punctuation">,</span> param <span class="token keyword">in</span> net<span class="token punctuation">.</span>named_parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
  <span class="token keyword">if</span> <span class="token string">&quot;weight&quot;</span> <span class="token keyword">in</span> name<span class="token punctuation">:</span>
    init_weight_<span class="token punctuation">(</span>param<span class="token punctuation">,</span>mean<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span>std<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">)</span>
</code></pre><div class="highlight-lines"><br><div class="highlight-line"> </div><br><div class="highlight-line"> </div><br><br><br><br></div><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="共享模型参数" tabindex="-1"><a class="header-anchor" href="#共享模型参数"><span>共享模型参数</span></a></h3><p>只要保证两个层来自同一个数据寄存器（或者说来自同一个变量），即可保证参数共享。如：</p><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="language-python"><code>linear <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">)</span>
net <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>linear<span class="token punctuation">,</span>linear<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token builtin">id</span><span class="token punctuation">(</span>net<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">==</span><span class="token builtin">id</span><span class="token punctuation">(</span>net<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token builtin">id</span><span class="token punctuation">(</span>net<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>weight<span class="token punctuation">)</span><span class="token operator">==</span><span class="token builtin">id</span><span class="token punctuation">(</span>net<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>weight<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment"># 输出</span>
<span class="token boolean">True</span>
<span class="token boolean">True</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><div class="hint-container tip"><p class="hint-container-title">值得注意的是</p><p>在反向传播过程中，这两层的参数梯度是累加的。</p></div><h2 id="自定义层" tabindex="-1"><a class="header-anchor" href="#自定义层"><span>自定义层</span></a></h2><p>如前所说，<code>Module</code>这玩意是很宽泛的，可以继承它然后来构建很多自定义层。自定义层又分为两种：</p><ul><li>不带模型参数的自定义层</li><li>带模型参数的自定义层</li></ul><blockquote><p>不带模型参数的自定义层好理解，类似<code>FlattenLayer</code>就是一个不带模型参数的自定义层</p></blockquote><p><strong>本文着重讨论带模型参数的自定义层。</strong></p><p>由前文可知，模型参数应该是<code>Parameter</code>类型的，也是<code>Tensor</code>的子类，所以我们在继承类的<code>__init__()</code>函数中，应该通过<code>nn.Parameter()</code>来定义模型参数（定义方式与<code>Tensor</code>一致），指定的参数名字也会被<code>name_parameters()</code>读取。也可以通过<code>ParameterList()</code>或<code>ParameterDict()</code>类型来定义（输入一个<code>Parameter</code>列表或字典），举例如下：</p><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="language-python"><code><span class="token keyword">class</span> <span class="token class-name">MyDense</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>MyDense<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>params <span class="token operator">=</span> nn<span class="token punctuation">.</span>ParameterList<span class="token punctuation">(</span><span class="token punctuation">[</span>nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>params<span class="token punctuation">.</span>append<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>params<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            x <span class="token operator">=</span> torch<span class="token punctuation">.</span>mm<span class="token punctuation">(</span>x<span class="token punctuation">,</span> self<span class="token punctuation">.</span>params<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> x
net <span class="token operator">=</span> MyDense<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>net<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="torchvision-transforms实例" tabindex="-1"><a class="header-anchor" href="#torchvision-transforms实例"><span><code>Torchvision.transforms</code>实例</span></a></h2><p><code>torchvision.transforms</code>提供了多种实例对数据集进行操作，多用于数据增强、图像增广。</p><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="language-python"><code>torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>Resize<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment"># 提供了重置大小转换器</span>
torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>CenterCrop<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment"># 提供了中心裁剪转换器</span>
torchvision<span class="token punctuation">.</span>transfotms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment"># 提供了将数据转换为\`Tensor\`的转换器</span>
torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>Normalize<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment"># 提供了将数据归一化的转换器</span>

<span class="token comment"># 以上转换器可以按顺序放进列表结构中，通过\`Compose\`实例串联使用</span>
torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span>trans<span class="token punctuation">:</span> <span class="token builtin">list</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div>`,25),q=n("code",null,"AlexNet",-1),O=n("h2",{id:"深度学习相关概念",tabindex:"-1"},[n("a",{class:"header-anchor",href:"#深度学习相关概念"},[n("span",null,"深度学习相关概念")])],-1),A=n("h3",{id:"感受野",tabindex:"-1"},[n("a",{class:"header-anchor",href:"#感受野"},[n("span",null,"感受野")])],-1),E={href:"https://zhuanlan.zhihu.com/p/28492837",target:"_blank",rel:"noopener noreferrer"},S=n("p",null,"在一定的感受野下，我们愿意选择较小的卷积核，以此来获得更深的网络深度，学习更为复杂的全局特征，同时更小的卷积核意味着我们可以在较少的计算量下完成特征提取。",-1),B=n("h3",{id:"iou-交并比",tabindex:"-1"},[n("a",{class:"header-anchor",href:"#iou-交并比"},[n("span",null,"IOU（交并比）")])],-1),T={href:"https://zhuanlan.zhihu.com/p/111013447",target:"_blank",rel:"noopener noreferrer"},P=n("p",null,"IOU 其实是 Intersection over Union 的简称，也叫‘交并比’。IoU 在目标检测以及语义分割中，都有着至关重要的作用。",-1),C=n("p",{class:"katex-block"},[n("span",{class:"katex-display"},[n("span",{class:"katex"},[n("span",{class:"katex-mathml"},[n("math",{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},[n("semantics",null,[n("mrow",null,[n("mi",null,"I"),n("mi",null,"O"),n("mi",null,"U"),n("mo",null,"="),n("mfrac",null,[n("mrow",null,[n("mi",{mathvariant:"normal"},"∣"),n("mi",null,"A"),n("mo",null,"∩"),n("mi",null,"B"),n("mi",{mathvariant:"normal"},"∣")]),n("mrow",null,[n("mi",{mathvariant:"normal"},"∣"),n("mi",null,"A"),n("mo",null,"∪"),n("mi",null,"B"),n("mi",{mathvariant:"normal"},"∣")])])]),n("annotation",{encoding:"application/x-tex"}," IOU=\\frac{|A\\cap B|}{|A\\cup B|} ")])])]),n("span",{class:"katex-html","aria-hidden":"true"},[n("span",{class:"base"},[n("span",{class:"strut",style:{height:"0.6833em"}}),n("span",{class:"mord mathnormal",style:{"margin-right":"0.07847em"}},"I"),n("span",{class:"mord mathnormal",style:{"margin-right":"0.02778em"}},"O"),n("span",{class:"mord mathnormal",style:{"margin-right":"0.10903em"}},"U"),n("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),n("span",{class:"mrel"},"="),n("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),n("span",{class:"base"},[n("span",{class:"strut",style:{height:"2.363em","vertical-align":"-0.936em"}}),n("span",{class:"mord"},[n("span",{class:"mopen nulldelimiter"}),n("span",{class:"mfrac"},[n("span",{class:"vlist-t vlist-t2"},[n("span",{class:"vlist-r"},[n("span",{class:"vlist",style:{height:"1.427em"}},[n("span",{style:{top:"-2.314em"}},[n("span",{class:"pstrut",style:{height:"3em"}}),n("span",{class:"mord"},[n("span",{class:"mord"},"∣"),n("span",{class:"mord mathnormal"},"A"),n("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),n("span",{class:"mbin"},"∪"),n("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),n("span",{class:"mord mathnormal",style:{"margin-right":"0.05017em"}},"B"),n("span",{class:"mord"},"∣")])]),n("span",{style:{top:"-3.23em"}},[n("span",{class:"pstrut",style:{height:"3em"}}),n("span",{class:"frac-line",style:{"border-bottom-width":"0.04em"}})]),n("span",{style:{top:"-3.677em"}},[n("span",{class:"pstrut",style:{height:"3em"}}),n("span",{class:"mord"},[n("span",{class:"mord"},"∣"),n("span",{class:"mord mathnormal"},"A"),n("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),n("span",{class:"mbin"},"∩"),n("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),n("span",{class:"mord mathnormal",style:{"margin-right":"0.05017em"}},"B"),n("span",{class:"mord"},"∣")])])]),n("span",{class:"vlist-s"},"​")]),n("span",{class:"vlist-r"},[n("span",{class:"vlist",style:{height:"0.936em"}},[n("span")])])])]),n("span",{class:"mclose nulldelimiter"})])])])])])],-1),N=n("p",null,"用该物理量表示两个图像框的相似度。 优点：",-1),G=n("ol",null,[n("li",null,"具有尺度不变性；"),n("li",null,"满足非负性；"),n("li",null,"满足对称性；")],-1),R=n("div",{class:"hint-container warning"},[n("p",{class:"hint-container-title"},"缺点"),n("p",null,[s("如果"),n("span",{class:"katex"},[n("span",{class:"katex-mathml"},[n("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[n("semantics",null,[n("mrow",null,[n("mi",{mathvariant:"normal"},"∣"),n("mi",null,"A"),n("mo",null,"∩"),n("mi",null,"B"),n("mi",{mathvariant:"normal"},"∣"),n("mo",null,"="),n("mn",null,"0")]),n("annotation",{encoding:"application/x-tex"},"|A\\cap B|=0")])])]),n("span",{class:"katex-html","aria-hidden":"true"},[n("span",{class:"base"},[n("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),n("span",{class:"mord"},"∣"),n("span",{class:"mord mathnormal"},"A"),n("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),n("span",{class:"mbin"},"∩"),n("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),n("span",{class:"base"},[n("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),n("span",{class:"mord mathnormal",style:{"margin-right":"0.05017em"}},"B"),n("span",{class:"mord"},"∣"),n("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),n("span",{class:"mrel"},"="),n("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),n("span",{class:"base"},[n("span",{class:"strut",style:{height:"0.6444em"}}),n("span",{class:"mord"},"0")])])]),s("，即：两个图像没有相交时，无法比较两个图像的远近")]),n("p",null,"同时无法体现两个图像是如何相交的")],-1),Z=n("h4",{id:"giou",tabindex:"-1"},[n("a",{class:"header-anchor",href:"#giou"},[n("span",null,"GIOU")])],-1),F=n("p",null,"它能在更广义的层面上计算 IoU，并解决刚才我们说的‘两个图像没有相交时，无法比较两个图像的距离远近’的问题。",-1),V=n("p",{class:"katex-block"},[n("span",{class:"katex-display"},[n("span",{class:"katex"},[n("span",{class:"katex-mathml"},[n("math",{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},[n("semantics",null,[n("mrow",null,[n("mi",null,"G"),n("mi",null,"L"),n("mi",null,"O"),n("mi",null,"U"),n("mo",null,"="),n("mi",null,"I"),n("mi",null,"O"),n("mi",null,"U"),n("mo",null,"−"),n("mfrac",null,[n("mrow",null,[n("mi",{mathvariant:"normal"},"∣"),n("mi",null,"C"),n("mo",null,"−"),n("mo",{stretchy:"false"},"("),n("mi",null,"A"),n("mo",null,"∪"),n("mi",null,"B"),n("mo",{stretchy:"false"},")"),n("mi",{mathvariant:"normal"},"∣")]),n("mi",null,"C")])]),n("annotation",{encoding:"application/x-tex"}," GLOU=IOU-\\frac{|C-(A\\cup B)|}{C} ")])])]),n("span",{class:"katex-html","aria-hidden":"true"},[n("span",{class:"base"},[n("span",{class:"strut",style:{height:"0.6833em"}}),n("span",{class:"mord mathnormal"},"G"),n("span",{class:"mord mathnormal"},"L"),n("span",{class:"mord mathnormal",style:{"margin-right":"0.02778em"}},"O"),n("span",{class:"mord mathnormal",style:{"margin-right":"0.10903em"}},"U"),n("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),n("span",{class:"mrel"},"="),n("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),n("span",{class:"base"},[n("span",{class:"strut",style:{height:"0.7667em","vertical-align":"-0.0833em"}}),n("span",{class:"mord mathnormal",style:{"margin-right":"0.07847em"}},"I"),n("span",{class:"mord mathnormal",style:{"margin-right":"0.02778em"}},"O"),n("span",{class:"mord mathnormal",style:{"margin-right":"0.10903em"}},"U"),n("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),n("span",{class:"mbin"},"−"),n("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),n("span",{class:"base"},[n("span",{class:"strut",style:{height:"2.113em","vertical-align":"-0.686em"}}),n("span",{class:"mord"},[n("span",{class:"mopen nulldelimiter"}),n("span",{class:"mfrac"},[n("span",{class:"vlist-t vlist-t2"},[n("span",{class:"vlist-r"},[n("span",{class:"vlist",style:{height:"1.427em"}},[n("span",{style:{top:"-2.314em"}},[n("span",{class:"pstrut",style:{height:"3em"}}),n("span",{class:"mord"},[n("span",{class:"mord mathnormal",style:{"margin-right":"0.07153em"}},"C")])]),n("span",{style:{top:"-3.23em"}},[n("span",{class:"pstrut",style:{height:"3em"}}),n("span",{class:"frac-line",style:{"border-bottom-width":"0.04em"}})]),n("span",{style:{top:"-3.677em"}},[n("span",{class:"pstrut",style:{height:"3em"}}),n("span",{class:"mord"},[n("span",{class:"mord"},"∣"),n("span",{class:"mord mathnormal",style:{"margin-right":"0.07153em"}},"C"),n("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),n("span",{class:"mbin"},"−"),n("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),n("span",{class:"mopen"},"("),n("span",{class:"mord mathnormal"},"A"),n("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),n("span",{class:"mbin"},"∪"),n("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),n("span",{class:"mord mathnormal",style:{"margin-right":"0.05017em"}},"B"),n("span",{class:"mclose"},")"),n("span",{class:"mord"},"∣")])])]),n("span",{class:"vlist-s"},"​")]),n("span",{class:"vlist-r"},[n("span",{class:"vlist",style:{height:"0.686em"}},[n("span")])])])]),n("span",{class:"mclose nulldelimiter"})])])])])])],-1),H=n("p",null,[s("其中，"),n("span",{class:"katex"},[n("span",{class:"katex-mathml"},[n("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[n("semantics",null,[n("mrow",null,[n("mi",null,"C")]),n("annotation",{encoding:"application/x-tex"},"C")])])]),n("span",{class:"katex-html","aria-hidden":"true"},[n("span",{class:"base"},[n("span",{class:"strut",style:{height:"0.6833em"}}),n("span",{class:"mord mathnormal",style:{"margin-right":"0.07153em"}},"C")])])]),s("代表两个图像的最小包庇面积，也可以理解为这两个图像的最小外接矩形面积")],-1),Y=n("p",null,[n("strong",null,"GIoU 完善了图像重叠度的计算功能，但仍无法对图形距离以及长宽比的相似性进行很好的表示。")],-1),j=n("h3",{id:"diou",tabindex:"-1"},[n("a",{class:"header-anchor",href:"#diou"},[n("span",null,"DIOU")])],-1),J=n("p",null,"GIoU 虽然解决了 IoU 的一些问题，但是它并不能直接反映预测框与目标框之间的距离，DIoU（Distance-IoU）即可解决这个问题，它将两个框之间的重叠度、距离、尺度都考虑了进来，DIoU 的计算公式如下：",-1),K=n("p",{class:"katex-block"},[n("span",{class:"katex-display"},[n("span",{class:"katex"},[n("span",{class:"katex-mathml"},[n("math",{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},[n("semantics",null,[n("mrow",null,[n("mi",null,"D"),n("mi",null,"I"),n("mi",null,"O"),n("mi",null,"U"),n("mo",null,"="),n("mi",null,"I"),n("mi",null,"O"),n("mi",null,"U"),n("mo",null,"−"),n("mfrac",null,[n("mrow",null,[n("msup",null,[n("mi",null,"ρ"),n("mn",null,"2")]),n("mo",{stretchy:"false"},"("),n("mi",null,"b"),n("mo",{separator:"true"},","),n("msup",null,[n("mi",null,"b"),n("mrow",null,[n("mi",null,"g"),n("mi",null,"t")])]),n("mo",{stretchy:"false"},")")]),n("msup",null,[n("mi",null,"c"),n("mn",null,"2")])])]),n("annotation",{encoding:"application/x-tex"}," DIOU=IOU-\\frac{\\rho^2(b,b^{gt})}{c^2} ")])])]),n("span",{class:"katex-html","aria-hidden":"true"},[n("span",{class:"base"},[n("span",{class:"strut",style:{height:"0.6833em"}}),n("span",{class:"mord mathnormal",style:{"margin-right":"0.02778em"}},"D"),n("span",{class:"mord mathnormal",style:{"margin-right":"0.07847em"}},"I"),n("span",{class:"mord mathnormal",style:{"margin-right":"0.02778em"}},"O"),n("span",{class:"mord mathnormal",style:{"margin-right":"0.10903em"}},"U"),n("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),n("span",{class:"mrel"},"="),n("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),n("span",{class:"base"},[n("span",{class:"strut",style:{height:"0.7667em","vertical-align":"-0.0833em"}}),n("span",{class:"mord mathnormal",style:{"margin-right":"0.07847em"}},"I"),n("span",{class:"mord mathnormal",style:{"margin-right":"0.02778em"}},"O"),n("span",{class:"mord mathnormal",style:{"margin-right":"0.10903em"}},"U"),n("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),n("span",{class:"mbin"},"−"),n("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),n("span",{class:"base"},[n("span",{class:"strut",style:{height:"2.1771em","vertical-align":"-0.686em"}}),n("span",{class:"mord"},[n("span",{class:"mopen nulldelimiter"}),n("span",{class:"mfrac"},[n("span",{class:"vlist-t vlist-t2"},[n("span",{class:"vlist-r"},[n("span",{class:"vlist",style:{height:"1.4911em"}},[n("span",{style:{top:"-2.314em"}},[n("span",{class:"pstrut",style:{height:"3em"}}),n("span",{class:"mord"},[n("span",{class:"mord"},[n("span",{class:"mord mathnormal"},"c"),n("span",{class:"msupsub"},[n("span",{class:"vlist-t"},[n("span",{class:"vlist-r"},[n("span",{class:"vlist",style:{height:"0.7401em"}},[n("span",{style:{top:"-2.989em","margin-right":"0.05em"}},[n("span",{class:"pstrut",style:{height:"2.7em"}}),n("span",{class:"sizing reset-size6 size3 mtight"},[n("span",{class:"mord mtight"},"2")])])])])])])])])]),n("span",{style:{top:"-3.23em"}},[n("span",{class:"pstrut",style:{height:"3em"}}),n("span",{class:"frac-line",style:{"border-bottom-width":"0.04em"}})]),n("span",{style:{top:"-3.677em"}},[n("span",{class:"pstrut",style:{height:"3em"}}),n("span",{class:"mord"},[n("span",{class:"mord"},[n("span",{class:"mord mathnormal"},"ρ"),n("span",{class:"msupsub"},[n("span",{class:"vlist-t"},[n("span",{class:"vlist-r"},[n("span",{class:"vlist",style:{height:"0.8141em"}},[n("span",{style:{top:"-3.063em","margin-right":"0.05em"}},[n("span",{class:"pstrut",style:{height:"2.7em"}}),n("span",{class:"sizing reset-size6 size3 mtight"},[n("span",{class:"mord mtight"},"2")])])])])])])]),n("span",{class:"mopen"},"("),n("span",{class:"mord mathnormal"},"b"),n("span",{class:"mpunct"},","),n("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),n("span",{class:"mord"},[n("span",{class:"mord mathnormal"},"b"),n("span",{class:"msupsub"},[n("span",{class:"vlist-t"},[n("span",{class:"vlist-r"},[n("span",{class:"vlist",style:{height:"0.7936em"}},[n("span",{style:{top:"-3.063em","margin-right":"0.05em"}},[n("span",{class:"pstrut",style:{height:"2.7em"}}),n("span",{class:"sizing reset-size6 size3 mtight"},[n("span",{class:"mord mtight"},[n("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.03588em"}},"g"),n("span",{class:"mord mathnormal mtight"},"t")])])])])])])])]),n("span",{class:"mclose"},")")])])]),n("span",{class:"vlist-s"},"​")]),n("span",{class:"vlist-r"},[n("span",{class:"vlist",style:{height:"0.686em"}},[n("span")])])])]),n("span",{class:"mclose nulldelimiter"})])])])])])],-1),Q=n("p",null,[s("其中，"),n("span",{class:"katex"},[n("span",{class:"katex-mathml"},[n("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[n("semantics",null,[n("mrow",null,[n("mi",null,"b")]),n("annotation",{encoding:"application/x-tex"},"b")])])]),n("span",{class:"katex-html","aria-hidden":"true"},[n("span",{class:"base"},[n("span",{class:"strut",style:{height:"0.6944em"}}),n("span",{class:"mord mathnormal"},"b")])])]),s("，"),n("span",{class:"katex"},[n("span",{class:"katex-mathml"},[n("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[n("semantics",null,[n("mrow",null,[n("msup",null,[n("mi",null,"b"),n("mrow",null,[n("mi",null,"g"),n("mi",null,"t")])])]),n("annotation",{encoding:"application/x-tex"},"b^{gt}")])])]),n("span",{class:"katex-html","aria-hidden":"true"},[n("span",{class:"base"},[n("span",{class:"strut",style:{height:"0.7936em"}}),n("span",{class:"mord"},[n("span",{class:"mord mathnormal"},"b"),n("span",{class:"msupsub"},[n("span",{class:"vlist-t"},[n("span",{class:"vlist-r"},[n("span",{class:"vlist",style:{height:"0.7936em"}},[n("span",{style:{top:"-3.063em","margin-right":"0.05em"}},[n("span",{class:"pstrut",style:{height:"2.7em"}}),n("span",{class:"sizing reset-size6 size3 mtight"},[n("span",{class:"mord mtight"},[n("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.03588em"}},"g"),n("span",{class:"mord mathnormal mtight"},"t")])])])])])])])])])])]),s("代表两个框的中心点，"),n("span",{class:"katex"},[n("span",{class:"katex-mathml"},[n("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[n("semantics",null,[n("mrow",null,[n("mi",null,"ρ")]),n("annotation",{encoding:"application/x-tex"},"\\rho")])])]),n("span",{class:"katex-html","aria-hidden":"true"},[n("span",{class:"base"},[n("span",{class:"strut",style:{height:"0.625em","vertical-align":"-0.1944em"}}),n("span",{class:"mord mathnormal"},"ρ")])])]),s("代表两个中心点之间的欧氏距离，"),n("span",{class:"katex"},[n("span",{class:"katex-mathml"},[n("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[n("semantics",null,[n("mrow",null,[n("mi",null,"c")]),n("annotation",{encoding:"application/x-tex"},"c")])])]),n("span",{class:"katex-html","aria-hidden":"true"},[n("span",{class:"base"},[n("span",{class:"strut",style:{height:"0.4306em"}}),n("span",{class:"mord mathnormal"},"c")])])]),s(" 表示最小包庇矩形的对角线长")],-1),W=n("figure",null,[n("img",{src:"https://raw.githubusercontent.com/dream-oyh/dream-oyh.github.io/images/DIOU.png",alt:"",tabindex:"0",loading:"lazy"}),n("figcaption")],-1),X=n("ul",null,[n("li",null,"DIoU 可直接最小化两个框之间的距离，所以作为损失函数的时候 Loss 收敛的更快；"),n("li",null,"在两个框完全上下排列或左右排列时，没有空白区域，此时 GIoU 几乎退化为了 IoU，但是 DIoU 仍然有效。")],-1),$=n("h2",{id:"保存和加载模型",tabindex:"-1"},[n("a",{class:"header-anchor",href:"#保存和加载模型"},[n("span",null,"保存和加载模型")])],-1),nn={href:"https://tangshusen.me/Dive-into-DL-PyTorch/#/chapter04_DL_computation/4.5_read-write",target:"_blank",rel:"noopener noreferrer"},sn=n("h2",{id:"gpu-计算",tabindex:"-1"},[n("a",{class:"header-anchor",href:"#gpu-计算"},[n("span",null,"GPU 计算")])],-1),an={href:"https://tangshusen.me/Dive-into-DL-PyTorch/#/chapter04_DL_computation/4.6_use-gpu",target:"_blank",rel:"noopener noreferrer"};function tn(en,pn){const e=o("RouteLink"),t=o("ExternalLinkIcon");return i(),u("div",null,[m,n("p",null,[d,s("中，各层模型可以以多种方式输入，这一点在"),a(e,{to:"/code/python/pytorch/2.1linear_regression.html#%E5%AE%9A%E4%B9%89%E6%A8%A1%E5%9E%8B"},{default:p(()=>[s("线性回归实现的笔记")]),_:1}),s("中有提到，总的来说，模型参数支持 直接输入各层、输入有序字典"),h,s("或通过"),k,s("函数添加。")]),g,n("div",v,[b,n("p",null,[s("我们在"),a(e,{to:"/code/python/pytorch/2.3softmax.html#%E5%AE%9A%E4%B9%89%E5%92%8C%E5%88%9D%E5%A7%8B%E5%8C%96%E6%A8%A1%E5%9E%8B"},{default:p(()=>[s("softmax")]),_:1}),s("中定义了一个"),y,s("层，这个层不同于一般印象里的线性计算，他只是一个"),_,s("的操作，但是我们把这也叫做一个层。也因为如此，我们对于"),f,s("的认识应该更广泛一些，"),w,s("提供的"),x,s("函数可以看作是这个层的"),M,s("，一种广义上的行为，而不只是前向传播。")]),n("p",null,[s("对于"),n("a",L,[s("丢弃法 (Dropout)"),a(t)]),s("，"),D,s("也提供了"),U,s("层，以方便使用。我们需要在全连接层之后加入"),I,s("层，它将在训练模型中以指定的丢弃概率随机丢弃一部分神经元，而在测试模型中不发挥作用。")])]),z,n("p",null,[s("具体应用实例可以见"),a(e,{to:"/code/python/pytorch/4.3AlexNet.html#%E8%AF%BB%E5%8F%96%E6%95%B0%E6%8D%AE"},{default:p(()=>[q,s("模型")]),_:1})]),O,A,n("p",null,[s("有关感受野可以看"),n("a",E,[s("这篇文章"),a(t)])]),S,B,n("p",null,[s("Source:"),n("a",T,[s("目标检测基础模块之 IoU 及优化 - 知乎 (zhihu.com)"),a(t)])]),P,C,N,G,R,Z,F,V,H,Y,j,J,K,Q,W,X,$,n("p",null,[n("a",nn,[s("查看文档链接"),a(t)])]),sn,n("p",null,[n("a",an,[s("查看文档链接"),a(t)])])])}const cn=c(r,[["render",tn],["__file","3.1Deeplearning_basic.html.vue"]]),un=JSON.parse('{"path":"/code/python/pytorch/3.1Deeplearning_basic.html","title":"深度学习基础","lang":"zh-CN","frontmatter":{"date":"2024-02-18T00:00:00.000Z","description":"深度学习基础 模型构建 根据之前章节，我们已经能够发现，利用nn.Module和nn.Sequential可以很方便地构建模型，并且nn.Sequential本身也是nn.Module的一个继承类。所以，通过nn.Module来构建继承类也是非常通用的模型构建方式，一般来说，在继承类中我们会重载nn.Module的forward()函数，比如说我们可以...","head":[["meta",{"property":"og:url","content":"https://dream-oyh.github.io/code/python/pytorch/3.1Deeplearning_basic.html"}],["meta",{"property":"og:site_name","content":"Dream_oyh 的 blog"}],["meta",{"property":"og:title","content":"深度学习基础"}],["meta",{"property":"og:description","content":"深度学习基础 模型构建 根据之前章节，我们已经能够发现，利用nn.Module和nn.Sequential可以很方便地构建模型，并且nn.Sequential本身也是nn.Module的一个继承类。所以，通过nn.Module来构建继承类也是非常通用的模型构建方式，一般来说，在继承类中我们会重载nn.Module的forward()函数，比如说我们可以..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:image","content":"https://raw.githubusercontent.com/dream-oyh/dream-oyh.github.io/images/DIOU.png"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2024-02-21T13:57:19.000Z"}],["meta",{"name":"twitter:card","content":"summary_large_image"}],["meta",{"name":"twitter:image:alt","content":"深度学习基础"}],["meta",{"property":"article:author","content":"OYH"}],["meta",{"property":"article:published_time","content":"2024-02-18T00:00:00.000Z"}],["meta",{"property":"article:modified_time","content":"2024-02-21T13:57:19.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"深度学习基础\\",\\"image\\":[\\"https://raw.githubusercontent.com/dream-oyh/dream-oyh.github.io/images/DIOU.png\\"],\\"datePublished\\":\\"2024-02-18T00:00:00.000Z\\",\\"dateModified\\":\\"2024-02-21T13:57:19.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"OYH\\",\\"email\\":\\"19859860010@163.com\\"}]}"]]},"headers":[{"level":2,"title":"模型构建","slug":"模型构建","link":"#模型构建","children":[{"level":3,"title":"nn.Module的子类","slug":"nn-module的子类","link":"#nn-module的子类","children":[]}]},{"level":2,"title":"访问模型参数","slug":"访问模型参数","link":"#访问模型参数","children":[]},{"level":2,"title":"初始化模型参数","slug":"初始化模型参数","link":"#初始化模型参数","children":[{"level":3,"title":"自定义初始化方法","slug":"自定义初始化方法","link":"#自定义初始化方法","children":[]},{"level":3,"title":"共享模型参数","slug":"共享模型参数","link":"#共享模型参数","children":[]}]},{"level":2,"title":"自定义层","slug":"自定义层","link":"#自定义层","children":[]},{"level":2,"title":"Torchvision.transforms实例","slug":"torchvision-transforms实例","link":"#torchvision-transforms实例","children":[]},{"level":2,"title":"深度学习相关概念","slug":"深度学习相关概念","link":"#深度学习相关概念","children":[{"level":3,"title":"感受野","slug":"感受野","link":"#感受野","children":[]},{"level":3,"title":"IOU（交并比）","slug":"iou-交并比","link":"#iou-交并比","children":[]},{"level":3,"title":"DIOU","slug":"diou","link":"#diou","children":[]}]},{"level":2,"title":"保存和加载模型","slug":"保存和加载模型","link":"#保存和加载模型","children":[]},{"level":2,"title":"GPU 计算","slug":"gpu-计算","link":"#gpu-计算","children":[]}],"git":{"createdTime":1708262283000,"updatedTime":1708523839000,"contributors":[{"name":"dream_linux","email":"1399541701@qq.com","commits":3},{"name":"dream同学0","email":"1399541701@qq.com","commits":1}]},"readingTime":{"minutes":7.5,"words":2250},"filePathRelative":"code/python/pytorch/3.1Deeplearning_basic.md","localizedDate":"2024年2月18日","excerpt":"\\n<h2>模型构建</h2>\\n<p>根据之前章节，我们已经能够发现，利用<code>nn.Module</code>和<code>nn.Sequential</code>可以很方便地构建模型，并且<code>nn.Sequential</code>本身也是<code>nn.Module</code>的一个继承类。所以，通过<code>nn.Module</code>来构建继承类也是非常通用的模型构建方式，一般来说，在继承类中我们会重载<code>nn.Module</code>的<code>forward()</code>函数，比如说我们可以通过继承类很容易地构建一个多层感知机模型：</p>\\n","autoDesc":true}');export{cn as comp,un as data};
