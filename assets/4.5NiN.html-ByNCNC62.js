import{_ as o}from"./plugin-vue_export-helper-DlAUqK2U.js";import{r as p,o as c,c as l,d as t,b as n,a as e,w as s,e as i}from"./app-_PtCGCuv.js";const u={},r=i('<h1 id="nin-网络中的网络" tabindex="-1"><a class="header-anchor" href="#nin-网络中的网络"><span>NiN（网络中的网络）</span></a></h1><div class="hint-container tip"><p class="hint-container-title">本节学习要点</p><ol><li>掌握 1x1 卷积层代替全连接层的设计思路</li><li>学会 1x1 卷积层的定义和使用</li><li>了解 NiN 结构的定义</li></ol></div><blockquote><p>What is it NiN?</p></blockquote><p>相较于 LeNet, AlexNet 与 VGG 提供了更为深度的学习网络，能够学习更复杂的特征，但是 AlexNet 与 VGG 的基本结构都是卷积层 + 全连接层，而全连接层作为最后一端，参数过多，计算量大，因此 NiN 提出，将卷积层与全连接层交替排列，减少计算，提高效率。但是问题在于，卷积层的输入输出均为四维数组，可是全连接层的输入输出为二维数组，难以实现，这时候需要用到 1x1 卷积层用来充当全连接层的作用。</p><h2 id="nin-块" tabindex="-1"><a class="header-anchor" href="#nin-块"><span>NiN 块</span></a></h2>',5),d=i(`<p>定义 NiN 块的函数如下：</p><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="language-python"><code><span class="token keyword">def</span> <span class="token function">nin_block</span><span class="token punctuation">(</span>in_channels<span class="token punctuation">,</span> out_channels<span class="token punctuation">,</span> kernel_size<span class="token punctuation">,</span> padding<span class="token punctuation">,</span> stride<span class="token punctuation">)</span><span class="token punctuation">:</span>
  net <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
    nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token punctuation">,</span> out_channels<span class="token punctuation">,</span> kernel_size<span class="token punctuation">,</span> padding<span class="token operator">=</span>padding<span class="token punctuation">,</span> stride<span class="token operator">=</span>stride<span class="token punctuation">)</span><span class="token punctuation">,</span>
    nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>out_channels<span class="token punctuation">,</span> out_channels<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>out_channels<span class="token punctuation">,</span> out_channels<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
  <span class="token punctuation">)</span>
  <span class="token keyword">return</span> net
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="nin-网络" tabindex="-1"><a class="header-anchor" href="#nin-网络"><span>NiN 网络</span></a></h2>`,3),N=t("p",null,"NiN 去掉了 AlexNet 最后的 3 个全连接层，取而代之地，NiN 使用了输出通道数等于标签类别数的 NiN 块，然后使用全局平均池化层对每个通道中所有元素求平均并直接用于分类。这里的全局平均池化层即窗口形状等于输入空间维形状的平均池化层。NiN 的这个设计的好处是可以显著减小模型参数尺寸，从而缓解过拟合。然而，该设计有时会造成获得有效模型的训练时间的增加。",-1);function h(k,m){const a=p("RouteLink");return c(),l("div",null,[r,t("p",null,[n("NiN 块与"),e(a,{to:"/code/python/pytorch/4.4VGG.html#%E5%AE%9A%E4%B9%89-vgg-%E5%9D%97%E5%87%BD%E6%95%B0"},{default:s(()=>[n(" VGG 中的 VGG 块 ")]),_:1}),n("类似，是 NiN 网络中的基本组成单元，它由一个卷积层加两个充当全连接层的 1x1 卷积层串联而成，第一个卷积层的参数可以自定义，而第二和第三个的卷积层参数一般是固定的。")]),d,t("p",null,[n("NiN 使用卷积窗口形状分别为 11×11、5×5 和 3×3 的卷积层，相应的输出通道数也与 "),e(a,{to:"/code/python/pytorch/4.3AlexNet.html#%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84"},{default:s(()=>[n(" AlexNet ")]),_:1}),n(" 中的一致。每个 NiN 块后接一个步幅为 2、窗口形状为 3×3 的最大池化层。")]),N])}const x=o(u,[["render",h],["__file","4.5NiN.html.vue"]]),y=JSON.parse('{"path":"/code/python/pytorch/4.5NiN.html","title":"NiN（网络中的网络）","lang":"zh-CN","frontmatter":{"date":"2024-02-25T00:00:00.000Z","description":"NiN（网络中的网络） 本节学习要点 掌握 1x1 卷积层代替全连接层的设计思路 学会 1x1 卷积层的定义和使用 了解 NiN 结构的定义 What is it NiN? 相较于 LeNet, AlexNet 与 VGG 提供了更为深度的学习网络，能够学习更复杂的特征，但是 AlexNet 与 VGG 的基本结构都是卷积层 + 全连接层，而全连接层作...","head":[["meta",{"property":"og:url","content":"https://dream-oyh.github.io/code/python/pytorch/4.5NiN.html"}],["meta",{"property":"og:site_name","content":"Dream_oyh 的 blog"}],["meta",{"property":"og:title","content":"NiN（网络中的网络）"}],["meta",{"property":"og:description","content":"NiN（网络中的网络） 本节学习要点 掌握 1x1 卷积层代替全连接层的设计思路 学会 1x1 卷积层的定义和使用 了解 NiN 结构的定义 What is it NiN? 相较于 LeNet, AlexNet 与 VGG 提供了更为深度的学习网络，能够学习更复杂的特征，但是 AlexNet 与 VGG 的基本结构都是卷积层 + 全连接层，而全连接层作..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2024-02-25T12:51:11.000Z"}],["meta",{"property":"article:author","content":"OYH"}],["meta",{"property":"article:published_time","content":"2024-02-25T00:00:00.000Z"}],["meta",{"property":"article:modified_time","content":"2024-02-25T12:51:11.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"NiN（网络中的网络）\\",\\"image\\":[\\"\\"],\\"datePublished\\":\\"2024-02-25T00:00:00.000Z\\",\\"dateModified\\":\\"2024-02-25T12:51:11.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"OYH\\",\\"email\\":\\"19859860010@163.com\\"}]}"]]},"headers":[{"level":2,"title":"NiN 块","slug":"nin-块","link":"#nin-块","children":[]},{"level":2,"title":"NiN 网络","slug":"nin-网络","link":"#nin-网络","children":[]}],"git":{"createdTime":1708865471000,"updatedTime":1708865471000,"contributors":[{"name":"dream_linux","email":"1399541701@qq.com","commits":1}]},"readingTime":{"minutes":1.89,"words":566},"filePathRelative":"code/python/pytorch/4.5NiN.md","localizedDate":"2024年2月25日","excerpt":"\\n<div class=\\"hint-container tip\\">\\n<p class=\\"hint-container-title\\">本节学习要点</p>\\n<ol>\\n<li>掌握 1x1 卷积层代替全连接层的设计思路</li>\\n<li>学会 1x1 卷积层的定义和使用</li>\\n<li>了解 NiN 结构的定义</li>\\n</ol>\\n</div>\\n<blockquote>\\n<p>What is it NiN?</p>\\n</blockquote>\\n<p>相较于 LeNet, AlexNet 与 VGG 提供了更为深度的学习网络，能够学习更复杂的特征，但是 AlexNet 与 VGG 的基本结构都是卷积层 + 全连接层，而全连接层作为最后一端，参数过多，计算量大，因此 NiN 提出，将卷积层与全连接层交替排列，减少计算，提高效率。但是问题在于，卷积层的输入输出均为四维数组，可是全连接层的输入输出为二维数组，难以实现，这时候需要用到 1x1 卷积层用来充当全连接层的作用。</p>","autoDesc":true}');export{x as comp,y as data};
