import{_ as l}from"./plugin-vue_export-helper-DlAUqK2U.js";import{r as e,o as u,c as i,d as s,b as n,a,w as o,e as t}from"./app-Br-bB8XC.js";const k={},r=t(`<h1 id="nin-网络中的网络" tabindex="-1"><a class="header-anchor" href="#nin-网络中的网络"><span>NiN（网络中的网络）</span></a></h1><div class="hint-container tip"><p class="hint-container-title">本节学习要点</p><ol><li>掌握 1x1 卷积层代替全连接层的设计思路</li><li>学会 1x1 卷积层的定义和使用</li><li>了解 NiN 结构的定义</li></ol></div><blockquote><p>What is it NiN?</p></blockquote><p>相较于 LeNet, AlexNet 与 VGG 提供了更为深度的学习网络，能够学习更复杂的特征，但是 AlexNet 与 VGG 的基本结构都是卷积层 + 全连接层，而全连接层作为最后一端，参数过多，计算量大，因此 NiN 提出，将卷积层与全连接层交替排列，减少计算，提高效率。但是问题在于，卷积层的输入输出均为四维数组，可是全连接层的输入输出为二维数组，难以实现，这时候需要用到 1x1 卷积层用来充当全连接层的作用。</p><div class="hint-container tip"><p class="hint-container-title">本节学习要点</p><ol><li>掌握 1x1 卷积层代替全连接层的设计思路</li><li>学习全局平均层的原理和实现</li><li>掌握 NiN 结构的定义</li></ol></div><h2 id="导入需要的包" tabindex="-1"><a class="header-anchor" href="#导入需要的包"><span>导入需要的包</span></a></h2><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="language-python"><code><span class="token keyword">import</span> torch
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F
<span class="token keyword">import</span> sys
sys<span class="token punctuation">.</span>path<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token string">&quot;.&quot;</span><span class="token punctuation">)</span>
<span class="token keyword">import</span> d2lzh_pytorch <span class="token keyword">as</span> d2l
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="nin-块" tabindex="-1"><a class="header-anchor" href="#nin-块"><span>NiN 块</span></a></h2>`,8),d=t(`<p>定义 NiN 块的函数如下：</p><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="language-python"><code><span class="token keyword">def</span> <span class="token function">nin_block</span><span class="token punctuation">(</span>in_channels<span class="token punctuation">,</span> out_channels<span class="token punctuation">,</span> kernel_size<span class="token punctuation">,</span> padding<span class="token punctuation">,</span> stride<span class="token punctuation">)</span><span class="token punctuation">:</span>
  net <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
    nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token punctuation">,</span> out_channels<span class="token punctuation">,</span> kernel_size<span class="token punctuation">,</span> padding<span class="token operator">=</span>padding<span class="token punctuation">,</span> stride<span class="token operator">=</span>stride<span class="token punctuation">)</span><span class="token punctuation">,</span>
    nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>out_channels<span class="token punctuation">,</span> out_channels<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>out_channels<span class="token punctuation">,</span> out_channels<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
  <span class="token punctuation">)</span>
  <span class="token keyword">return</span> net
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="nin-网络" tabindex="-1"><a class="header-anchor" href="#nin-网络"><span>NiN 网络</span></a></h2>`,3),m=t(`<p>NiN 去掉了 AlexNet 最后的 3 个全连接层，取而代之地，NiN 使用了输出通道数等于标签类别数的 NiN 块，然后使用全局平均池化层<sup class="footnote-ref"><a href="#footnote1">[1]</a><a class="footnote-anchor" id="footnote-ref1"></a></sup>对每个通道中所有元素求平均并直接用于分类。这里的全局平均池化层即窗口形状等于输入空间维形状的平均池化层。NiN 的这个设计的好处是可以显著减小模型参数尺寸，从而缓解过拟合。然而，该设计有时会造成获得有效模型的训练时间的增加。</p><p>但是 pytorch 目前并没有给出全局池化层，需要自行定义，定义全局池化层的函数如下：</p><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="language-python"><code><span class="token keyword">class</span> <span class="token class-name">GlobalAveragePooling</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
  <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token builtin">super</span><span class="token punctuation">(</span>GlobalAveragePooling<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>

  <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> F<span class="token punctuation">.</span>avg_pool2d<span class="token punctuation">(</span>x<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span>x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><details class="hint-container details"><summary>对全局平均池化层的测试</summary><p>由于我看了定义和通俗理解，还是不知道这个 <code>function.avg_pool2d()</code>，怎么就能变成这个全局平均池化层了，就写了个程序测试了一下，测试代码如下：</p><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="language-python"><code>x <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">)</span>
layer <span class="token operator">=</span> GlobalAveragePooling<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>layer<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>输出结果为：<code>torch.Size([1, 16, 1, 1])</code>，可以发现，这个全局平均池化层确实能够将输入的 <code>32x32</code> 变成 <code>1x1</code> 的输出，并且保证前两维不变。</p></details><p>定义 NiN 网络如下：</p><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="language-python"><code>net <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
    nin_block<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">96</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">11</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    nin_block<span class="token punctuation">(</span><span class="token number">96</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    nin_block<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">384</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token comment"># 标签类别数是 10</span>
    nin_block<span class="token punctuation">(</span><span class="token number">384</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    GlobalAveragePooling2d<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    d2l<span class="token punctuation">.</span>FlattenLayer<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>为了更直观地看出 NiN 对输入图像维数的操作，我们可以写一个程序测试一下。</p><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="language-python"><code>x <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">224</span><span class="token punctuation">,</span> <span class="token number">224</span><span class="token punctuation">)</span>
<span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>net<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    x <span class="token operator">=</span> net<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>i<span class="token punctuation">,</span> <span class="token string">&quot;out shape: &quot;</span><span class="token punctuation">,</span> x<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>输出结果为：</p><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="language-python"><code><span class="token number">0</span> out shape<span class="token punctuation">:</span>  torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">96</span><span class="token punctuation">,</span> <span class="token number">54</span><span class="token punctuation">,</span> <span class="token number">54</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token number">1</span> out shape<span class="token punctuation">:</span>  torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">96</span><span class="token punctuation">,</span> <span class="token number">26</span><span class="token punctuation">,</span> <span class="token number">26</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token number">2</span> out shape<span class="token punctuation">:</span>  torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">26</span><span class="token punctuation">,</span> <span class="token number">26</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token number">3</span> out shape<span class="token punctuation">:</span>  torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">12</span><span class="token punctuation">,</span> <span class="token number">12</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token number">4</span> out shape<span class="token punctuation">:</span>  torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">384</span><span class="token punctuation">,</span> <span class="token number">12</span><span class="token punctuation">,</span> <span class="token number">12</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token number">5</span> out shape<span class="token punctuation">:</span>  torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">384</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token number">6</span> out shape<span class="token punctuation">:</span>  torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">384</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token number">7</span> out shape<span class="token punctuation">:</span>  torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token number">8</span> out shape<span class="token punctuation">:</span>  torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token number">9</span> out shape<span class="token punctuation">:</span>  torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>可以看出网络在变的越来越深，有利于更复杂特征的学习，最后<code>FlattenLayer()</code>层的意义是将四维的输出转为二维的输出，与各类别对应上。</p><hr class="footnotes-sep">`,12),b={class:"footnotes"},v={class:"footnotes-list"},h={id:"footnote1",class:"footnote-item"},N={href:"https://blog.csdn.net/u012370185/article/details/95591712",target:"_blank",rel:"noopener noreferrer"},y=s("a",{href:"#footnote-ref1",class:"footnote-backref"},"↩︎",-1);function _(g,x){const p=e("RouteLink"),c=e("ExternalLinkIcon");return u(),i("div",null,[r,s("p",null,[n("NiN 块与"),a(p,{to:"/code/python/pytorch/4.4VGG.html#%E5%AE%9A%E4%B9%89-vgg-%E5%9D%97%E5%87%BD%E6%95%B0"},{default:o(()=>[n(" VGG 中的 VGG 块 ")]),_:1}),n("类似，是 NiN 网络中的基本组成单元，它由一个卷积层加两个充当全连接层的 1x1 卷积层串联而成，第一个卷积层的参数可以自定义，而第二和第三个的卷积层参数一般是固定的。")]),d,s("p",null,[n("NiN 使用卷积窗口形状分别为 11×11、5×5 和 3×3 的卷积层，相应的输出通道数也与 "),a(p,{to:"/code/python/pytorch/4.3AlexNet.html#%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84"},{default:o(()=>[n(" AlexNet ")]),_:1}),n(" 中的一致。每个 NiN 块后接一个步幅为 2、窗口形状为 3×3 的最大池化层。")]),m,s("section",b,[s("ol",v,[s("li",h,[s("p",null,[s("a",N,[n("全局平均池化层的通俗理解"),a(c)]),n(),y])])])])])}const G=l(k,[["render",_],["__file","4.5NiN.html.vue"]]),w=JSON.parse('{"path":"/code/python/pytorch/4.5NiN.html","title":"NiN（网络中的网络）","lang":"zh-CN","frontmatter":{"date":"2024-02-25T00:00:00.000Z","description":"NiN（网络中的网络） 本节学习要点 掌握 1x1 卷积层代替全连接层的设计思路 学会 1x1 卷积层的定义和使用 了解 NiN 结构的定义 What is it NiN? 相较于 LeNet, AlexNet 与 VGG 提供了更为深度的学习网络，能够学习更复杂的特征，但是 AlexNet 与 VGG 的基本结构都是卷积层 + 全连接层，而全连接层作...","head":[["meta",{"property":"og:url","content":"https://dream-oyh.github.io/code/python/pytorch/4.5NiN.html"}],["meta",{"property":"og:site_name","content":"Dream_oyh 的 blog"}],["meta",{"property":"og:title","content":"NiN（网络中的网络）"}],["meta",{"property":"og:description","content":"NiN（网络中的网络） 本节学习要点 掌握 1x1 卷积层代替全连接层的设计思路 学会 1x1 卷积层的定义和使用 了解 NiN 结构的定义 What is it NiN? 相较于 LeNet, AlexNet 与 VGG 提供了更为深度的学习网络，能够学习更复杂的特征，但是 AlexNet 与 VGG 的基本结构都是卷积层 + 全连接层，而全连接层作..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2024-02-26T09:40:30.000Z"}],["meta",{"property":"article:author","content":"OYH"}],["meta",{"property":"article:published_time","content":"2024-02-25T00:00:00.000Z"}],["meta",{"property":"article:modified_time","content":"2024-02-26T09:40:30.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"NiN（网络中的网络）\\",\\"image\\":[\\"\\"],\\"datePublished\\":\\"2024-02-25T00:00:00.000Z\\",\\"dateModified\\":\\"2024-02-26T09:40:30.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"OYH\\",\\"email\\":\\"19859860010@163.com\\"}]}"]]},"headers":[{"level":2,"title":"导入需要的包","slug":"导入需要的包","link":"#导入需要的包","children":[]},{"level":2,"title":"NiN 块","slug":"nin-块","link":"#nin-块","children":[]},{"level":2,"title":"NiN 网络","slug":"nin-网络","link":"#nin-网络","children":[]}],"git":{"createdTime":1708865471000,"updatedTime":1708940430000,"contributors":[{"name":"dream同学0","email":"1399541701@qq.com","commits":3},{"name":"dream_linux","email":"1399541701@qq.com","commits":1}]},"readingTime":{"minutes":3.65,"words":1096},"filePathRelative":"code/python/pytorch/4.5NiN.md","localizedDate":"2024年2月25日","excerpt":"\\n<div class=\\"hint-container tip\\">\\n<p class=\\"hint-container-title\\">本节学习要点</p>\\n<ol>\\n<li>掌握 1x1 卷积层代替全连接层的设计思路</li>\\n<li>学会 1x1 卷积层的定义和使用</li>\\n<li>了解 NiN 结构的定义</li>\\n</ol>\\n</div>\\n<blockquote>\\n<p>What is it NiN?</p>\\n</blockquote>\\n<p>相较于 LeNet, AlexNet 与 VGG 提供了更为深度的学习网络，能够学习更复杂的特征，但是 AlexNet 与 VGG 的基本结构都是卷积层 + 全连接层，而全连接层作为最后一端，参数过多，计算量大，因此 NiN 提出，将卷积层与全连接层交替排列，减少计算，提高效率。但是问题在于，卷积层的输入输出均为四维数组，可是全连接层的输入输出为二维数组，难以实现，这时候需要用到 1x1 卷积层用来充当全连接层的作用。</p>","autoDesc":true}');export{G as comp,w as data};
