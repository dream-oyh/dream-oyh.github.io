import{_ as c}from"./plugin-vue_export-helper-DlAUqK2U.js";import{r as o,o as i,c as r,d as s,b as n,a,w as p,e as t}from"./app-De0vRfeP.js";const u={},m=t(`<h1 id="深度学习基础" tabindex="-1"><a class="header-anchor" href="#深度学习基础"><span>深度学习基础</span></a></h1><h2 id="模型构建" tabindex="-1"><a class="header-anchor" href="#模型构建"><span>模型构建</span></a></h2><p>根据之前章节，我们已经能够发现，利用<code>nn.Module</code>和<code>nn.Sequential</code>可以很方便地构建模型，并且<code>nn.Sequential</code>本身也是<code>nn.Module</code>的一个继承类。所以，通过<code>nn.Module</code>来构建继承类也是非常通用的模型构建方式，一般来说，在继承类中我们会重载<code>nn.Module</code>的<code>forward()</code>函数，比如说我们可以通过继承类很容易地构建一个多层感知机模型：</p><blockquote><p>forward() 函数的目的在于，定义模型的前向计算，如何根据输入的数据 <code>x</code>计算出所需要的模型输出 <code>y</code>。</p></blockquote><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="language-python"><code><span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn
<span class="token keyword">class</span> <span class="token class-name">MLP</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
  <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span><span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token builtin">super</span><span class="token punctuation">(</span>MLP<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token operator">**</span>kwargs<span class="token punctuation">)</span>
    self<span class="token punctuation">.</span>hidden <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">784</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">)</span>  <span class="token comment"># 隐藏层</span>
    self<span class="token punctuation">.</span>act <span class="token operator">=</span> nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span>
    self<span class="token punctuation">.</span>output <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span>  <span class="token comment"># 输出层</span>
  <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
    a <span class="token operator">=</span> self<span class="token punctuation">.</span>act<span class="token punctuation">(</span>self<span class="token punctuation">.</span>hidden<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>
    renturn self<span class="token punctuation">.</span>output<span class="token punctuation">(</span>a<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>而<code>pytorch</code>库会自动生成<code>backward</code>反向传播函数</p><h3 id="nn-module的子类" tabindex="-1"><a class="header-anchor" href="#nn-module的子类"><span><code>nn.Module</code>的子类</span></a></h3><p><code>Pytorch</code>提供了丰富的<code>nn.Module</code>子类，我们可以直接使用这些子类来构建模型，比如<code>nn.Sequential</code>，<code>nn.Moudlelist</code>，<code>nn.ModuleDict</code>等，这些子类都继承自<code>nn.Module</code>。</p><h4 id="nn-sequential类" tabindex="-1"><a class="header-anchor" href="#nn-sequential类"><span><code>nn.Sequential</code>类</span></a></h4>`,9),d=s("code",null,"nn.Sequential",-1),h=s("code",null,"OrderedDict",-1),k=s("code",null,"add_module()",-1),g=t(`<h4 id="nn-modulelist类" tabindex="-1"><a class="header-anchor" href="#nn-modulelist类"><span><code>nn.ModuleList</code>类</span></a></h4><p>该类接受一个模块列表作为输入，如：</p><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="language-python"><code>net <span class="token operator">=</span> nn<span class="token punctuation">.</span>Modulelist<span class="token punctuation">(</span><span class="token punctuation">[</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
net<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">[</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div><p>该类的索引和列表类似，并且支持类似列表的<code>.append()</code>和<code>.extend()</code>操作。</p><div class="hint-container tip"><p class="hint-container-title">注意</p><p>不同于<code>nn.Sequential</code>，<code>nn.ModuleList</code>类并不支持<code>forward()</code>函数，而是需要自己定义。但是区分于传统<code>列表</code>，<code>nn.ModuleList</code>又能够生成参数，可以通过<code>nn.MoudleList.parameters()</code>来访问参数，所以该类只能认为是一个模块的容器，而并不是一个新的网络。</p></div><h4 id="nn-moduledict类" tabindex="-1"><a class="header-anchor" href="#nn-moduledict类"><span><code>nn.ModuleDict</code>类</span></a></h4><p>该类接受一个模块字典作为输入，也可以像字典一样操作。</p><p>和<code>nn.ModuleList</code>与<code>list</code>的关系一样，<code>nn.ModuleDict</code>没有定义<code>forward()</code>函数，需要自己定义，并且他较传统字典，他包括了模型所需要的权重参数。</p><ul><li>由于三者均为<code>nn..Module</code>的子类，所以可以互相嵌套调用。</li></ul>`,9),y={class:"hint-container important"},v=s("p",{class:"hint-container-title"},"不要局限了 Module 的用法",-1),b=s("code",null,"FlattenLayer",-1),_=s("code",null,"reshape",-1),f=s("code",null,"Module",-1),x=s("code",null,"Module",-1),w=s("code",null,"forward",-1),M=s("code",null,"Action",-1),P={href:"https://tangshusen.me/Dive-into-DL-PyTorch/#/chapter03_DL-basics/3.13_dropout?id=_3131-%E6%96%B9%E6%B3%95",target:"_blank",rel:"noopener noreferrer"},T=s("code",null,"nn.Module",-1),U=s("code",null,"nn.Dropout(drop_prob)",-1),L=s("code",null,"Dropout",-1),I=t(`<h2 id="访问模型参数" tabindex="-1"><a class="header-anchor" href="#访问模型参数"><span>访问模型参数</span></a></h2><p>对于用<code>Sequential</code>类构建的网络，我们可以简单地用<code>net[i]</code>调用指定层（i 的索引从 0 开始），用<code>parameters()</code>和<code>name_parameters()</code>调用参数，并且返回一个参数迭代器。</p><p>如：</p><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="language-python"><code>net <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">for</span> params <span class="token keyword">in</span> net<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span>：
    <span class="token keyword">print</span><span class="token punctuation">(</span>params<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment"># 输出结果为：</span>
torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">10</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

<span class="token keyword">for</span> name<span class="token punctuation">,</span>params <span class="token keyword">in</span> net<span class="token punctuation">.</span>named_parameters<span class="token punctuation">(</span><span class="token punctuation">)</span>：
    <span class="token keyword">print</span><span class="token punctuation">(</span>name<span class="token punctuation">,</span>params<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment"># name_parameters() 输出带有名字的参数列表，输出结果为：</span>
<span class="token number">0</span><span class="token punctuation">.</span>weight torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token number">0</span><span class="token punctuation">.</span>bias torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">10</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token number">2</span><span class="token punctuation">.</span>weight torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token number">2</span><span class="token punctuation">.</span>bias torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><div class="hint-container tip"><p class="hint-container-title">params 的对象类型</p><p><code>params</code>本质上也是一个<code>Tesnor</code>张量，其类型为<code>torch.nn.parameter.Parameter</code>，可以与<code>Tensor</code>有同样的操作，如<code>.data</code>读取数据，<code>.grad</code>求取梯度。</p></div><h2 id="初始化模型参数" tabindex="-1"><a class="header-anchor" href="#初始化模型参数"><span>初始化模型参数</span></a></h2><p>一般来说，我们需要对权重赋予正态分布的初始化，对偏差清零，赋予常数的初始化，我们可以通过参数的名字对参数进行区分：</p><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="language-python"><code><span class="token keyword">for</span> name<span class="token punctuation">,</span> param <span class="token keyword">in</span> net<span class="token punctuation">.</span>named_parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
  <span class="token keyword">if</span> <span class="token string">&quot;weight&quot;</span> <span class="token keyword">in</span> name<span class="token punctuation">:</span>
    init<span class="token punctuation">.</span>normal_<span class="token punctuation">(</span>param<span class="token punctuation">,</span>mean<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span>std<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">)</span>
  <span class="token keyword">if</span> <span class="token string">&quot;bias&quot;</span> <span class="token keyword">in</span> name<span class="token punctuation">:</span>
    init<span class="token punctuation">.</span>constant_<span class="token punctuation">(</span>param<span class="token punctuation">,</span>val <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="自定义初始化方法" tabindex="-1"><a class="header-anchor" href="#自定义初始化方法"><span>自定义初始化方法</span></a></h3><p><code>pytorch</code>中对一个张量初始化是不记录梯度的，所以我们需要在<code>with tensor.no_grad()</code>环境里配置，比如说初始化使得整体分布于（0,0.01）的标准正态分布，但是权重有一半的概率初始化为 0，另一半参数大于 0。可以这么定义初始化函数：</p><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="language-python"><code><span class="token keyword">def</span> <span class="token function">init_weight_</span><span class="token punctuation">(</span>tensor<span class="token punctuation">,</span> mean<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> std<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
  <span class="token keyword">with</span> tensor<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    tensor<span class="token punctuation">.</span>normal_<span class="token punctuation">(</span>mean<span class="token punctuation">,</span>std<span class="token punctuation">)</span>
    tensor <span class="token operator">*=</span> <span class="token punctuation">(</span>tensor<span class="token operator">&gt;</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token keyword">for</span> name<span class="token punctuation">,</span> param <span class="token keyword">in</span> net<span class="token punctuation">.</span>named_parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
  <span class="token keyword">if</span> <span class="token string">&quot;weight&quot;</span> <span class="token keyword">in</span> name<span class="token punctuation">:</span>
    init_weight_<span class="token punctuation">(</span>param<span class="token punctuation">,</span>mean<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span>std<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">)</span>
</code></pre><div class="highlight-lines"><br><div class="highlight-line"> </div><br><div class="highlight-line"> </div><br><br><br><br></div><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="共享模型参数" tabindex="-1"><a class="header-anchor" href="#共享模型参数"><span>共享模型参数</span></a></h3><p>只要保证两个层来自同一个数据寄存器（或者说来自同一个变量），即可保证参数共享。如：</p><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="language-python"><code>linear <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">)</span>
net <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>linear<span class="token punctuation">,</span>linear<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token builtin">id</span><span class="token punctuation">(</span>net<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">==</span><span class="token builtin">id</span><span class="token punctuation">(</span>net<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token builtin">id</span><span class="token punctuation">(</span>net<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>weight<span class="token punctuation">)</span><span class="token operator">==</span><span class="token builtin">id</span><span class="token punctuation">(</span>net<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>weight<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment"># 输出</span>
<span class="token boolean">True</span>
<span class="token boolean">True</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><div class="hint-container tip"><p class="hint-container-title">值得注意的是</p><p>在反向传播过程中，这两层的参数梯度是累加的。</p></div><h2 id="自定义层" tabindex="-1"><a class="header-anchor" href="#自定义层"><span>自定义层</span></a></h2><p>如前所说，<code>Module</code>这玩意是很宽泛的，可以继承它然后来构建很多自定义层。自定义层又分为两种：</p><ul><li>不带模型参数的自定义层</li><li>带模型参数的自定义层</li></ul><blockquote><p>不带模型参数的自定义层好理解，类似<code>FlattenLayer</code>就是一个不带模型参数的自定义层</p></blockquote><p><strong>本文着重讨论带模型参数的自定义层。</strong></p><p>由前文可知，模型参数应该是<code>Parameter</code>类型的，也是<code>Tensor</code>的子类，所以我们在继承类的<code>__init__()</code>函数中，应该通过<code>nn.Parameter()</code>来定义模型参数（定义方式与<code>Tensor</code>一致），指定的参数名字也会被<code>name_parameters()</code>读取。也可以通过<code>ParameterList()</code>或<code>ParameterDict()</code>类型来定义（输入一个<code>Parameter</code>列表或字典），举例如下：</p><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="language-python"><code><span class="token keyword">class</span> <span class="token class-name">MyDense</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>MyDense<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>params <span class="token operator">=</span> nn<span class="token punctuation">.</span>ParameterList<span class="token punctuation">(</span><span class="token punctuation">[</span>nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>params<span class="token punctuation">.</span>append<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>params<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            x <span class="token operator">=</span> torch<span class="token punctuation">.</span>mm<span class="token punctuation">(</span>x<span class="token punctuation">,</span> self<span class="token punctuation">.</span>params<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> x
net <span class="token operator">=</span> MyDense<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>net<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="torchvision-transforms实例" tabindex="-1"><a class="header-anchor" href="#torchvision-transforms实例"><span><code>Torchvision.transforms</code>实例</span></a></h2><p><code>torchvision.transforms</code>提供了多种实例对数据集进行操作，多用于数据增强、图像增广。</p><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="language-python"><code>torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>Resize<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment"># 提供了重置大小转换器</span>
torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>CenterCrop<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment"># 中心裁剪</span>
torchvision<span class="token punctuation">.</span>transfotms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment"># 将数据转换为\`Tensor\`</span>
torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>Normalize<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment"># 将数据归一化</span>
torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>RandomHorizontalFlip<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment"># 随机水平翻转</span>
torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>RandomVerticalFlip<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment"># 随机垂直翻转</span>
torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>RandomResizedCrop<span class="token punctuation">(</span><span class="token number">200</span><span class="token punctuation">,</span> scale<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">0.1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> ratio<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment"># 随机裁剪出一块面积为原面积 10%∼100% 的区域，且该区域的宽和高之比随机取自 0.5∼2，然后再将该区域的宽和高分别缩放到 200 像素</span>
torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>ColorJitter<span class="token punctuation">(</span>brightness<span class="token punctuation">,</span> hue<span class="token punctuation">,</span> contrast<span class="token punctuation">,</span> saturation<span class="token punctuation">)</span>
<span class="token comment"># 改变图像颜色，参数分别是亮度、色调、对比度、饱和度</span>

<span class="token comment"># 以上转换器可以按顺序放进列表结构中，通过\`Compose\`实例串联使用</span>
torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span>trans<span class="token punctuation">:</span> <span class="token builtin">list</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div>`,25),z=s("code",null,"AlexNet",-1),D=s("h2",{id:"pytorch-保存和加载模型",tabindex:"-1"},[s("a",{class:"header-anchor",href:"#pytorch-保存和加载模型"},[s("span",null,"Pytorch 保存和加载模型")])],-1),q={href:"https://tangshusen.me/Dive-into-DL-PyTorch/#/chapter04_DL_computation/4.5_read-write",target:"_blank",rel:"noopener noreferrer"},N=s("h2",{id:"pytorch-导入-gpu-计算",tabindex:"-1"},[s("a",{class:"header-anchor",href:"#pytorch-导入-gpu-计算"},[s("span",null,"Pytorch 导入 GPU 计算")])],-1),C={href:"https://tangshusen.me/Dive-into-DL-PyTorch/#/chapter04_DL_computation/4.6_use-gpu",target:"_blank",rel:"noopener noreferrer"},A=s("h2",{id:"深度学习相关概念",tabindex:"-1"},[s("a",{class:"header-anchor",href:"#深度学习相关概念"},[s("span",null,"深度学习相关概念")])],-1),O=s("h3",{id:"感受野",tabindex:"-1"},[s("a",{class:"header-anchor",href:"#感受野"},[s("span",null,"感受野")])],-1),B={href:"https://zhuanlan.zhihu.com/p/28492837",target:"_blank",rel:"noopener noreferrer"},E=s("p",null,"在一定的感受野下，我们愿意选择较小的卷积核，以此来获得更深的网络深度，学习更为复杂的全局特征，同时更小的卷积核意味着我们可以在较少的计算量下完成特征提取。",-1),F=s("h3",{id:"iou-交并比",tabindex:"-1"},[s("a",{class:"header-anchor",href:"#iou-交并比"},[s("span",null,"IOU（交并比）")])],-1),S={href:"https://zhuanlan.zhihu.com/p/111013447",target:"_blank",rel:"noopener noreferrer"},Y=s("p",null,"IOU 其实是 Intersection over Union 的简称，也叫‘交并比’。IoU 在目标检测以及语义分割中，都有着至关重要的作用。",-1),R=s("p",{class:"katex-block"},[s("span",{class:"katex-display"},[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},[s("semantics",null,[s("mrow",null,[s("mi",null,"I"),s("mi",null,"O"),s("mi",null,"U"),s("mo",null,"="),s("mfrac",null,[s("mrow",null,[s("mi",{mathvariant:"normal"},"∣"),s("mi",null,"A"),s("mo",null,"∩"),s("mi",null,"B"),s("mi",{mathvariant:"normal"},"∣")]),s("mrow",null,[s("mi",{mathvariant:"normal"},"∣"),s("mi",null,"A"),s("mo",null,"∪"),s("mi",null,"B"),s("mi",{mathvariant:"normal"},"∣")])])]),s("annotation",{encoding:"application/x-tex"}," IOU=\\frac{|A\\cap B|}{|A\\cup B|} ")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.6833em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.07847em"}},"I"),s("span",{class:"mord mathnormal",style:{"margin-right":"0.02778em"}},"O"),s("span",{class:"mord mathnormal",style:{"margin-right":"0.10903em"}},"U"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"2.363em","vertical-align":"-0.936em"}}),s("span",{class:"mord"},[s("span",{class:"mopen nulldelimiter"}),s("span",{class:"mfrac"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.427em"}},[s("span",{style:{top:"-2.314em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"},[s("span",{class:"mord"},"∣"),s("span",{class:"mord mathnormal"},"A"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"∪"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.05017em"}},"B"),s("span",{class:"mord"},"∣")])]),s("span",{style:{top:"-3.23em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"frac-line",style:{"border-bottom-width":"0.04em"}})]),s("span",{style:{top:"-3.677em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"},[s("span",{class:"mord"},"∣"),s("span",{class:"mord mathnormal"},"A"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"∩"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.05017em"}},"B"),s("span",{class:"mord"},"∣")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.936em"}},[s("span")])])])]),s("span",{class:"mclose nulldelimiter"})])])])])])],-1),G=s("p",null,"用该物理量表示两个图像框的相似度。 优点：",-1),Z=s("ol",null,[s("li",null,"具有尺度不变性；"),s("li",null,"满足非负性；"),s("li",null,"满足对称性；")],-1),V=s("div",{class:"hint-container warning"},[s("p",{class:"hint-container-title"},"缺点"),s("p",null,[n("如果"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",{mathvariant:"normal"},"∣"),s("mi",null,"A"),s("mo",null,"∩"),s("mi",null,"B"),s("mi",{mathvariant:"normal"},"∣"),s("mo",null,"="),s("mn",null,"0")]),s("annotation",{encoding:"application/x-tex"},"|A\\cap B|=0")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord"},"∣"),s("span",{class:"mord mathnormal"},"A"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"∩"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.05017em"}},"B"),s("span",{class:"mord"},"∣"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.6444em"}}),s("span",{class:"mord"},"0")])])]),n("，即：两个图像没有相交时，无法比较两个图像的远近")]),s("p",null,"同时无法体现两个图像是如何相交的")],-1),j=s("h4",{id:"giou",tabindex:"-1"},[s("a",{class:"header-anchor",href:"#giou"},[s("span",null,"GIOU")])],-1),H=s("p",null,"它能在更广义的层面上计算 IoU，并解决刚才我们说的‘两个图像没有相交时，无法比较两个图像的距离远近’的问题。",-1),J=s("p",{class:"katex-block"},[s("span",{class:"katex-display"},[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},[s("semantics",null,[s("mrow",null,[s("mi",null,"G"),s("mi",null,"L"),s("mi",null,"O"),s("mi",null,"U"),s("mo",null,"="),s("mi",null,"I"),s("mi",null,"O"),s("mi",null,"U"),s("mo",null,"−"),s("mfrac",null,[s("mrow",null,[s("mi",{mathvariant:"normal"},"∣"),s("mi",null,"C"),s("mo",null,"−"),s("mo",{stretchy:"false"},"("),s("mi",null,"A"),s("mo",null,"∪"),s("mi",null,"B"),s("mo",{stretchy:"false"},")"),s("mi",{mathvariant:"normal"},"∣")]),s("mi",null,"C")])]),s("annotation",{encoding:"application/x-tex"}," GLOU=IOU-\\frac{|C-(A\\cup B)|}{C} ")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.6833em"}}),s("span",{class:"mord mathnormal"},"G"),s("span",{class:"mord mathnormal"},"L"),s("span",{class:"mord mathnormal",style:{"margin-right":"0.02778em"}},"O"),s("span",{class:"mord mathnormal",style:{"margin-right":"0.10903em"}},"U"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.7667em","vertical-align":"-0.0833em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.07847em"}},"I"),s("span",{class:"mord mathnormal",style:{"margin-right":"0.02778em"}},"O"),s("span",{class:"mord mathnormal",style:{"margin-right":"0.10903em"}},"U"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"−"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"2.113em","vertical-align":"-0.686em"}}),s("span",{class:"mord"},[s("span",{class:"mopen nulldelimiter"}),s("span",{class:"mfrac"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.427em"}},[s("span",{style:{top:"-2.314em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.07153em"}},"C")])]),s("span",{style:{top:"-3.23em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"frac-line",style:{"border-bottom-width":"0.04em"}})]),s("span",{style:{top:"-3.677em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"},[s("span",{class:"mord"},"∣"),s("span",{class:"mord mathnormal",style:{"margin-right":"0.07153em"}},"C"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"−"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal"},"A"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"∪"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.05017em"}},"B"),s("span",{class:"mclose"},")"),s("span",{class:"mord"},"∣")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.686em"}},[s("span")])])])]),s("span",{class:"mclose nulldelimiter"})])])])])])],-1),X=s("p",null,[n("其中，"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"C")]),s("annotation",{encoding:"application/x-tex"},"C")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.6833em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.07153em"}},"C")])])]),n("代表两个图像的最小包庇面积，也可以理解为这两个图像的最小外接矩形面积")],-1),K=s("p",null,[s("strong",null,"GIoU 完善了图像重叠度的计算功能，但仍无法对图形距离以及长宽比的相似性进行很好的表示。")],-1),Q=s("h3",{id:"diou",tabindex:"-1"},[s("a",{class:"header-anchor",href:"#diou"},[s("span",null,"DIOU")])],-1),W=s("p",null,"GIoU 虽然解决了 IoU 的一些问题，但是它并不能直接反映预测框与目标框之间的距离，DIoU（Distance-IoU）即可解决这个问题，它将两个框之间的重叠度、距离、尺度都考虑了进来，DIoU 的计算公式如下：",-1),$=s("p",{class:"katex-block"},[s("span",{class:"katex-display"},[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},[s("semantics",null,[s("mrow",null,[s("mi",null,"D"),s("mi",null,"I"),s("mi",null,"O"),s("mi",null,"U"),s("mo",null,"="),s("mi",null,"I"),s("mi",null,"O"),s("mi",null,"U"),s("mo",null,"−"),s("mfrac",null,[s("mrow",null,[s("msup",null,[s("mi",null,"ρ"),s("mn",null,"2")]),s("mo",{stretchy:"false"},"("),s("mi",null,"b"),s("mo",{separator:"true"},","),s("msup",null,[s("mi",null,"b"),s("mrow",null,[s("mi",null,"g"),s("mi",null,"t")])]),s("mo",{stretchy:"false"},")")]),s("msup",null,[s("mi",null,"c"),s("mn",null,"2")])])]),s("annotation",{encoding:"application/x-tex"}," DIOU=IOU-\\frac{\\rho^2(b,b^{gt})}{c^2} ")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.6833em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.02778em"}},"D"),s("span",{class:"mord mathnormal",style:{"margin-right":"0.07847em"}},"I"),s("span",{class:"mord mathnormal",style:{"margin-right":"0.02778em"}},"O"),s("span",{class:"mord mathnormal",style:{"margin-right":"0.10903em"}},"U"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.7667em","vertical-align":"-0.0833em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.07847em"}},"I"),s("span",{class:"mord mathnormal",style:{"margin-right":"0.02778em"}},"O"),s("span",{class:"mord mathnormal",style:{"margin-right":"0.10903em"}},"U"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"−"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"2.1771em","vertical-align":"-0.686em"}}),s("span",{class:"mord"},[s("span",{class:"mopen nulldelimiter"}),s("span",{class:"mfrac"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.4911em"}},[s("span",{style:{top:"-2.314em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"},[s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"c"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.7401em"}},[s("span",{style:{top:"-2.989em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},"2")])])])])])])])])]),s("span",{style:{top:"-3.23em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"frac-line",style:{"border-bottom-width":"0.04em"}})]),s("span",{style:{top:"-3.677em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"},[s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"ρ"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8141em"}},[s("span",{style:{top:"-3.063em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},"2")])])])])])])]),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal"},"b"),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"b"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.7936em"}},[s("span",{style:{top:"-3.063em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.03588em"}},"g"),s("span",{class:"mord mathnormal mtight"},"t")])])])])])])])]),s("span",{class:"mclose"},")")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.686em"}},[s("span")])])])]),s("span",{class:"mclose nulldelimiter"})])])])])])],-1),ss=s("p",null,[n("其中，"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"b")]),s("annotation",{encoding:"application/x-tex"},"b")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.6944em"}}),s("span",{class:"mord mathnormal"},"b")])])]),n("，"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("msup",null,[s("mi",null,"b"),s("mrow",null,[s("mi",null,"g"),s("mi",null,"t")])])]),s("annotation",{encoding:"application/x-tex"},"b^{gt}")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.7936em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"b"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.7936em"}},[s("span",{style:{top:"-3.063em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.03588em"}},"g"),s("span",{class:"mord mathnormal mtight"},"t")])])])])])])])])])])]),n("代表两个框的中心点，"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"ρ")]),s("annotation",{encoding:"application/x-tex"},"\\rho")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.625em","vertical-align":"-0.1944em"}}),s("span",{class:"mord mathnormal"},"ρ")])])]),n("代表两个中心点之间的欧氏距离，"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"c")]),s("annotation",{encoding:"application/x-tex"},"c")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.4306em"}}),s("span",{class:"mord mathnormal"},"c")])])]),n(" 表示最小包庇矩形的对角线长")],-1),ns=t('<figure><img src="https://raw.githubusercontent.com/dream-oyh/dream-oyh.github.io/images/DIOU.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><ul><li>DIoU 可直接最小化两个框之间的距离，所以作为损失函数的时候 Loss 收敛的更快；</li><li>在两个框完全上下排列或左右排列时，没有空白区域，此时 GIoU 几乎退化为了 IoU，但是 DIoU 仍然有效。</li></ul><h2 id="评价指标" tabindex="-1"><a class="header-anchor" href="#评价指标"><span>评价指标</span></a></h2><h3 id="混淆矩阵" tabindex="-1"><a class="header-anchor" href="#混淆矩阵"><span>混淆矩阵</span></a></h3><p>混淆矩阵是一个<code>nxn</code>的网格，横轴表示真实值，纵轴表示预测值，每一个小方块的坐标是（真实值，预测值），即：真实值是<code>x</code>，但是被预测为<code>y</code>，如果<code>y</code>和<code>x</code>相同，也就是说在对角线上的格子，是预测符合实际的结果。</p><p>但是机器学习里为了更好地描述预测结果，给出了四个指标（TP,FP,FN,YN），很容易混淆 <s>（因此称作混淆矩阵）</s>，现将其记录如下，并且从 <a href="#0-1-%E9%A2%84%E6%B5%8B">0-1 预测</a>拓展至<a href="#%E5%A4%9A%E7%B1%BB%E9%A2%84%E6%B5%8B">多类预测</a>。</p><h4 id="_0-1-预测" tabindex="-1"><a class="header-anchor" href="#_0-1-预测"><span>0-1 预测</span></a></h4><p>混淆矩阵示意图：</p><figure><img src="https://raw.githubusercontent.com/dream-oyh/dream-oyh.github.io/images/Python_pytorch/confusion_matrix.png" alt="" width="200" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>根据混淆矩阵定义：</p><ul><li><code>A1</code>处的数字表示：80% 的真实值为<code>yes</code>的数据被预测为了<code>Yes</code></li><li><code>B1</code>处的数字表示：40% 的真实值为<code>No</code>的数据被预测为了<code>Yes</code></li><li>其余以此类推</li></ul><p>下面给出四个指标在 0-1 预测下的定义 <mark>（极其容易搞混，多看多记多理解）</mark></p><p>先解释一下四个字母的由来，分别代表如下所示的单词：</p><table><thead><tr><th style="text-align:center;">T</th><th style="text-align:center;">F</th><th style="text-align:center;">P</th><th style="text-align:center;">N</th></tr></thead><tbody><tr><td style="text-align:center;">True</td><td style="text-align:center;">False</td><td style="text-align:center;">Positive</td><td style="text-align:center;">Negative</td></tr></tbody></table><ul><li><code>TP</code>：表示某对象的被预测值是<code>Yes</code>，并且其实际值与预测值相符，也是<code>Yes</code></li><li><code>TN</code>: 表示某对象的被预测值是<code>No</code>，并且其实际值与预测值相符，也是<code>No</code></li><li><code>FP</code>: 表示某对象的被预测值是<code>Yes</code>，但是其实际值与预测值相悖，是<code>No</code></li><li><code>FN</code>: 表示某对象的被预测值是<code>No</code>，但是其实际值与预测值相悖，是<code>Yes</code></li></ul><p>故这四个指标的分布应该如下所示（横轴真实值，纵轴预测值）：</p><table><thead><tr><th style="text-align:center;"></th><th style="text-align:center;">Yes</th><th style="text-align:center;">No</th></tr></thead><tbody><tr><td style="text-align:center;">Yes</td><td style="text-align:center;">TP</td><td style="text-align:center;">FP</td></tr><tr><td style="text-align:center;">No</td><td style="text-align:center;">FN</td><td style="text-align:center;">TN</td></tr></tbody></table><div class="hint-container important"><p class="hint-container-title">理解</p><p><strong>对 P、N 的理解</strong></p><p>P、N 表示的是预测值的正/负，但具体是哪个标签叫做正，哪个标签叫做负，是由人来决定的，我们这里默认预测为<code>Yes</code>时，预测值是<code>Positive</code>的。</p><blockquote><p>你当然可以说我要的是<code>No</code>标签，那此时预测出<code>No</code>就得用<code>P</code>表示（也从此我们可以引出多种类别的预测）</p></blockquote><p><strong>对 T、F 的理解</strong></p><p>T、F 表示的是实际值与预测值是否相反。如果是<code>T</code>，说明实际值与预测值相同；如果是<code>F</code>，说明实际值与预测值相反。</p><blockquote><p>这也是为什么我要先写<code>对P、N的理解</code>再来写<code>对T、F的理解</code>，因为我们是先看的后边字母，再看的前边字母，才能得到这个指标对应的预测值和实际值都是什么标签。</p></blockquote></div><h4 id="多类预测" tabindex="-1"><a class="header-anchor" href="#多类预测"><span>多类预测</span></a></h4>',19),as=s("p",null,[n("结合 0-1 预测的概念，我们可以将这四个极易混淆的指标推导到多类预测的情况下，多类预测的混淆矩阵是一个"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"n"),s("mo",null,"×"),s("mi",null,"n")]),s("annotation",{encoding:"application/x-tex"},"n\\times n")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.6667em","vertical-align":"-0.0833em"}}),s("span",{class:"mord mathnormal"},"n"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"×"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.4306em"}}),s("span",{class:"mord mathnormal"},"n")])])]),n("的矩阵，如图所示。")],-1),ts=t('<figure><img src="https://raw.githubusercontent.com/dream-oyh/dream-oyh.github.io/images/Python_pytorch/confusion_matrix_multi.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>与 0-1 预测类似，多类预测里的<code>P</code>与<code>N</code>是针对某一个标签而言的，比如说上图种我需要的是<code>Crack</code>类别，那预测值为<code>Crack</code>就是<code>Positive</code>的，预测值不是<code>Crack</code>的统统归为<code>Negative</code>，因此可以得到多类预测下四个指标的解释：</p><ul><li><code>TP</code>：表示某对象的被预测值是<code>Crack</code>，并且其实际值与预测值相符，也是<code>Crack</code></li><li><code>TN</code>: 表示某对象的被预测值<mark>不</mark>是<code>Crack</code>，并且其实际值与预测值相符，也<mark>不</mark>是<code>Crack</code></li><li><code>FP</code>: 表示某对象的被预测值是<code>Crack</code>，但是其实际值与预测值相悖，<mark>不</mark>是<code>Crack</code></li><li><code>FN</code>: 表示某对象的被预测值<mark>不</mark>是<code>Crack</code>，但是其实际值与预测值相悖，是<code>Crack</code></li></ul><h3 id="召回率与准确率" tabindex="-1"><a class="header-anchor" href="#召回率与准确率"><span>召回率与准确率</span></a></h3><p>因此可以得到召回率与准确率的定义：</p><ul><li>召回率</li></ul><p>召回率描述的是实际值为<code>Yes</code>的标签中有多少被正确预测了。</p>',7),es=s("p",{class:"katex-block"},[s("span",{class:"katex-display"},[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},[s("semantics",null,[s("mrow",null,[s("msub",null,[s("mi",null,"w"),s("mtext",null,"召回")]),s("mo",null,"="),s("mfrac",null,[s("mrow",null,[s("mi",null,"T"),s("mi",null,"P")]),s("mrow",null,[s("mi",null,"T"),s("mi",null,"P"),s("mo",null,"+"),s("mi",null,"F"),s("mi",null,"N")])])]),s("annotation",{encoding:"application/x-tex"}," w_{\\text{召回}} = \\frac{TP}{TP+FN} ")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.5806em","vertical-align":"-0.15em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.02691em"}},"w"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3283em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0269em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord text mtight"},[s("span",{class:"mord cjk_fallback mtight"},"召回")])])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"2.1297em","vertical-align":"-0.7693em"}}),s("span",{class:"mord"},[s("span",{class:"mopen nulldelimiter"}),s("span",{class:"mfrac"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.3603em"}},[s("span",{style:{top:"-2.314em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.13889em"}},"TP"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"+"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.10903em"}},"FN")])]),s("span",{style:{top:"-3.23em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"frac-line",style:{"border-bottom-width":"0.04em"}})]),s("span",{style:{top:"-3.677em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.13889em"}},"TP")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.7693em"}},[s("span")])])])]),s("span",{class:"mclose nulldelimiter"})])])])])])],-1),ls=s("ul",null,[s("li",null,"准确率")],-1),ps=s("p",null,[n("准确率描述的是预测出"),s("code",null,"Yes"),n("的标签中，有哪些是和实际值相符的。")],-1),os=s("p",{class:"katex-block"},[s("span",{class:"katex-display"},[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},[s("semantics",null,[s("mrow",null,[s("msub",null,[s("mi",null,"w"),s("mtext",null,"准确")]),s("mo",null,"="),s("mfrac",null,[s("mrow",null,[s("mi",null,"T"),s("mi",null,"P")]),s("mrow",null,[s("mi",null,"T"),s("mi",null,"P"),s("mo",null,"+"),s("mi",null,"F"),s("mi",null,"P")])])]),s("annotation",{encoding:"application/x-tex"}," w_{\\text{准确}} = \\frac{TP}{TP+FP} ")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.5806em","vertical-align":"-0.15em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.02691em"}},"w"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3283em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0269em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord text mtight"},[s("span",{class:"mord cjk_fallback mtight"},"准确")])])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"2.1297em","vertical-align":"-0.7693em"}}),s("span",{class:"mord"},[s("span",{class:"mopen nulldelimiter"}),s("span",{class:"mfrac"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.3603em"}},[s("span",{style:{top:"-2.314em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.13889em"}},"TP"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"+"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.13889em"}},"FP")])]),s("span",{style:{top:"-3.23em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"frac-line",style:{"border-bottom-width":"0.04em"}})]),s("span",{style:{top:"-3.677em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.13889em"}},"TP")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.7693em"}},[s("span")])])])]),s("span",{class:"mclose nulldelimiter"})])])])])])],-1),cs=t('<h3 id="confidence-与-iou-阈值" tabindex="-1"><a class="header-anchor" href="#confidence-与-iou-阈值"><span>Confidence 与 IOU 阈值</span></a></h3><p>二者虽然类似，但是有很大的差别。</p><ul><li><em>Confidence</em>是基于预测框的预测值来定义的，<em>confidence</em>定义了大于多少置信度的预测框才会被认为是有效的。比如说某个物体，AI 模型认为他有 0.5 的概率是 X（即：预测框的置信度是 0.5），若此时<em>confidence</em>调成 0.4，则该框会输出在最终图上，若此时<em>confidence</em>设置成 0.6，则该框不会输出在最终图上。 <blockquote><p>最佳的<em>confidence</em>应该从输出结果图中<em>F1-confidence</em>曲线来判断，取<em>F1</em>为最高点时对应的<em>confidence</em>即可，千万不要根据测试集去改<em>confidence</em>，我们因为这点在中南自院计算机视觉比赛中吃了大亏。</p></blockquote></li><li><em>IOU_conf</em> 是用来抑制多余框的，如果<em>IOU_conf=1</em>，此时输出图中会有非常非常多重合的框，因为此时 AI 认为，只有当两个框完全重合（即：此时两个框的 IOU 为 1）时，才可以认为这是同一个框，才可以去除其中一个。而例如，当<em>IOU_conf=0.8</em>时，系统认为两个框要重合到 <em>&gt;0.8</em> 时，才可以认为这是同一个框。</li></ul>',3);function is(rs,us){const l=o("RouteLink"),e=o("ExternalLinkIcon");return i(),r("div",null,[m,s("p",null,[d,n("中，各层模型可以以多种方式输入，这一点在"),a(l,{to:"/code/python/pytorch/2.1linear_regression.html#%E5%AE%9A%E4%B9%89%E6%A8%A1%E5%9E%8B"},{default:p(()=>[n("线性回归实现的笔记")]),_:1}),n("中有提到，总的来说，模型参数支持 直接输入各层、输入有序字典"),h,n("或通过"),k,n("函数添加。")]),g,s("div",y,[v,s("p",null,[n("我们在"),a(l,{to:"/code/python/pytorch/2.3softmax.html#%E5%AE%9A%E4%B9%89%E5%92%8C%E5%88%9D%E5%A7%8B%E5%8C%96%E6%A8%A1%E5%9E%8B"},{default:p(()=>[n("softmax")]),_:1}),n("中定义了一个"),b,n("层，这个层不同于一般印象里的线性计算，他只是一个"),_,n("的操作，但是我们把这也叫做一个层。也因为如此，我们对于"),f,n("的认识应该更广泛一些，"),x,n("提供的"),w,n("函数可以看作是这个层的"),M,n("，一种广义上的行为，而不只是前向传播。")]),s("p",null,[n("对于"),s("a",P,[n("丢弃法 (Dropout)"),a(e)]),n("，"),T,n("也提供了"),U,n("层，以方便使用。我们需要在全连接层之后加入"),L,n("层，它将在训练模型中以指定的丢弃概率随机丢弃一部分神经元，而在测试模型中不发挥作用。")])]),I,s("p",null,[n("具体应用实例可以见"),a(l,{to:"/code/python/pytorch/4.3AlexNet.html#%E8%AF%BB%E5%8F%96%E6%95%B0%E6%8D%AE"},{default:p(()=>[z,n("模型")]),_:1})]),D,s("p",null,[s("a",q,[n("查看文档链接"),a(e)])]),N,s("p",null,[s("a",C,[n("查看文档链接"),a(e)])]),A,O,s("p",null,[n("有关感受野可以看"),s("a",B,[n("这篇文章"),a(e)])]),E,F,s("p",null,[n("Source:"),s("a",S,[n("目标检测基础模块之 IoU 及优化 - 知乎 (zhihu.com)"),a(e)])]),Y,R,G,Z,V,j,H,J,X,K,Q,W,$,ss,ns,as,ts,es,ls,ps,os,cs])}const hs=c(u,[["render",is],["__file","3.1Deeplearning_basic.html.vue"]]),ks=JSON.parse('{"path":"/code/python/pytorch/3.1Deeplearning_basic.html","title":"深度学习基础","lang":"zh-CN","frontmatter":{"date":"2024-02-18T00:00:00.000Z","description":"深度学习基础 模型构建 根据之前章节，我们已经能够发现，利用nn.Module和nn.Sequential可以很方便地构建模型，并且nn.Sequential本身也是nn.Module的一个继承类。所以，通过nn.Module来构建继承类也是非常通用的模型构建方式，一般来说，在继承类中我们会重载nn.Module的forward()函数，比如说我们可以...","head":[["meta",{"property":"og:url","content":"https://dream-oyh.github.io/code/python/pytorch/3.1Deeplearning_basic.html"}],["meta",{"property":"og:site_name","content":"Dream_oyh 的 blog"}],["meta",{"property":"og:title","content":"深度学习基础"}],["meta",{"property":"og:description","content":"深度学习基础 模型构建 根据之前章节，我们已经能够发现，利用nn.Module和nn.Sequential可以很方便地构建模型，并且nn.Sequential本身也是nn.Module的一个继承类。所以，通过nn.Module来构建继承类也是非常通用的模型构建方式，一般来说，在继承类中我们会重载nn.Module的forward()函数，比如说我们可以..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:image","content":"https://raw.githubusercontent.com/dream-oyh/dream-oyh.github.io/images/DIOU.png"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2024-03-18T16:27:30.000Z"}],["meta",{"property":"article:author","content":"OYH"}],["meta",{"property":"article:published_time","content":"2024-02-18T00:00:00.000Z"}],["meta",{"property":"article:modified_time","content":"2024-03-18T16:27:30.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"深度学习基础\\",\\"image\\":[\\"https://raw.githubusercontent.com/dream-oyh/dream-oyh.github.io/images/DIOU.png\\",\\"https://raw.githubusercontent.com/dream-oyh/dream-oyh.github.io/images/Python_pytorch/confusion_matrix.png =200x\\",\\"https://raw.githubusercontent.com/dream-oyh/dream-oyh.github.io/images/Python_pytorch/confusion_matrix_multi.png\\"],\\"datePublished\\":\\"2024-02-18T00:00:00.000Z\\",\\"dateModified\\":\\"2024-03-18T16:27:30.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"OYH\\",\\"email\\":\\"19859860010@163.com\\"}]}"]]},"headers":[{"level":2,"title":"模型构建","slug":"模型构建","link":"#模型构建","children":[{"level":3,"title":"nn.Module的子类","slug":"nn-module的子类","link":"#nn-module的子类","children":[]}]},{"level":2,"title":"访问模型参数","slug":"访问模型参数","link":"#访问模型参数","children":[]},{"level":2,"title":"初始化模型参数","slug":"初始化模型参数","link":"#初始化模型参数","children":[{"level":3,"title":"自定义初始化方法","slug":"自定义初始化方法","link":"#自定义初始化方法","children":[]},{"level":3,"title":"共享模型参数","slug":"共享模型参数","link":"#共享模型参数","children":[]}]},{"level":2,"title":"自定义层","slug":"自定义层","link":"#自定义层","children":[]},{"level":2,"title":"Torchvision.transforms实例","slug":"torchvision-transforms实例","link":"#torchvision-transforms实例","children":[]},{"level":2,"title":"Pytorch 保存和加载模型","slug":"pytorch-保存和加载模型","link":"#pytorch-保存和加载模型","children":[]},{"level":2,"title":"Pytorch 导入 GPU 计算","slug":"pytorch-导入-gpu-计算","link":"#pytorch-导入-gpu-计算","children":[]},{"level":2,"title":"深度学习相关概念","slug":"深度学习相关概念","link":"#深度学习相关概念","children":[{"level":3,"title":"感受野","slug":"感受野","link":"#感受野","children":[]},{"level":3,"title":"IOU（交并比）","slug":"iou-交并比","link":"#iou-交并比","children":[]},{"level":3,"title":"DIOU","slug":"diou","link":"#diou","children":[]}]},{"level":2,"title":"评价指标","slug":"评价指标","link":"#评价指标","children":[{"level":3,"title":"混淆矩阵","slug":"混淆矩阵","link":"#混淆矩阵","children":[]},{"level":3,"title":"召回率与准确率","slug":"召回率与准确率","link":"#召回率与准确率","children":[]},{"level":3,"title":"Confidence 与 IOU 阈值","slug":"confidence-与-iou-阈值","link":"#confidence-与-iou-阈值","children":[]}]}],"git":{"createdTime":1708262283000,"updatedTime":1710779250000,"contributors":[{"name":"dream同学0","email":"1399541701@qq.com","commits":4},{"name":"dream_linux","email":"1399541701@qq.com","commits":3}]},"readingTime":{"minutes":12.22,"words":3665},"filePathRelative":"code/python/pytorch/3.1Deeplearning_basic.md","localizedDate":"2024年2月18日","excerpt":"\\n<h2>模型构建</h2>\\n<p>根据之前章节，我们已经能够发现，利用<code>nn.Module</code>和<code>nn.Sequential</code>可以很方便地构建模型，并且<code>nn.Sequential</code>本身也是<code>nn.Module</code>的一个继承类。所以，通过<code>nn.Module</code>来构建继承类也是非常通用的模型构建方式，一般来说，在继承类中我们会重载<code>nn.Module</code>的<code>forward()</code>函数，比如说我们可以通过继承类很容易地构建一个多层感知机模型：</p>\\n","autoDesc":true}');export{hs as comp,ks as data};
