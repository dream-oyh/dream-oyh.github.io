import{_ as i}from"./plugin-vue_export-helper-DlAUqK2U.js";import{r as e,o as l,c as u,a as t,d as n,b as s,w as r,e as a}from"./app-B5yLcklx.js";const d={},k=a(`<h1 id="线性回归实现" tabindex="-1"><a class="header-anchor" href="#线性回归实现"><span>线性回归实现</span></a></h1><div class="hint-container tip"><p class="hint-container-title">需要导入模块</p><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="language-python"><code><span class="token keyword">import</span> torch
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">as</span> Data
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn

<span class="token keyword">from</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">import</span> init
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>optim <span class="token keyword">as</span> optim
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></div><p>线性回归实现的 pipes 如下所示：</p>`,3),m=a(`<h2 id="生成并制作数据集" tabindex="-1"><a class="header-anchor" href="#生成并制作数据集"><span>生成并制作数据集</span></a></h2><p>深度学习中，我们把自变量称作<code>features</code>，把因变量称作<code>labels</code>，我们要制作的数据集就是为了制作<mark>从 features 到 labels 的映射</mark>。</p><div class="language-python line-numbers-mode" data-ext="py" data-title="生成数据集"><pre class="language-python"><code><span class="token comment"># 生成数据集</span>
num_inputs <span class="token operator">=</span> <span class="token number">2</span>
num_examples <span class="token operator">=</span> <span class="token number">1000</span>
true_w <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">3.4</span><span class="token punctuation">]</span>
true_b <span class="token operator">=</span> <span class="token number">4.2</span>
features <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>
    np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>normal<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>num_examples<span class="token punctuation">,</span> num_inputs<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span><span class="token builtin">float</span>
<span class="token punctuation">)</span>
labels <span class="token operator">=</span> <span class="token punctuation">(</span>
    true_w<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">*</span> features<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span>
    <span class="token operator">+</span> true_w<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">*</span> features<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span>
    <span class="token operator">+</span> true_b
    <span class="token operator">+</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>normal<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0.01</span><span class="token punctuation">,</span> num_examples<span class="token punctuation">)</span>
<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>利用<code>torch.utils.data</code>库制作成数据集（建立映射），再定义<code>batch_size</code>，通过数据读取器从数据集里随机读取数据。</p><blockquote><p>这个什么“制作数据集”“数据读取器”的表述是基于我自己理解的自造词，并不代表官方描述</p></blockquote><div class="hint-container tip"><p class="hint-container-title">数据集和数据读取器的类型</p><p>数据集 (<code>Data.TensorDataset</code>) 的类型是<code>&lt;class &#39;torch.utils.data.dataset.TensorDataset&#39;&gt;</code></p><p>数据读取器 (<code>Data.DataLoader</code>) 的类型是<code>&lt;class &#39;torch.utils.data.dataloader.DataLoader&#39;&gt;</code></p></div><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="language-python"><code>batch_size <span class="token operator">=</span> <span class="token number">10</span>
dataset <span class="token operator">=</span> Data<span class="token punctuation">.</span>TensorDataset<span class="token punctuation">(</span>features<span class="token punctuation">,</span> labels<span class="token punctuation">)</span>
data_iter <span class="token operator">=</span> Data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>dataset<span class="token punctuation">,</span> batch_size<span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token builtin">type</span><span class="token punctuation">(</span>dataset<span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># &lt;class &#39;torch.utils.data.dataset.TensorDataset&#39;&gt;</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token builtin">type</span><span class="token punctuation">(</span>data_iter<span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment">#  &lt;class &#39;torch.utils.data.dataloader.DataLoader&#39;&gt;</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="定义模型" tabindex="-1"><a class="header-anchor" href="#定义模型"><span>定义模型</span></a></h2><p>Pytorch 包提供了大量预定义的<strong>层</strong>，我们只需要关注如何正确调用和排布这些层，以定义神经网络模型，这样能够使得线性回归实现变得简单。定义神经网络用到了<code>torch.nn</code>库。</p><p><code>nn</code>的核心数据结构是<code>Module</code>，它是一个抽象概念，既可以表示神经网络中的某个层（layer），也可以表示一个包含很多层的神经网络。在实际使用中，最常见的做法是继承<code>nn.Module</code>，撰写自己的网络/层。一个<code>nn.Module</code>实例应该包含一些层以及返回输出的前向传播（forward）方法。</p><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="language-python"><code><span class="token keyword">class</span> <span class="token class-name">LinearNet</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> n_feature<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>LinearNet<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>linear <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>n_feature<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
        <span class="token comment"># n_features 为特征数，即：num_inputs</span>
    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        y <span class="token operator">=</span> self<span class="token punctuation">.</span>linear<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token keyword">return</span> y

net <span class="token operator">=</span> LinearNet<span class="token punctuation">(</span>num_inputs<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token builtin">type</span><span class="token punctuation">(</span>linear_net<span class="token punctuation">.</span>linear<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># &lt;class &#39;torch.nn.modules.linear.Linear&#39;&gt;</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>net<span class="token punctuation">)</span>
<span class="token comment"># LinearNet((linear): Linear(in_features=2, out_features=1, bias=True))</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>值得说明的是，线性网络模型继承自<code>nn.Module</code>，定义的成员变量<code>linear</code>就是线性层的一个实例，可以通过输入 x，直接得到 y。</p>`,12),v={class:"hint-container tip"},b=a(`<p class="hint-container-title">nn.Sequential 提供了更方便的方式来构建网络模型</p><p><code>Sequential</code>是一个有序的容器，网络层将按照在传入<code>Sequential</code>的顺序依次被添加到计算图中</p><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="language-python"><code><span class="token comment"># 写法一</span>
net <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
    nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>num_inputs<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
    <span class="token comment"># 此处还可以传入其他层</span>
    <span class="token punctuation">)</span>

<span class="token comment"># 写法二</span>
net <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token punctuation">)</span>
net<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">&#39;linear&#39;</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>num_inputs<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment"># net.add_module ......</span>

<span class="token comment"># 写法三</span>
<span class="token keyword">from</span> collections <span class="token keyword">import</span> OrderedDict
net <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>OrderedDict<span class="token punctuation">(</span><span class="token punctuation">[</span>
          <span class="token punctuation">(</span><span class="token string">&#39;linear&#39;</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>num_inputs<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
          <span class="token comment"># ......</span>
        <span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span>net<span class="token punctuation">)</span>  <span class="token comment"># Sequential((linear): Linear(in_features=2, out_features=1, bias=True))</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>net<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>  <span class="token comment"># Linear(in_features=2, out_features=1, bias=True)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>本文采用正文中的类定义方式建模。</p>`,4),h=a(`<p>可以通过<code>net.parameters()</code>来查看模型所有的可学习参数，此函数将返回一个生成器。</p><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="language-python"><code><span class="token keyword">for</span> param <span class="token keyword">in</span> net<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>param<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div><p>输出得到的结果为：</p><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="language-python"><code>Parameter containing<span class="token punctuation">:</span>
tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.6155</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.1029</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
Parameter containing<span class="token punctuation">:</span>
tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.0955</span><span class="token punctuation">]</span><span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div>`,4),y=n("p",null,[s("即：生成了"),n("span",{class:"katex"},[n("span",{class:"katex-mathml"},[n("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[n("semantics",null,[n("mrow",null,[n("mi",null,"ω")]),n("annotation",{encoding:"application/x-tex"},"\\omega")])])]),n("span",{class:"katex-html","aria-hidden":"true"},[n("span",{class:"base"},[n("span",{class:"strut",style:{height:"0.4306em"}}),n("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"ω")])])]),s("与"),n("span",{class:"katex"},[n("span",{class:"katex-mathml"},[n("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[n("semantics",null,[n("mrow",null,[n("mi",null,"b")]),n("annotation",{encoding:"application/x-tex"},"b")])])]),n("span",{class:"katex-html","aria-hidden":"true"},[n("span",{class:"base"},[n("span",{class:"strut",style:{height:"0.6944em"}}),n("span",{class:"mord mathnormal"},"b")])])]),s("的初值，并且允许追踪梯度。")],-1),g=a(`<h2 id="初始化模型参数" tabindex="-1"><a class="header-anchor" href="#初始化模型参数"><span>初始化模型参数</span></a></h2><p>在使用 <code>net</code> 前，需要对线性回归层中的参数进行初始化。<code>torch.nn</code>中的<code>init</code>模块提供了多种初始化方法。</p><ul><li><code>init.normal_()</code> 将权重参数初始化为均值为 0，标准差为 0.01 的正态分布</li><li><code>init.constant_()</code> 将参数初始化为同一个固定值，例如 0</li></ul><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="language-python"><code>init<span class="token punctuation">.</span>normal_<span class="token punctuation">(</span>net<span class="token punctuation">.</span>linear<span class="token punctuation">.</span>weight<span class="token punctuation">,</span> mean<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> std<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">)</span>
init<span class="token punctuation">.</span>constant_<span class="token punctuation">(</span>net<span class="token punctuation">.</span>linear<span class="token punctuation">.</span>bias<span class="token punctuation">,</span> val<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div><blockquote><p>可以看出，线性层已经包括了<code>weight</code>和<code>bias</code>两个参数，不需要我们额外定义。</p></blockquote><h2 id="定义损失函数" tabindex="-1"><a class="header-anchor" href="#定义损失函数"><span>定义损失函数</span></a></h2><p><code>nn</code>模块提供了各种损失函数，这些损失函数可以看作特殊的层，这里定义均方误差 (Mean Square Error) 作为损失函数。</p><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="language-python"><code>loss <span class="token operator">=</span> nn<span class="token punctuation">.</span>MSELoss<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><h2 id="定义优化算法" tabindex="-1"><a class="header-anchor" href="#定义优化算法"><span>定义优化算法</span></a></h2><p><code>torch.optim</code>模块提供了各种优化算法，这里使用随机梯度下降（SGD）来更新模型参数，并指定学习率为 0.03。</p><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="language-python"><code>optimizer <span class="token operator">=</span> optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>net<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.03</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><div class="hint-container tip"><p class="hint-container-title">为不同的网络设定不同的学习率</p><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="language-python"><code>optimizer <span class="token operator">=</span>optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span><span class="token punctuation">[</span>
                <span class="token comment"># 如果对某个参数不指定学习率，就使用最外层的默认学习率</span>
                <span class="token punctuation">{</span><span class="token string">&#39;params&#39;</span><span class="token punctuation">:</span> net<span class="token punctuation">.</span>subnet1<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token comment"># lr=0.03</span>
                <span class="token punctuation">{</span><span class="token string">&#39;params&#39;</span><span class="token punctuation">:</span> net<span class="token punctuation">.</span>subnet2<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">&#39;lr&#39;</span><span class="token punctuation">:</span> <span class="token number">0.01</span><span class="token punctuation">}</span>
            <span class="token punctuation">]</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.03</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></div>`,12),_=n("code",null,"optim",-1),w={href:"https://tangshusen.me/Dive-into-DL-PyTorch/#/chapter03_DL-basics/3.12_weight-decay?id=_3121-%e6%96%b9%e6%b3%95",target:"_blank",rel:"noopener noreferrer"},f=a(`<div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="language-python"><code>optimizer_w <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>params<span class="token operator">=</span><span class="token punctuation">[</span>net<span class="token punctuation">.</span>weight<span class="token punctuation">]</span><span class="token punctuation">,</span> lr<span class="token operator">=</span>lr<span class="token punctuation">,</span> weight_decay<span class="token operator">=</span>wd<span class="token punctuation">)</span> <span class="token comment"># 对权重参数衰减</span>
optimizer_b <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>params<span class="token operator">=</span><span class="token punctuation">[</span>net<span class="token punctuation">.</span>bias<span class="token punctuation">]</span><span class="token punctuation">,</span> lr<span class="token operator">=</span>lr<span class="token punctuation">)</span>  <span class="token comment"># 不对偏差参数衰减</span>
<span class="token comment"># 最后分别对两个优化器进行 step() 就行</span>
optimizer_w<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
optimizer_b<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="训练模型" tabindex="-1"><a class="header-anchor" href="#训练模型"><span>训练模型</span></a></h2><p>通过调用<code>optimizer.step()</code>来更新权重，并通过<code>loss.item()</code>获取当前的损失值。</p><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="language-python"><code>num_epochs <span class="token operator">=</span> <span class="token number">3</span>
<span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> num_epochs <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">for</span> X<span class="token punctuation">,</span> y <span class="token keyword">in</span> data_iter<span class="token punctuation">:</span>
        X <span class="token operator">=</span> X<span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
        y <span class="token operator">=</span> y<span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
        output <span class="token operator">=</span> net<span class="token punctuation">(</span>X<span class="token punctuation">)</span>
        l <span class="token operator">=</span> loss<span class="token punctuation">(</span>output<span class="token punctuation">,</span> y<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># 梯度清零，等价于 net.zero_grad()</span>
        l<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;epoch %d, loss: %f&quot;</span> <span class="token operator">%</span> <span class="token punctuation">(</span>epoch<span class="token punctuation">,</span> l<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>将这一步的逻辑细分，可见下图所示：</p>`,5),x={class:"hint-container details"},q=a(`<summary>RuntimeError: Found dtype Double but expected Float 报错解决</summary><ul><li>报错代码段：</li></ul><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="language-python"><code>num_epochs <span class="token operator">=</span> <span class="token number">3</span>
<span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> num_epochs <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">for</span> X<span class="token punctuation">,</span> y <span class="token keyword">in</span> data_iter<span class="token punctuation">:</span>
        output <span class="token operator">=</span> net<span class="token punctuation">(</span>X<span class="token punctuation">)</span>
        l <span class="token operator">=</span> loss<span class="token punctuation">(</span>output<span class="token punctuation">,</span> y<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># 梯度清零，等价于 net.zero_grad()</span>
        l<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;epoch %d, loss: %f&quot;</span> <span class="token operator">%</span> <span class="token punctuation">(</span>epoch<span class="token punctuation">,</span> l<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li>报错信息：</li></ul><div class="language-text line-numbers-mode" data-ext="text" data-title="text"><pre class="language-text"><code>Traceback (most recent call last):
  File &quot;/home/oyh/桌面/Pytorch_learning/mydocs_2024/chapter02/create_tensor.py&quot;, line 68, in &lt;module&gt;
    l.backward()
  File &quot;/home/oyh/miniconda3/envs/torch/lib/python3.12/site-packages/torch/_tensor.py&quot;, line 522, in backward
    torch.autograd.backward(
  File &quot;/home/oyh/miniconda3/envs/torch/lib/python3.12/site-packages/torch/autograd/__init__.py&quot;, line 266, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
RuntimeError: Found dtype Double but expected Float
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li><p>报错原因： You need match the data type of the data to the data type of the model.</p></li><li><p>解决方法：</p></li></ul><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="language-python"><code>num_epochs <span class="token operator">=</span> <span class="token number">3</span>
<span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> num_epochs <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">for</span> X<span class="token punctuation">,</span> y <span class="token keyword">in</span> data_iter<span class="token punctuation">:</span>
        X <span class="token operator">=</span> X<span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
        y <span class="token operator">=</span> y<span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
        output <span class="token operator">=</span> net<span class="token punctuation">(</span>X<span class="token punctuation">)</span>
        l <span class="token operator">=</span> loss<span class="token punctuation">(</span>output<span class="token punctuation">,</span> y<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># 梯度清零，等价于 net.zero_grad()</span>
        l<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;epoch %d, loss: %f&quot;</span> <span class="token operator">%</span> <span class="token punctuation">(</span>epoch<span class="token punctuation">,</span> l<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre><div class="highlight-lines"><br><br><br><div class="highlight-line"> </div><div class="highlight-line"> </div><br><br><br><br><br><br></div><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div>`,7),z={href:"https://stackoverflow.com/questions/67456368/pytorch-getting-runtimeerror-found-dtype-double-but-expected-float",target:"_blank",rel:"noopener noreferrer"},D=a(`<p>训练所得输出：</p><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="language-python"><code>epoch <span class="token number">1</span><span class="token punctuation">,</span> loss<span class="token punctuation">:</span> <span class="token number">0.000450</span>
epoch <span class="token number">2</span><span class="token punctuation">,</span> loss<span class="token punctuation">:</span> <span class="token number">0.000046</span>
epoch <span class="token number">3</span><span class="token punctuation">,</span> loss<span class="token punctuation">:</span> <span class="token number">0.000097</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><div class="hint-container tip"><p class="hint-container-title">比较最终参数训练结果和真实值：</p><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="language-python"><code><span class="token keyword">print</span><span class="token punctuation">(</span>net<span class="token punctuation">.</span>linear<span class="token punctuation">.</span>weight<span class="token punctuation">.</span>data<span class="token punctuation">,</span> true_w<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>net<span class="token punctuation">.</span>linear<span class="token punctuation">.</span>bias<span class="token punctuation">.</span>data<span class="token punctuation">,</span> true_b<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div><p>输出：</p><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="language-python"><code>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">1.9997</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">3.4004</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">3.4</span><span class="token punctuation">]</span>
tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">4.2001</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token number">4.2</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div></div>`,3);function L(T,P){const p=e("Mermaid"),c=e("RouteLink"),o=e("ExternalLinkIcon");return l(),u("div",null,[k,t(p,{id:"mermaid-9",code:"eJzT1dXlKsksyUm1Uni+a/+zhuVPZ897unfS03XznvdteLa18fmKbi6QGq60nPzy5IzEohIFnyAuBQWF51PmP+uY8HTntqcd257snfNs6oZnvetezm5T0NW1U3i6btaTnZ3PVix8Oq8bItAx9+ny7qc90yBiT/ubgBqQlfbOf7pk49P2vajCT/bMAOp5vm76s81TwcIv1q19vrsZYggXFwCkXWj4"}),m,n("div",v,[b,n("p",null,[s("更多模型构建可以参考"),t(c,{to:"/code/python/pytorch/3.1Deeplearning_basic.html"},{default:r(()=>[s("“深度学习基础”一节")]),_:1})])]),h,y,g,n("p",null,[_,s("支持为不同的模型权重参数指定"),n("a",w,[s("权重衰减"),t(o)]),s("系数，具体代码实现为：")]),f,t(p,{id:"mermaid-125",code:"eJzT1dXlKsksyUm1Unixbu3z3c3PVix8Oq+bCySelpNfnpyRWFSi4BPEpQAEL9bvfto/7emG/medO1+29z+buuFZ7zoFXV07hee79j9rWP5878Tnu+e82Df5afsusPCLdQufr5v+rHf+0yUbn7bvBWoACz9btP7prmXPdrS+nL0NLPC0v/fphIlP9ix4NmktWKC4JLXgZcOkF/tncwEAUrZWFQ=="}),n("details",x,[q,n("ul",null,[n("li",null,[n("a",z,[s("参考"),t(o)])])])]),D])}const M=i(d,[["render",L],["__file","2.1linear_regression.html.vue"]]),N=JSON.parse('{"path":"/code/python/pytorch/2.1linear_regression.html","title":"线性回归实现","lang":"zh-CN","frontmatter":{"date":"2024-02-17T00:00:00.000Z","description":"线性回归实现 需要导入模块 线性回归实现的 pipes 如下所示： 生成并制作数据集 深度学习中，我们把自变量称作features，把因变量称作labels，我们要制作的数据集就是为了制作从 features 到 labels 的映射。 利用torch.utils.data库制作成数据集（建立映射），再定义batch_size，通过数据读取器从数据集里...","head":[["meta",{"property":"og:url","content":"https://dream-oyh.github.io/code/python/pytorch/2.1linear_regression.html"}],["meta",{"property":"og:site_name","content":"Dream_oyh 的 blog"}],["meta",{"property":"og:title","content":"线性回归实现"}],["meta",{"property":"og:description","content":"线性回归实现 需要导入模块 线性回归实现的 pipes 如下所示： 生成并制作数据集 深度学习中，我们把自变量称作features，把因变量称作labels，我们要制作的数据集就是为了制作从 features 到 labels 的映射。 利用torch.utils.data库制作成数据集（建立映射），再定义batch_size，通过数据读取器从数据集里..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2024-02-18T13:18:03.000Z"}],["meta",{"property":"article:author","content":"OYH"}],["meta",{"property":"article:published_time","content":"2024-02-17T00:00:00.000Z"}],["meta",{"property":"article:modified_time","content":"2024-02-18T13:18:03.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"线性回归实现\\",\\"image\\":[\\"\\"],\\"datePublished\\":\\"2024-02-17T00:00:00.000Z\\",\\"dateModified\\":\\"2024-02-18T13:18:03.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"OYH\\",\\"email\\":\\"19859860010@163.com\\"}]}"]]},"headers":[{"level":2,"title":"生成并制作数据集","slug":"生成并制作数据集","link":"#生成并制作数据集","children":[]},{"level":2,"title":"定义模型","slug":"定义模型","link":"#定义模型","children":[]},{"level":2,"title":"初始化模型参数","slug":"初始化模型参数","link":"#初始化模型参数","children":[]},{"level":2,"title":"定义损失函数","slug":"定义损失函数","link":"#定义损失函数","children":[]},{"level":2,"title":"定义优化算法","slug":"定义优化算法","link":"#定义优化算法","children":[]},{"level":2,"title":"训练模型","slug":"训练模型","link":"#训练模型","children":[]}],"git":{"createdTime":1708138728000,"updatedTime":1708262283000,"contributors":[{"name":"dream_linux","email":"1399541701@qq.com","commits":2},{"name":"dream同学0","email":"1399541701@qq.com","commits":1}]},"readingTime":{"minutes":5.21,"words":1564},"filePathRelative":"code/python/pytorch/2.1linear_regression.md","localizedDate":"2024年2月17日","excerpt":"\\n<div class=\\"hint-container tip\\">\\n<p class=\\"hint-container-title\\">需要导入模块</p>\\n<div class=\\"language-python\\" data-ext=\\"py\\" data-title=\\"py\\"><pre class=\\"language-python\\"><code><span class=\\"token keyword\\">import</span> torch\\n<span class=\\"token keyword\\">import</span> numpy <span class=\\"token keyword\\">as</span> np\\n<span class=\\"token keyword\\">import</span> torch<span class=\\"token punctuation\\">.</span>utils<span class=\\"token punctuation\\">.</span>data <span class=\\"token keyword\\">as</span> Data\\n<span class=\\"token keyword\\">import</span> torch<span class=\\"token punctuation\\">.</span>nn <span class=\\"token keyword\\">as</span> nn\\n\\n<span class=\\"token keyword\\">from</span> torch<span class=\\"token punctuation\\">.</span>nn <span class=\\"token keyword\\">import</span> init\\n<span class=\\"token keyword\\">import</span> torch<span class=\\"token punctuation\\">.</span>optim <span class=\\"token keyword\\">as</span> optim\\n</code></pre></div></div>","autoDesc":true}');export{M as comp,N as data};
