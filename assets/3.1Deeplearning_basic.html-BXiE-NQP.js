import{_ as l}from"./plugin-vue_export-helper-DlAUqK2U.js";import{r as o,o as i,c as u,d as n,b as s,a,w as c,e}from"./app-BelB4nhf.js";const d={},r=e(`<h1 id="深度学习基础" tabindex="-1"><a class="header-anchor" href="#深度学习基础"><span>深度学习基础</span></a></h1><h2 id="模型构建" tabindex="-1"><a class="header-anchor" href="#模型构建"><span>模型构建</span></a></h2><p>根据之前章节，我们已经能够发现，利用<code>nn.Module</code>和<code>nn.Sequential</code>可以很方便地构建模型，并且<code>nn.Sequential</code>本身也是<code>nn.Module</code>的一个继承类。所以，通过<code>nn.Module</code>来构建继承类也是非常通用的模型构建方式，一般来说，在继承类中我们会重载<code>nn.Module</code>的<code>forward()</code>函数，比如说我们可以通过继承类很容易地构建一个多层感知机模型：</p><blockquote><p>forward() 函数的目的在于，定义模型的前向计算，如何根据输入的数据 <code>x</code>计算出所需要的模型输出 <code>y</code>。</p></blockquote><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="language-python"><code><span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn
<span class="token keyword">class</span> <span class="token class-name">MLP</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
  <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span><span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token builtin">super</span><span class="token punctuation">(</span>MLP<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token operator">**</span>kwargs<span class="token punctuation">)</span>
    self<span class="token punctuation">.</span>hidden <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">784</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">)</span>  <span class="token comment"># 隐藏层</span>
    self<span class="token punctuation">.</span>act <span class="token operator">=</span> nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span>
    self<span class="token punctuation">.</span>output <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span>  <span class="token comment"># 输出层</span>
  <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
    a <span class="token operator">=</span> self<span class="token punctuation">.</span>act<span class="token punctuation">(</span>self<span class="token punctuation">.</span>hidden<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>
    renturn self<span class="token punctuation">.</span>output<span class="token punctuation">(</span>a<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>而<code>pytorch</code>库会自动生成<code>backward</code>反向传播函数</p><h3 id="nn-module的子类" tabindex="-1"><a class="header-anchor" href="#nn-module的子类"><span><code>nn.Module</code>的子类</span></a></h3><p><code>Pytorch</code>提供了丰富的<code>nn.Module</code>子类，我们可以直接使用这些子类来构建模型，比如<code>nn.Sequential</code>，<code>nn.Moudlelist</code>，<code>nn.ModuleDict</code>等，这些子类都继承自<code>nn.Module</code>。</p><h4 id="nn-sequential类" tabindex="-1"><a class="header-anchor" href="#nn-sequential类"><span><code>nn.Sequential</code>类</span></a></h4>`,9),k=n("code",null,"nn.Sequential",-1),m=n("code",null,"OrderedDict",-1),h=n("code",null,"add_module()",-1),v=e(`<h4 id="nn-modulelist类" tabindex="-1"><a class="header-anchor" href="#nn-modulelist类"><span><code>nn.ModuleList</code>类</span></a></h4><p>该类接受一个模块列表作为输入，如：</p><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="language-python"><code>net <span class="token operator">=</span> nn<span class="token punctuation">.</span>Modulelist<span class="token punctuation">(</span><span class="token punctuation">[</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
net<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">[</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div><p>该类的索引和列表类似，并且支持类似列表的<code>.append()</code>和<code>.extend()</code>操作。</p><div class="hint-container tip"><p class="hint-container-title">注意</p><p>不同于<code>nn.Sequential</code>，<code>nn.ModuleList</code>类并不支持<code>forward()</code>函数，而是需要自己定义。但是区分于传统<code>列表</code>，<code>nn.ModuleList</code>又能够生成参数，可以通过<code>nn.MoudleList.parameters()</code>来访问参数，所以该类只能认为是一个模块的容器，而并不是一个新的网络。</p></div><h4 id="nn-moduledict类" tabindex="-1"><a class="header-anchor" href="#nn-moduledict类"><span><code>nn.ModuleDict</code>类</span></a></h4><p>该类接受一个模块字典作为输入，也可以像字典一样操作。</p><p>和<code>nn.ModuleList</code>与<code>list</code>的关系一样，<code>nn.ModuleDict</code>没有定义<code>forward()</code>函数，需要自己定义，并且他较传统字典，他包括了模型所需要的权重参数。</p><ul><li>由于三者均为<code>nn..Module</code>的子类，所以可以互相嵌套调用。</li></ul>`,9),b={class:"hint-container important"},_=n("p",{class:"hint-container-title"},"不要局限了 Module 的用法",-1),y=n("code",null,"FlattenLayer",-1),g=n("code",null,"reshape",-1),f=n("code",null,"Module",-1),w=n("code",null,"Module",-1),M=n("code",null,"forward",-1),x=n("code",null,"Action",-1),L={href:"https://tangshusen.me/Dive-into-DL-PyTorch/#/chapter03_DL-basics/3.13_dropout?id=_3131-%E6%96%B9%E6%B3%95",target:"_blank",rel:"noopener noreferrer"},q=n("code",null,"nn.Module",-1),D=n("code",null,"nn.Dropout(drop_prob)",-1),S=n("code",null,"Dropout",-1),E=e(`<h2 id="访问模型参数" tabindex="-1"><a class="header-anchor" href="#访问模型参数"><span>访问模型参数</span></a></h2><p>对于用<code>Sequential</code>类构建的网络，我们可以简单地用<code>net[i]</code>调用指定层（i 的索引从 0 开始），用<code>parameters()</code>和<code>name_parameters()</code>调用参数，并且返回一个参数迭代器。</p><p>如：</p><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="language-python"><code>net <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">for</span> params <span class="token keyword">in</span> net<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span>：
    <span class="token keyword">print</span><span class="token punctuation">(</span>params<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment"># 输出结果为：</span>
torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">10</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

<span class="token keyword">for</span> name<span class="token punctuation">,</span>params <span class="token keyword">in</span> net<span class="token punctuation">.</span>named_parameters<span class="token punctuation">(</span><span class="token punctuation">)</span>：
    <span class="token keyword">print</span><span class="token punctuation">(</span>name<span class="token punctuation">,</span>params<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment"># name_parameters() 输出带有名字的参数列表，输出结果为：</span>
<span class="token number">0</span><span class="token punctuation">.</span>weight torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token number">0</span><span class="token punctuation">.</span>bias torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">10</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token number">2</span><span class="token punctuation">.</span>weight torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token number">2</span><span class="token punctuation">.</span>bias torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><div class="hint-container tip"><p class="hint-container-title">params 的对象类型</p><p><code>params</code>本质上也是一个<code>Tesnor</code>张量，其类型为<code>torch.nn.parameter.Parameter</code>，可以与<code>Tensor</code>有同样的操作，如<code>.data</code>读取数据，<code>.grad</code>求取梯度。</p></div><h2 id="初始化模型参数" tabindex="-1"><a class="header-anchor" href="#初始化模型参数"><span>初始化模型参数</span></a></h2><p>一般来说，我们需要对权重赋予正态分布的初始化，对偏差清零，赋予常数的初始化，我们可以通过参数的名字对参数进行区分：</p><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="language-python"><code><span class="token keyword">for</span> name<span class="token punctuation">,</span> param <span class="token keyword">in</span> net<span class="token punctuation">.</span>named_parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
  <span class="token keyword">if</span> <span class="token string">&quot;weight&quot;</span> <span class="token keyword">in</span> name<span class="token punctuation">:</span>
    init<span class="token punctuation">.</span>normal_<span class="token punctuation">(</span>param<span class="token punctuation">,</span>mean<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span>std<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">)</span>
  <span class="token keyword">if</span> <span class="token string">&quot;bias&quot;</span> <span class="token keyword">in</span> name<span class="token punctuation">:</span>
    init<span class="token punctuation">.</span>constant_<span class="token punctuation">(</span>param<span class="token punctuation">,</span>val <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="自定义初始化方法" tabindex="-1"><a class="header-anchor" href="#自定义初始化方法"><span>自定义初始化方法</span></a></h3><p><code>pytorch</code>中对一个张量初始化是不记录梯度的，所以我们需要在<code>with tensor.no_grad()</code>环境里配置，比如说初始化使得整体分布于（0,0.01）的标准正态分布，但是权重有一半的概率初始化为 0，另一半参数大于 0。可以这么定义初始化函数：</p><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="language-python"><code><span class="token keyword">def</span> <span class="token function">init_weight_</span><span class="token punctuation">(</span>tensor<span class="token punctuation">,</span> mean<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> std<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
  <span class="token keyword">with</span> tensor<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    tensor<span class="token punctuation">.</span>normal_<span class="token punctuation">(</span>mean<span class="token punctuation">,</span>std<span class="token punctuation">)</span>
    tensor <span class="token operator">*=</span> <span class="token punctuation">(</span>tensor<span class="token operator">&gt;</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token keyword">for</span> name<span class="token punctuation">,</span> param <span class="token keyword">in</span> net<span class="token punctuation">.</span>named_parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
  <span class="token keyword">if</span> <span class="token string">&quot;weight&quot;</span> <span class="token keyword">in</span> name<span class="token punctuation">:</span>
    init_weight_<span class="token punctuation">(</span>param<span class="token punctuation">,</span>mean<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span>std<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">)</span>
</code></pre><div class="highlight-lines"><br><div class="highlight-line"> </div><br><div class="highlight-line"> </div><br><br><br><br></div><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="共享模型参数" tabindex="-1"><a class="header-anchor" href="#共享模型参数"><span>共享模型参数</span></a></h3><p>只要保证两个层来自同一个数据寄存器（或者说来自同一个变量），即可保证参数共享。如：</p><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="language-python"><code>linear <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">)</span>
net <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>linear<span class="token punctuation">,</span>linear<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token builtin">id</span><span class="token punctuation">(</span>net<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">==</span><span class="token builtin">id</span><span class="token punctuation">(</span>net<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token builtin">id</span><span class="token punctuation">(</span>net<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>weight<span class="token punctuation">)</span><span class="token operator">==</span><span class="token builtin">id</span><span class="token punctuation">(</span>net<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>weight<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment"># 输出</span>
<span class="token boolean">True</span>
<span class="token boolean">True</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><div class="hint-container tip"><p class="hint-container-title">值得注意的是</p><p>在反向传播过程中，这两层的参数梯度是累加的。</p></div><h2 id="自定义层" tabindex="-1"><a class="header-anchor" href="#自定义层"><span>自定义层</span></a></h2><p>如前所说，<code>Module</code>这玩意是很宽泛的，可以继承它然后来构建很多自定义层。自定义层又分为两种：</p><ul><li>不带模型参数的自定义层</li><li>带模型参数的自定义层</li></ul><blockquote><p>不带模型参数的自定义层好理解，类似<code>FlattenLayer</code>就是一个不带模型参数的自定义层</p></blockquote><p><strong>本文着重讨论带模型参数的自定义层。</strong></p><p>由前文可知，模型参数应该是<code>Parameter</code>类型的，也是<code>Tensor</code>的子类，所以我们在继承类的<code>__init__()</code>函数中，应该通过<code>nn.Parameter()</code>来定义模型参数（定义方式与<code>Tensor</code>一致），指定的参数名字也会被<code>name_parameters()</code>读取。也可以通过<code>ParameterList()</code>或<code>ParameterDict()</code>类型来定义（输入一个<code>Parameter</code>列表或字典），举例如下：</p><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="language-python"><code><span class="token keyword">class</span> <span class="token class-name">MyDense</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>MyDense<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>params <span class="token operator">=</span> nn<span class="token punctuation">.</span>ParameterList<span class="token punctuation">(</span><span class="token punctuation">[</span>nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>params<span class="token punctuation">.</span>append<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>params<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            x <span class="token operator">=</span> torch<span class="token punctuation">.</span>mm<span class="token punctuation">(</span>x<span class="token punctuation">,</span> self<span class="token punctuation">.</span>params<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> x
net <span class="token operator">=</span> MyDense<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>net<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="保存和加载模型" tabindex="-1"><a class="header-anchor" href="#保存和加载模型"><span>保存和加载模型</span></a></h2>`,23),P={href:"https://tangshusen.me/Dive-into-DL-PyTorch/#/chapter04_DL_computation/4.5_read-write",target:"_blank",rel:"noopener noreferrer"},T=n("h2",{id:"gpu-计算",tabindex:"-1"},[n("a",{class:"header-anchor",href:"#gpu-计算"},[n("span",null,"GPU 计算")])],-1),z={href:"https://tangshusen.me/Dive-into-DL-PyTorch/#/chapter04_DL_computation/4.6_use-gpu",target:"_blank",rel:"noopener noreferrer"};function A(B,N){const p=o("RouteLink"),t=o("ExternalLinkIcon");return i(),u("div",null,[r,n("p",null,[k,s("中，各层模型可以以多种方式输入，这一点在"),a(p,{to:"/code/python/pytorch/2.1linear_regression.html#%E5%AE%9A%E4%B9%89%E6%A8%A1%E5%9E%8B"},{default:c(()=>[s("线性回归实现的笔记")]),_:1}),s("中有提到，总的来说，模型参数支持 直接输入各层、输入有序字典"),m,s("或通过"),h,s("函数添加。")]),v,n("div",b,[_,n("p",null,[s("我们在"),a(p,{to:"/code/python/pytorch/2.3softmax.html#%E5%AE%9A%E4%B9%89%E5%92%8C%E5%88%9D%E5%A7%8B%E5%8C%96%E6%A8%A1%E5%9E%8B"},{default:c(()=>[s("softmax")]),_:1}),s("中定义了一个"),y,s("层，这个层不同于一般印象里的线性计算，他只是一个"),g,s("的操作，但是我们把这也叫做一个层。也因为如此，我们对于"),f,s("的认识应该更广泛一些，"),w,s("提供的"),M,s("函数可以看作是这个层的"),x,s("，一种广义上的行为，而不只是前向传播。")]),n("p",null,[s("对于"),n("a",L,[s("丢弃法 (Dropout)"),a(t)]),s("，"),q,s("也提供了"),D,s("层，以方便使用。我们需要在全连接层之后加入"),S,s("层，它将在训练模型中以指定的丢弃概率随机丢弃一部分神经元，而在测试模型中不发挥作用。")])]),E,n("p",null,[n("a",P,[s("查看文档链接"),a(t)])]),T,n("p",null,[n("a",z,[s("查看文档链接"),a(t)])])])}const U=l(d,[["render",A],["__file","3.1Deeplearning_basic.html.vue"]]),O=JSON.parse('{"path":"/code/python/pytorch/3.1Deeplearning_basic.html","title":"深度学习基础","lang":"zh-CN","frontmatter":{"description":"深度学习基础 模型构建 根据之前章节，我们已经能够发现，利用nn.Module和nn.Sequential可以很方便地构建模型，并且nn.Sequential本身也是nn.Module的一个继承类。所以，通过nn.Module来构建继承类也是非常通用的模型构建方式，一般来说，在继承类中我们会重载nn.Module的forward()函数，比如说我们可以...","head":[["meta",{"property":"og:url","content":"https://dream-oyh.github.io/code/python/pytorch/3.1Deeplearning_basic.html"}],["meta",{"property":"og:site_name","content":"Dream_oyh 的 blog"}],["meta",{"property":"og:title","content":"深度学习基础"}],["meta",{"property":"og:description","content":"深度学习基础 模型构建 根据之前章节，我们已经能够发现，利用nn.Module和nn.Sequential可以很方便地构建模型，并且nn.Sequential本身也是nn.Module的一个继承类。所以，通过nn.Module来构建继承类也是非常通用的模型构建方式，一般来说，在继承类中我们会重载nn.Module的forward()函数，比如说我们可以..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2024-02-18T13:18:03.000Z"}],["meta",{"property":"article:author","content":"OYH"}],["meta",{"property":"article:modified_time","content":"2024-02-18T13:18:03.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"深度学习基础\\",\\"image\\":[\\"\\"],\\"dateModified\\":\\"2024-02-18T13:18:03.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"OYH\\",\\"email\\":\\"19859860010@163.com\\"}]}"]]},"headers":[{"level":2,"title":"模型构建","slug":"模型构建","link":"#模型构建","children":[{"level":3,"title":"nn.Module的子类","slug":"nn-module的子类","link":"#nn-module的子类","children":[]}]},{"level":2,"title":"访问模型参数","slug":"访问模型参数","link":"#访问模型参数","children":[]},{"level":2,"title":"初始化模型参数","slug":"初始化模型参数","link":"#初始化模型参数","children":[{"level":3,"title":"自定义初始化方法","slug":"自定义初始化方法","link":"#自定义初始化方法","children":[]},{"level":3,"title":"共享模型参数","slug":"共享模型参数","link":"#共享模型参数","children":[]}]},{"level":2,"title":"自定义层","slug":"自定义层","link":"#自定义层","children":[]},{"level":2,"title":"保存和加载模型","slug":"保存和加载模型","link":"#保存和加载模型","children":[]},{"level":2,"title":"GPU 计算","slug":"gpu-计算","link":"#gpu-计算","children":[]}],"git":{"createdTime":1708262283000,"updatedTime":1708262283000,"contributors":[{"name":"dream_linux","email":"1399541701@qq.com","commits":1}]},"readingTime":{"minutes":5.11,"words":1534},"filePathRelative":"code/python/pytorch/3.1Deeplearning_basic.md","localizedDate":"2024年2月18日","excerpt":"\\n<h2>模型构建</h2>\\n<p>根据之前章节，我们已经能够发现，利用<code>nn.Module</code>和<code>nn.Sequential</code>可以很方便地构建模型，并且<code>nn.Sequential</code>本身也是<code>nn.Module</code>的一个继承类。所以，通过<code>nn.Module</code>来构建继承类也是非常通用的模型构建方式，一般来说，在继承类中我们会重载<code>nn.Module</code>的<code>forward()</code>函数，比如说我们可以通过继承类很容易地构建一个多层感知机模型：</p>\\n","autoDesc":true}');export{U as comp,O as data};
